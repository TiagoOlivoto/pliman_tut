[
  {
    "objectID": "00_about.html",
    "href": "00_about.html",
    "title": "Useful info!",
    "section": "",
    "text": "2 Author\n\n\n\n\n\n3 Overview\n\n{pliman} (plant image analysis) is designed (but not limited) to analyze plant images, especially related to leaf and seed analysis. The package will help you to:\n\nMeasure the severity of foliar diseases;\nCount the number of injuries;\nObtain characteristics of the shape of the lesions;\nCount objects in an image;\nObtain characteristics of objects (area, perimeter, radius, circularity, eccentricity, solidity, elongation);\nGet the RGB values for each object in an image;\nGet the coordinates of objects;\nGet the outlines of objects;\nGet the convex hull;\nIsolate objects;\nPlot object measurements.\n\n4 Instalation\nInstall the released version of pliman from CRAN with:\n\ninstall.packages (\"pliman\")\n\nOr install the development version from GitHub\n\n# instalação do github\nif(!require(devtools)){\n  install.packages(\"devtools\")\n}\n\ninstall_github(\"TiagoOlivoto/pliman\")\n\n# Para instalar a vinheta HTML, use\ndevtools::install_github(\"TiagoOlivoto/pliman\", build_vignettes = TRUE)\n\nNote: If you are a Windows user, it is suggested to first download and install the latest version of Rtools. For the latest release notes on this development version, see the NEWS file.\n\n5 Citation\nTo cite the pliman package in your studies, please, use the following reference:\n\nOlivoto, Tiago. 2022. “Lights, Camera, Pliman! An R Package for Plant Image Analysis”. Methods in Ecology and Evolution 13(4): 789–98 doi: 10.1111/2041-210X.13803\n\n\n\ncitation(\"pliman\")\n\n\nPlease, support this project by citing it in your publications!\n\n  Olivoto, T.(2022). Lights, camera, pliman! An R package for plant\n  image analysis. Methods Ecol Evol. 13:789-798\n  doi:10.1111/2041-210X.13803\n\nA BibTeX entry for LaTeX users is\n\n  @Article{Olivoto2022,\n    author = {Tiago Olivoto},\n    title = {Lights, camera, pliman! An R package for plant image analysis},\n    journal = {Methods in Ecology and Evolution},\n    volume = {13},\n    number = {4},\n    pages = {789-798},\n    year = {2022},\n    doi = {10.1111/2041-210X.13803},\n  }\n\n\n\n6 Useful packages\nThe results generated by the pliman package are returned as data.frame objects, which allows future manipulation within R. Therefore, it is suggested that the following packages be installed.\n\nlibrary(tidyverse)  # data manipulation\nlibrary(metan)      # descriptive statistics / arrange graphics\nlibrary(pliman)     # image analysis\n\n\n7 How to reproduce\nFirst, donwload the .zip file that contains the static website.\n  Download the images and scripts \nThe folder img has the following structure.\n\n\nE:/Desktop/UFSC/cursos/pliman_tut/imgs\n├── bean.jpg\n├── black.jpeg\n├── compound.jpg\n├── disease.jpeg\n├── feijao_b.png\n├── feijao_h.png\n├── feijao_s.png\n├── flax.jpg\n├── flax1.jpg\n├── flax2.jpg\n├── flax3.jpg\n├── flax4.jpg\n├── flax5.jpg\n├── folhalin.png\n├── folhas.jpg\n├── fourier\n│   ├── changes.png\n│   ├── distance.png\n│   ├── img1.jpg\n│   ├── img2.jpg\n│   ├── img3.jpg\n│   ├── img4.jpg\n│   ├── img5.jpg\n│   ├── img6.jpg\n│   ├── img7.jpg\n│   ├── img8.jpg\n│   └── img9.jpg\n├── fundolin.png\n├── fungo.jpeg\n├── grains.JPG\n├── green.jpg\n├── holes.jpg\n├── imgs\n│   ├── img_exported.jpg\n│   └── test\n├── img_exported.jpg\n├── img_sb_50_1.jpg\n├── img_sb_50_10.jpg\n├── img_sb_50_11.jpg\n├── img_sb_50_12.jpg\n├── img_sb_50_13.jpg\n├── img_sb_50_2.jpg\n├── img_sb_50_3.jpg\n├── img_sb_50_4.jpg\n├── img_sb_50_5.jpg\n├── img_sb_50_6.jpg\n├── img_sb_50_7.jpg\n├── img_sb_50_8.jpg\n├── img_sb_50_9.jpg\n├── L1_1.jpg\n├── L1_2.jpg\n├── L2_1.jpg\n├── L2_2.jpg\n├── L3_1.jpg\n├── L3_2.jpg\n├── L3_3.jpg\n├── L4_1.jpg\n├── L4_2.jpg\n├── L4_3.jpg\n├── L5_1.jpg\n├── L5_2.jpg\n├── leaf1.jpg\n├── leaf2.jpg\n├── leaf3.jpg\n├── leaf4.jpg\n├── leaf5.jpg\n├── linhaca\n│   ├── A10_90_1.jpg\n│   ├── A10_90_2.jpg\n│   ├── A10_90_3.jpg\n│   ├── A11_98_1.jpg\n│   ├── A11_98_2.jpg\n│   ├── A11_98_3.jpg\n│   ├── A12_105_1.jpg\n│   ├── A12_105_2.jpg\n│   ├── A12_105_3.jpg\n│   ├── A1_28_1.jpg\n│   ├── A1_28_2.jpg\n│   ├── A1_28_3.jpg\n│   ├── A2_32_1.jpg\n│   ├── A2_32_2.jpg\n│   ├── A2_32_3.jpg\n│   ├── A3_42_1.jpg\n│   ├── A3_42_2.jpg\n│   ├── A3_42_3.jpg\n│   ├── A4_46_1.jpg\n│   ├── A4_46_2.jpg\n│   ├── A4_46_3.jpg\n│   ├── A5_55_1.jpg\n│   ├── A5_55_2.jpg\n│   ├── A5_55_3.jpg\n│   ├── A6_63_1.jpg\n│   ├── A6_63_2.jpg\n│   ├── A6_63_3.jpg\n│   ├── A7_70_1.jpg\n│   ├── A7_70_2.jpg\n│   ├── A7_70_3.jpg\n│   ├── A8_76_1.jpg\n│   ├── A8_76_2.jpg\n│   ├── A8_76_3.jpg\n│   ├── A9_83_1.jpg\n│   ├── A9_83_2.jpg\n│   ├── A9_83_3.jpg\n│   ├── proc\n│   └── res\n├── lista\n│   ├── img_sb_50_1.jpg\n│   └── img_sb_50_2.jpg\n├── lista_exportada\n│   ├── img_exported.jpg\n│   ├── img_sb_50_1.jpg\n│   ├── img_sb_50_10.jpg\n│   ├── img_sb_50_11.jpg\n│   ├── img_sb_50_12.jpg\n│   ├── img_sb_50_13.jpg\n│   ├── img_sb_50_2.jpg\n│   ├── img_sb_50_3.jpg\n│   ├── img_sb_50_4.jpg\n│   ├── img_sb_50_5.jpg\n│   ├── img_sb_50_6.jpg\n│   ├── img_sb_50_7.jpg\n│   ├── img_sb_50_8.jpg\n│   └── img_sb_50_9.jpg\n├── manipula\n│   ├── 20220819_140351.jpg\n│   ├── 20220819_140836.jpg\n│   ├── 20220819_141224.jpg\n│   ├── 20220819_141521.jpg\n│   └── renomeadas\n├── mosaic.tif\n├── multiplas_01.jpeg\n├── multiplas_02.jpeg\n├── multiplas_03.jpeg\n├── multiplas_04.jpeg\n├── multiplas_05.jpg\n├── objects_300.jpg\n├── proc\n│   ├── proc_soy_1.jpg\n│   ├── proc_soy_10.jpg\n│   ├── proc_soy_11.jpg\n│   ├── proc_soy_12.jpg\n│   ├── proc_soy_13.jpg\n│   ├── proc_soy_14.jpg\n│   ├── proc_soy_15.jpg\n│   ├── proc_soy_16.jpg\n│   ├── proc_soy_17.jpg\n│   ├── proc_soy_18.jpg\n│   ├── proc_soy_19.jpg\n│   ├── proc_soy_2.jpg\n│   ├── proc_soy_20.jpg\n│   ├── proc_soy_21.jpg\n│   ├── proc_soy_22.jpg\n│   ├── proc_soy_23.jpg\n│   ├── proc_soy_24.jpg\n│   ├── proc_soy_25.jpg\n│   ├── proc_soy_26.jpg\n│   ├── proc_soy_27.jpg\n│   ├── proc_soy_28.jpg\n│   ├── proc_soy_29.jpg\n│   ├── proc_soy_3.jpg\n│   ├── proc_soy_30.jpg\n│   ├── proc_soy_31.jpg\n│   ├── proc_soy_32.jpg\n│   ├── proc_soy_33.jpg\n│   ├── proc_soy_34.jpg\n│   ├── proc_soy_35.jpg\n│   ├── proc_soy_36.jpg\n│   ├── proc_soy_37.jpg\n│   ├── proc_soy_38.jpg\n│   ├── proc_soy_39.jpg\n│   ├── proc_soy_4.jpg\n│   ├── proc_soy_40.jpg\n│   ├── proc_soy_41.jpg\n│   ├── proc_soy_42.jpg\n│   ├── proc_soy_43.jpg\n│   ├── proc_soy_44.jpg\n│   ├── proc_soy_45.jpg\n│   ├── proc_soy_46.jpg\n│   ├── proc_soy_47.jpg\n│   ├── proc_soy_48.jpg\n│   ├── proc_soy_49.jpg\n│   ├── proc_soy_5.jpg\n│   ├── proc_soy_50.jpg\n│   ├── proc_soy_6.jpg\n│   ├── proc_soy_7.jpg\n│   ├── proc_soy_8.jpg\n│   └── proc_soy_9.jpg\n├── ref_leaves.jpg\n├── resultado.xlsx\n├── Rplots.pdf\n├── rule.jpg\n├── samples.png\n├── scripts_pliman_rmd_files\n│   └── figure-html\n├── sev_back.png\n├── sev_disease.png\n├── sev_healthy.png\n├── shapefiles.jpg\n├── simple.jpg\n├── site.png\n├── soja_b.png\n├── soja_h.png\n├── soja_s.png\n├── soy_1.jpg\n├── soy_10.jpg\n├── soy_11.jpg\n├── soy_12.jpg\n├── soy_13.jpg\n├── soy_14.jpg\n├── soy_15.jpg\n├── soy_16.jpg\n├── soy_17.jpg\n├── soy_18.jpg\n├── soy_19.jpg\n├── soy_2.jpg\n├── soy_20.jpg\n├── soy_21.jpg\n├── soy_22.jpg\n├── soy_23.jpg\n├── soy_24.jpg\n├── soy_25.jpg\n├── soy_26.jpg\n├── soy_27.jpg\n├── soy_28.jpg\n├── soy_29.jpg\n├── soy_3.jpg\n├── soy_30.jpg\n├── soy_31.jpg\n├── soy_32.jpg\n├── soy_33.jpg\n├── soy_34.jpg\n├── soy_35.jpg\n├── soy_36.jpg\n├── soy_37.jpg\n├── soy_38.jpg\n├── soy_39.jpg\n├── soy_4.jpg\n├── soy_40.jpg\n├── soy_41.jpg\n├── soy_42.jpg\n├── soy_43.jpg\n├── soy_44.jpg\n├── soy_45.jpg\n├── soy_46.jpg\n├── soy_47.jpg\n├── soy_48.jpg\n├── soy_49.jpg\n├── soy_5.jpg\n├── soy_50.jpg\n├── soy_6.jpg\n├── soy_7.jpg\n├── soy_8.jpg\n├── soy_9.jpg\n├── TRAT1_1.jpg\n├── TRAT1_2.jpg\n├── TRAT1_3.jpg\n├── TRAT1_4.jpg\n├── TRAT2_1.jpg\n├── TRAT2_2.jpg\n├── TRAT2_3.jpg\n├── TRAT2_4.jpg\n├── TRAT3_1.jpg\n├── TRAT3_2.jpg\n├── TRAT3_3.jpg\n├── TRAT3_4.jpg\n├── TRAT4_1.jpg\n├── TRAT4_2.jpg\n├── TRAT4_3.jpg\n├── TRAT4_4.jpg\n├── vicia.jpg\n├── videira.png\n├── videira_b.png\n├── videira_d.png\n└── videira_h.png\n\n\nThe html material (_site/index.html) will give access to the site. Within it, it will be possible to visualize all the examples, with codes and outputs. To reproduce the material, just use the *.qmd files.\nFor rendering, it is suggested that the folder imgs be set as the default directory. In my case, I set the directory using the following command.\n\n# change according to your folder\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n\n\n\n8 Slides\nSee the slides here\n\n\n\n\n\n9 License\nThis content is licensed under a CC BY-NC-SA 4.0. The readable license summary states that you have the right to:\n Share — copy and redistribute material in any medium or format\nAdapt — remix, transform, and build upon material\nAttribution — You must give appropriate credit, provide a link to the license and indicate if changes have been made. You must do so under any reasonable circumstances, but in no way that suggests that the licensor endorses you or your use.\nAccording to the following terms\n\nNon-Commercial — You may not use the material for commercial purposes.\nShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo Additional Restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license allows."
  },
  {
    "objectID": "01_manipulate.html",
    "href": "01_manipulate.html",
    "title": "Import and manipulate",
    "section": "",
    "text": "2 File manipulation\n\nlibrary(pliman)\nlibrary(tidyverse)\nlibrary(patchwork)\n# set_wd_here(\"imgs\")\nlist.files(pattern = \"2022\", path = \"manipula\")\n## [1] \"20220819_140351.jpg\" \"20220819_140836.jpg\" \"20220819_141224.jpg\"\n## [4] \"20220819_141521.jpg\"\n\n# name vector\nnomes <- c(\"T1_R1\", \"T1_R2\", \"T2_R1\", \"T2_R2\")\n\n# rename the files\nmanipulate_files(pattern = \"2022\",\n                 name = nomes,\n                 save_to = \"manipula/renomeadas\",\n                 dir = \"manipula\")\n\n\n3 Import images\n\nimg <- image_import(\"folhas.jpg\")\n\nTo import a list of images, use a vector of image names, or the pattern argument. In the latter, all images that match the pattern name are imported into a list.\n\nimg_list1 <- image_import(c(\"img_sb_50_1.jpg\", \"img_sb_50_2.jpg\"))\nimg_list2 <- image_import(pattern = \"img_sb_\")\nstr(img_list2)\n\nList of 13\n $ img_sb_50_1.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.365 0.361 0.361 0.349 0.365 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_10.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.42 0.408 0.416 0.416 0.416 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_11.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.388 0.38 0.384 0.38 0.369 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_12.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.38 0.376 0.392 0.384 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_13.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.392 0.392 0.412 0.384 0.4 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_2.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.376 0.384 0.392 0.388 0.396 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_3.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.369 0.376 0.361 0.361 0.365 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_4.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.4 0.408 0.404 0.396 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_5.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.396 0.404 0.396 0.396 0.388 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_6.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.4 0.38 0.396 0.384 0.388 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_7.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.349 0.361 0.365 0.365 0.373 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_8.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.361 0.373 0.376 0.388 0.384 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_9.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.373 0.365 0.373 0.384 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n\n\n\n4 Displaying imagens\nIndividual images are displayed with plot(). To combine images, the image_combine() function is used. Users can enter a comma-separated list of objects or a list of objects of the Image class.\n\n# Imagens individuais\nplot(img)\n\n\n\n\n\n# Combine imagens\nimage_combine(img_list1)\n\n\n\n\npliman provides a set of image_*() functions to perform image manipulation and transformation of unique images or an image list based on EBImage package.\n\n5 Resize an image\nSometimes resizing high-resolution images is necessary to reduce computational effort and processing time. The image_resize() function is used to resize an image. The rel_size argument can be used to resize the image by relative size. For example, setting rel_size = 50 for an image of width 1280 x 720, the new image will have a size of 640 x 360.\n\nimage_dimension(img)\n\n\n----------------------\nImage dimension\n----------------------\nWidth :  783 \nHeight:  1005 \n\nimg_resized <- image_resize(img, rel_size = 50)\nimage_dimension(img_resized)\n\n\n----------------------\nImage dimension\n----------------------\nWidth :  392 \nHeight:  502 \n\n\n\n6 Image resolution (DPI)\nThe dpi() function executes an interactive function to calculate the image resolution given a known distance entered by the user. To calculate the image resolution (dpi), the user must use the left mouse button to create a line of known distance. This can be done, for example, using a model with known distance, as follows.\n\n#  this only works in an interactive section\nrule <- image_import(\"rule.jpg\", plot = TRUE)\nx11()\n(imgres <- dpi(rule))\n\nrule2 <- \n  image_crop(rule,\n             width = 130:1390,\n             height = 582:1487,\n             plot = TRUE)\n\nanalyze_objects(rule2,\n                watershed = FALSE,\n                marker = \"area\",\n                contour_col = \"blue\",\n                contour_size = 8) |> \n  get_measures(dpi = 518) |> \n  plot_measures(measure = \"area\", vjust = -100, size = 2)\n\n\n7 Align an image\nTo construct shapefiles with image_shp() the image objects need to be aligned along the x/y axis. image_align() can be used to provide such alignment. Users will need to draw a line along the y axis that corresponds to the alignment of the objects (e.g., field plots). By default, the aligment will be to the vertical, which means that if the drawed line have an angle < 90º parallel to the x axis, the rotation angle wil be negative (anticlocwise rotation). If the drawed line have an angle > 90º along the x axis, the rotation angle wil be positive (clocwise rotation). If the aligment is horizontal, the image will be rotated to align the drawed line paralell to the x axis assuming the shortest angle (left or right rotation if the angle is < 90º or > 90º, respectively)\n\nshp <- image_import(\"shapefiles.jpg\")\nshp_aligned <- image_align(shp)\n\n\n8 Filter, blur, contrast, dilatation, erosion, opening, and closing\n\nimg_filter <- image_filter(img)\nimg_blur <- image_blur(img)\nimg_contrast <- image_contrast(img)\nimg_dilatation <- image_dilate(img)\nimg_erosion <- image_erode(img)\nimg_opening <- image_opening(img)\nimg_closing <- image_closing(img)\nimage_combine(img,\n              img_filter,\n              img_blur,\n              img_contrast,\n              img_dilatation,\n              img_erosion,\n              img_opening,\n              img_closing,\n              ncol = 4)\n\n\n\n\n\n9 Apply a function to images\n\napply_fun_to_imgs(pattern = \"img_\",\n                  fun = image_autocrop,\n                  dir_processed = \"lista_exportada\")\n\nProcessing image img_exported.jpg |==                            | 7% 00:00:00 \nProcessing image img_sb_50_1.jpg |====                           | 14% 00:00:01 \nProcessing image img_sb_50_10.jpg |======                        | 21% 00:00:01 \nProcessing image img_sb_50_11.jpg |=========                     | 29% 00:00:01 \nProcessing image img_sb_50_12.jpg |===========                   | 36% 00:00:01 \nProcessing image img_sb_50_13.jpg |=============                 | 43% 00:00:02 \nProcessing image img_sb_50_2.jpg |================               | 50% 00:00:02 \nProcessing image img_sb_50_3.jpg |==================             | 57% 00:00:02 \nProcessing image img_sb_50_4.jpg |====================           | 64% 00:00:03 \nProcessing image img_sb_50_5.jpg |======================         | 71% 00:00:03 \nProcessing image img_sb_50_6.jpg |========================       | 79% 00:00:03 \nProcessing image img_sb_50_7.jpg |===========================    | 86% 00:00:03 \nProcessing image img_sb_50_8.jpg |=============================  | 93% 00:00:04 \nProcessing image img_sb_50_9.jpg |===============================| 100% 00:00:04 \n\n\n\n10 Export\nTo export images to the current directory, use the image_export() function. If an image list is exported, the images will be saved considering the name and extension present in the list. If no extension is present, images will be saved as *.jpg files.\n\nimage_export(img, \"imgs/img_exported.jpg\")\n# or a subfolder\nimage_export(img, \"imgs/test/img_exported.jpg\")\n\nimage_export(img_list1, subfolder = \"lista\")"
  },
  {
    "objectID": "02_segment.html",
    "href": "02_segment.html",
    "title": "Segment objects",
    "section": "",
    "text": "setwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")"
  },
  {
    "objectID": "02_segment.html#using-image-indexes",
    "href": "02_segment.html#using-image-indexes",
    "title": "Segment objects",
    "section": "\n5.1 Using image indexes",
    "text": "5.1 Using image indexes\nThe image_segment() function is used to segment images using image indices. In this example, we will use compare the B and NB index to segment the leaves.\n\nseg1 <- \n  image_segment(img,\n                index = c(\"B, NB\"))"
  },
  {
    "objectID": "02_segment.html#using-k-means-algorithm",
    "href": "02_segment.html#using-k-means-algorithm",
    "title": "Segment objects",
    "section": "\n5.2 Using k-means algorithm",
    "text": "5.2 Using k-means algorithm\nTHe function image_segment_kmeans() segments image objects using clustering by the k-means clustering algorithm. Users need to declare the number of classes after object segmentation using the argument nclasses. By default, two classes are returned.\n\nseg2 <- image_segment_kmeans(img, nclasses = 4)\n\n\n\nseg2 <- image_segment_kmeans(img, nclasses = 2) # default\n\n\n\nseg2 <- \n  image_segment_kmeans(img,\n                       nclasses = 2,\n                       invert = TRUE,\n                       filter = 5)"
  },
  {
    "objectID": "02_segment.html#using-a-mask",
    "href": "02_segment.html#using-a-mask",
    "title": "Segment objects",
    "section": "\n5.3 Using a mask",
    "text": "5.3 Using a mask\nBy using image_segment_mask() it is possible to segment an object using a mask.\n\nobjs <- image_import(\"objects_300.jpg\", plot = TRUE)\nimage_segment_mask(objs,\n                   type = \"shadow\",\n                   size = 1171,\n                   shape = \"box\")\nimage_segment_mask(objs,\n                   size = 1171,\n                   rel_pos_y = 0.6,\n                   rel_pos_x = 0.08,\n                   shape = \"disc\")\n\n\n\n\n\n\n\n\n\nImage \n  colorMode    : Color \n  storage.mode : double \n  dim          : 2126 1535 3 \n  frames.total : 3 \n  frames.render: 1 \n\nimageData(object)[1:5,1:6,1]\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    1    1    1    1    1\n[2,]    1    1    1    1    1    1\n[3,]    1    1    1    1    1    1\n[4,]    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1\n\n\n\n\n\n\n\nImage \n  colorMode    : Color \n  storage.mode : double \n  dim          : 2126 1535 3 \n  frames.total : 3 \n  frames.render: 1 \n\nimageData(object)[1:5,1:6,1]\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    1    1    1    1    1\n[2,]    1    1    1    1    1    1\n[3,]    1    1    1    1    1    1\n[4,]    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1"
  },
  {
    "objectID": "02_segment.html#iterative-segmentation",
    "href": "02_segment.html#iterative-segmentation",
    "title": "Segment objects",
    "section": "\n6.1 Iterative segmentation",
    "text": "6.1 Iterative segmentation\nThe function image_segment_iter() provides an iterative image segmentation. Users can choose how many segmentation to perform, using the argument nseg. Note that the same results can be obtained with image_segment_iter() using an iterative section.\n\n# Only run iteratively\nimage_segment_iter(img, nseg = 1)"
  },
  {
    "objectID": "02_segment.html#point-click-and-segment",
    "href": "02_segment.html#point-click-and-segment",
    "title": "Segment objects",
    "section": "\n6.2 Point, click, and segment",
    "text": "6.2 Point, click, and segment\nimage_segment_manual() segments image objects ‘by hand’. The user will need to pick the perimeter of the object to be segmented. So, this only works in an interactive section.\n\nx11()\nseg3 <- image_segment_manual(img)\nseg3 <- image_segment_manual(img, resize = FALSE)\nseg3 <- image_segment_manual(img, type = \"exclude\")"
  },
  {
    "objectID": "02_segment.html#shapefiles",
    "href": "02_segment.html#shapefiles",
    "title": "Segment objects",
    "section": "\n6.3 Shapefiles",
    "text": "6.3 Shapefiles\nimage_shp() creates a list of object coordinates given the desired number of rows and columns. It starts by selecting 4 points at the corners of objects of interest in the plot space. Then, given rows and cols, a grid is drawn and the objects’ coordinates are returned.\n\nx11()\nflax <- image_import(\"shapefiles.jpg\", plot = TRUE)\nshps <- image_shp(flax, rows = 3, cols = 10)\nstr(shps)\nlines(shps$bbox, col = \"red\", lwd = 5)\n\nobject_split_shp() splits the image objects into a list of objects considering the object coordinates computed with image_shp().\n\nleaves <- object_split_shp(flax, rows = 3, cols = 5)\nimage_combine(leaves[1:2])"
  },
  {
    "objectID": "03_analyze.html",
    "href": "03_analyze.html",
    "title": "Analyze objects",
    "section": "",
    "text": "setwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")"
  },
  {
    "objectID": "03_analyze.html#area",
    "href": "03_analyze.html#area",
    "title": "Analyze objects",
    "section": "\n2.1 Area",
    "text": "2.1 Area\nThe area of a shape is calculated using Shoelace’s formula (Lee and Lim, 2017)5, as follows\n\\[\nA=\\frac{1}{2}\\left |\\sum_{i=1}^{n}\\left(x_{i} y_{i+1}-x_{i+1}y_{i}\\right)\\right|\n\\]\n\npoly_area(cont)\n\n      1       2      12      23 \n18379.0 36412.5  8294.0  1750.0"
  },
  {
    "objectID": "03_analyze.html#perimeter",
    "href": "03_analyze.html#perimeter",
    "title": "Analyze objects",
    "section": "\n2.2 Perimeter",
    "text": "2.2 Perimeter\nThe perimeter is calculated as the sum of the Euclidean distance between all points on a shape. Distances can be obtained with poly_distpts().\n\npoly_perimeter(cont)\n\n        1         2        12        23 \n 615.0143 1122.8448  469.5584  555.0833 \n\n# perimeter of a circle with radius 2\ncircle <- draw_circle(radius = 2, plot = FALSE)\npoly_perimeter(circle)\n\n[1] 12.56635\n\n# check the result\n2*pi*2\n\n[1] 12.56637"
  },
  {
    "objectID": "03_analyze.html#radius",
    "href": "03_analyze.html#radius",
    "title": "Analyze objects",
    "section": "\n2.3 Radius",
    "text": "2.3 Radius\nThe radius of a pixel on the object’s contour is calculated as its distance from the object’s centroid(also called ‘center of mass’). These distances can be obtained with poly_centdist().\n\ndist <- poly_centdist(cont)\n\n# stats for radius\nmean_list(dist)\n\n        1         2        12        23 \n 81.52730 107.18736  61.76413  68.00845 \n\nmin_list(dist)\n\n       1        2       12       23 \n56.16876 62.37804 29.40537  3.44969 \n\nmax_list(dist)\n\n       1        2       12       23 \n126.9367 152.4562 106.8634 135.5301 \n\nsd_list(dist)\n\n       1        2       12       23 \n17.40508 18.44772 23.15230 38.91780 \n\n# average radius of above circle\npoly_centdist(circle) |> mean_list()\n\n[1] 1.999998"
  },
  {
    "objectID": "03_analyze.html#length-and-width",
    "href": "03_analyze.html#length-and-width",
    "title": "Analyze objects",
    "section": "\n2.4 Length and width",
    "text": "2.4 Length and width\nThe length and width of an object are calculated with poly_lw(), as the difference between the maximum and minimum of the x and y coordinates after the object has been aligned with poly_align().\n\npoly_lw(cont)\n\n     length     width\n1  238.5645 125.11629\n2  280.5703 237.69880\n12 208.3183  68.91907\n23 269.2557  10.63356"
  },
  {
    "objectID": "03_analyze.html#circularity-eccentricity-diameter-and-elongation",
    "href": "03_analyze.html#circularity-eccentricity-diameter-and-elongation",
    "title": "Analyze objects",
    "section": "\n2.5 Circularity, eccentricity, diameter, and elongation",
    "text": "2.5 Circularity, eccentricity, diameter, and elongation\nCircularity(Montero et al. 2009)6 is also called shape compactness, or measure of roundness of an object. It is given by \\(C = P^2 / A\\), where \\(P\\) is the perimeter and \\(A\\) is the area of the object.\n\npoly_circularity(cont)\n\n        1         2        12        23 \n 20.58015  34.62494  26.58369 176.06710 \n\n\nAs the above measurement depends on the scale, normalized roundness can be used. In this case, a perfect circle is assumed to have a circularity equal to 1. This measure is invariant under translation, rotation and scale transformations, given \\(Cn = P^2 / 4 \\pi A\\)\n\npoly_circularity_norm(cont)\n\n        1         2        12        23 \n 1.637716  2.755365  2.115463 14.010975 \n\n# normalized circularity for different shapes\ndraw_square(plot =FALSE) |> poly_circularity_norm()\n\n[1] 1.27324\n\ndraw_circle(plot=FALSE) |> poly_circularity_norm()\n\n[1] 1.000003\n\n\npoly_circularity_haralick() calculates the Circularity of Haralick, CH (Haralick, 1974)7. The method is based on calculating all Euclidean distances from the object’s centroid to each contour pixel. With this set of distances, the mean(\\(m\\)) and the standard deviation(\\(s\\)) are calculated. These statistical parameters are used in a ratio that calculates CH as $CH = m/ sd $.\n\npoly_circularity_haralick(cont)\n\n       1        2       12       23 \n4.684109 5.810331 2.667732 1.747489 \n\n\npoly_convexity() Calculates the convexity of a shape using a ratio of the perimeter of the convex hull to the perimeter of the polygon.\n\npoly_convexity(cont)\n\n        1         2        12        23 \n0.8795792 0.6891546 0.9133513 0.7703550 \n\n\npoly_eccentricity() Calculates the eccentricity of a shape using the ratio of the eigenvalues(coordinate inertia axes).\n\npoly_eccentricity(cont)\n\n         1          2         12         23 \n0.34777030 0.84355337 0.12747908 0.00205374 \n\n\npoly_elongation() Calculates the elongation of an object as 1 - width / length\n\npoly_elongation(cont)\n\n        1         2        12        23 \n0.4755452 0.1528012 0.6691646 0.9605076 \n\n\npoly_caliper() Calculates the gauge(also called Feret’s diameter).\n\npoly_caliper(cont)\n\n       1        2       12       23 \n238.6064 284.5083 208.4322 269.2675 \n\n\nUsers can use the poly_measures() function to calculate most object measurements in a single call.\n\nmeasures <- poly_measures(cont) |> round_cols()\nt(measures)\n\n                            1        2      12      23\nid                       1.00     2.00    3.00    4.00\nx                      472.94   808.90  443.60  412.66\ny                      144.26   168.36  512.17  657.39\narea                 18379.00 36412.50 8294.00 1750.00\narea_ch              19558.00 45900.50 8815.50 2110.50\nperimeter              615.01  1122.84  469.56  555.08\nradius_mean             81.53   107.19   61.76   68.01\nradius_min              56.17    62.38   29.41    3.45\nradius_max             126.94   152.46  106.86  135.53\nradius_sd               17.41    18.45   23.15   38.92\nradius_ratio             2.26     2.44    3.63   39.29\ndiam_mean              163.05   214.37  123.53  136.02\ndiam_min               112.34   124.76   58.81    6.90\ndiam_max               253.87   304.91  213.73  271.06\ncaliper                238.61   284.51  208.43  269.27\nlength                 238.56   280.57  208.32  269.26\nwidth                  125.12   237.70   68.92   10.63\nsolidity                 0.94     0.79    0.94    0.83\nconvexity                0.88     0.69    0.91    0.77\nelongation               0.48     0.15    0.67    0.96\ncircularity             20.58    34.62   26.58  176.07\ncircularity_haralick     3.23     3.38    1.27    0.09\ncircularity_norm         1.64     2.76    2.12   14.01\neccentricity             0.35     0.84    0.13    0.00\n\n\nIf the image resolution is known, the measurements can be corrected with get_measures(). Image resolution can be obtained using a known distance in the image. In the example, the white square has a side of 5 cm. So using dpi() the resolution can be obtained. In this case, the dpi is ~50.\n\ncolor_measures <- get_measures(measures, dpi = 50)\nt(color_measures)\n\n                           1       2      12      23\nid                     1.000   2.000   3.000   4.000\nx                    472.940 808.900 443.600 412.660\ny                    144.260 168.360 512.170 657.390\narea                  47.430  93.968  21.404   4.516\narea_ch               50.472 118.453  22.750   5.446\nperimeter             31.243  57.040  23.854  28.198\nradius_mean            4.142   5.445   3.137   3.455\nradius_min             2.853   3.169   1.494   0.175\nradius_max             6.449   7.745   5.428   6.885\nradius_sd              0.884   0.937   1.176   1.977\nradius_ratio           0.115   0.124   0.184   1.996\ndiam_mean              8.283  10.890   6.275   6.910\ndiam_min               5.707   6.338   2.988   0.351\ndiam_max              12.897  15.489  10.857  13.770\ncaliper               12.121  14.453  10.588  13.679\nlength                12.119  14.253  10.583  13.678\nwidth                  6.356  12.075   3.501   0.540\nsolidity               0.940   0.790   0.940   0.830\nconvexity              0.880   0.690   0.910   0.770\nelongation             0.480   0.150   0.670   0.960\ncircularity           20.580  34.620  26.580 176.070\ncircularity_haralick   3.230   3.380   1.270   0.090\ncircularity_norm       1.640   2.760   2.120  14.010\neccentricity           0.350   0.840   0.130   0.000\n\n\nSome useful functions can be used to manipulate coordinates. In the following example I will show some features implemented in pliman. Just for simplicity, I’ll use only one object.\n\no2 <- cont[[\"12\"]]\nplot_polygon(o2)"
  },
  {
    "objectID": "03_analyze.html#rotate-polygons",
    "href": "03_analyze.html#rotate-polygons",
    "title": "Analyze objects",
    "section": "\n2.6 Rotate polygons",
    "text": "2.6 Rotate polygons\npoly_rotate() can be used to rotate the polygon coordinates by an angle (0-360 degrees) in the trigonometric (anti-clockwise) direction.\n\nrot <- poly_rotate(o2, angle = 45)"
  },
  {
    "objectID": "03_analyze.html#invert-polygons",
    "href": "03_analyze.html#invert-polygons",
    "title": "Analyze objects",
    "section": "\n2.7 Invert polygons",
    "text": "2.7 Invert polygons\npoly_flip_x() and poly_flip_y() can be used to flip shapes along the x and y axis, respectively.\n\nflipped <- \n  list(fx = poly_flip_x(o2), \n       fy = poly_flip_y(o2))\n\nplot_polygon(flipped, merge = FALSE)"
  },
  {
    "objectID": "03_analyze.html#perimeter-sampling",
    "href": "03_analyze.html#perimeter-sampling",
    "title": "Analyze objects",
    "section": "\n2.8 Perimeter sampling",
    "text": "2.8 Perimeter sampling\npoly_sample() samples n coordinates between existing points, and poly_sample_prop() samples a proportion of coordinates between existing ones.\n\n# sample 50 coordinates\npoly_sample(o2, n=10) |> plot_polygon()\n\n\n\n# sample 10% of coordinates\npoly_sample_prop(o2, prop = 0.1) |> plot_polygon()"
  },
  {
    "objectID": "03_analyze.html#smoothing",
    "href": "03_analyze.html#smoothing",
    "title": "Analyze objects",
    "section": "\n2.9 smoothing",
    "text": "2.9 smoothing\npoly_smooth() smooths the contour of a polygon by combining prop coordinate point samples and interpolating them using vertices vertices(default is 1000) .\n\nsmoothed <-\n  list( original = o2,\n        s1 = poly_smooth(o2, prop = 0.2, plot = FALSE),\n        s2 = poly_smooth(o2, prop = 0.1, plot = FALSE),\n        s1 = poly_smooth(o2, prop = 0.04, plot = FALSE)\n  )\n\nplot_polygon(smoothed, merge = FALSE, ncol = 2, aspect_ratio = 1)"
  },
  {
    "objectID": "03_analyze.html#noises",
    "href": "03_analyze.html#noises",
    "title": "Analyze objects",
    "section": "\n2.10 Noises",
    "text": "2.10 Noises\npoly_jitter() adds a small amount of noise to a set of coordinates. See base::jitter() for more details.\n\nset.seed(1)\nc1 <- draw_circle(n = 200, plot = FALSE)\nc2 <- draw_circle(n = 200, plot = FALSE) |>\n  poly_jitter(noise_x = 100,\n              noise_y = 100,\n              plot = FALSE)\n\nplot_polygon(list(c1, c2), merge = FALSE)"
  },
  {
    "objectID": "03_analyze.html#adjusting-object-measurements",
    "href": "03_analyze.html#adjusting-object-measurements",
    "title": "Analyze objects",
    "section": "\n3.1 Adjusting object measurements",
    "text": "3.1 Adjusting object measurements\nThe results were stored in img_res. Since there is no scale declared in the example above, we have no idea about the actual area of objects in cm\\(^2\\), only in pixels. In this case, we use get_measures() to adjust pixel measurements to metric units.\nThere are two main ways to adjust object measurements (from pixels to cm, for example). The first is to declare the known area, perimeter or radius of a given object. The measure for the other objects will then be calculated by a simple rule of three. The second is by declaring a known image resolution in dpi(dots per inch). In this case, perimeter, area, and radius will be adjusted by the dpi informed.\n\n3.1.1 Declaring a known value\nSince we know the area of the larger square (object 1), let’s adjust the area of the other objects in the image using this.\n\nget_measures(img_res ,\n             id = 1,\n             area ~ 100) |> \n  t()\n\n-----------------------------------------\nmeasures corrected with:\nobject id: 1\narea     : 100\n-----------------------------------------\nTotal    : 40.009 \nAverage  : 13.336 \n-----------------------------------------\n\n\n                            2        3        4\nid                      2.000    3.000    4.000\nx                    1737.518 1737.571 1737.966\ny                     452.998 1296.354  939.007\narea                   25.041    7.019    7.949\narea_ch                24.958    7.022    7.907\nperimeter              19.983   10.093   11.913\nradius_mean             2.866    1.491    1.668\nradius_min              2.492    1.479    0.988\nradius_max              3.531    1.504    2.224\nradius_sd               0.314    0.004    0.423\ndiam_mean               5.732    2.982    3.335\ndiam_min                4.983    2.957    1.976\ndiam_max                7.062    3.008    4.449\nmajor_axis              5.783    2.990    4.609\nminor_axis              5.773    2.989    2.299\nlength                  6.520    2.996    3.994\nwidth                   6.509    2.999    1.987\nradius_ratio            1.417    1.017    2.252\neccentricity            0.996    0.994    0.348\ntheta                   1.563   -1.547    0.000\nsolidity                1.003    1.000    1.005\nconvexity               0.749    0.905    0.836\nelongation              0.002   -0.001    0.502\ncircularity            15.946   14.512   17.854\ncircularity_haralick    9.127  423.369    3.947\ncircularity_norm        1.273    1.161    1.430\ncoverage                0.107    0.030    0.034\nasm                     0.913    0.829    0.853\ncon                     0.051    0.078    0.069\ncor                     0.731    0.781    0.786\nvar                     1.095    1.178    1.161\nidm                     0.987    0.975    0.979\nsav                    21.901   21.821   21.828\nsva                   475.312  468.297  470.245\nsen                     0.106    0.196    0.156\nent                     0.116    0.220    0.176\ndva                     0.051    0.078    0.069\nden                     0.054    0.090    0.076\nf12                     0.518    0.523    0.555\nf13                     0.279    0.380    0.356\n\n\n\n3.1.2 Declaring the image resolution\nIf the image resolution is known, all measurements will be adjusted accordingly. Let’s see a numerical example with pixels_to_cm(). This function converts the number of pixels(* px *) into cm, considering the image resolution in dpi, as follows: \\(cm = px \\times(2.54 / dpi)\\). As we know the number of pixels of the larger square, its perimeter in cm is given by\n\n# number of pixels for the perimeter of the largest square\n\nls_px <- img_res$results$perimeter[1]\npixels_to_cm(px = ls_px , dpi = 300)\n\n[1] 39.9265\n\n\nThe perimeter of object 1 adjusted by image resolution is very close to the known value (40 cm). Below, the values of all measures are adjusted by declaring the dpi argument in get_measures().\n\nimg_res_cor <- get_measures(img_res, dpi = 300)\n\nt(img_res_cor)\n\n                           1        2        3        4\nid                     1.000    2.000    3.000    4.000\nx                    668.995 1737.518 1737.571 1737.966\ny                    797.992  452.998 1296.354  939.007\narea                  99.812   24.994    7.006    7.934\narea_ch               99.686   24.911    7.008    7.892\nperimeter             39.926   19.964   10.083   11.902\nradius_mean            5.728    2.863    1.489    1.666\nradius_min             4.984    2.489    1.477    0.987\nradius_max             7.057    3.528    1.502    2.222\nradius_sd              0.629    0.314    0.004    0.422\ndiam_mean             11.456    5.726    2.979    3.332\ndiam_min               9.967    4.978    2.955    1.974\ndiam_max              14.114    7.055    3.005    4.445\nmajor_axis            11.546    5.778    2.987    4.604\nminor_axis            11.526    5.768    2.986    2.297\nlength                11.121    6.514    2.994    3.990\nwidth                 11.107    6.503    2.996    1.985\nradius_ratio           1.416    1.417    1.017    2.252\neccentricity           0.997    0.996    0.994    0.348\ntheta                 -0.007    1.563   -1.547    0.000\nsolidity               1.001    1.003    1.000    1.005\nconvexity              0.750    0.749    0.905    0.836\nelongation             0.001    0.002   -0.001    0.502\ncircularity           15.971   15.946   14.512   17.854\ncircularity_haralick   9.111    9.127  423.369    3.947\ncircularity_norm       1.273    1.273    1.161    1.430\ncoverage               0.427    0.107    0.030    0.034\nasm                    0.949    0.913    0.829    0.853\ncon                    0.016    0.051    0.078    0.069\ncor                    0.797    0.731    0.781    0.786\nvar                    1.040    1.095    1.178    1.161\nidm                    0.995    0.987    0.975    0.979\nsav                   21.946   21.901   21.821   21.828\nsva                  478.992  475.312  468.297  470.245\nsen                    0.063    0.106    0.196    0.156\nent                    0.069    0.116    0.220    0.176\ndva                    0.016    0.051    0.078    0.069\nden                    0.024    0.054    0.090    0.076\nf12                    0.674    0.518    0.523    0.555\nf13                    0.260    0.279    0.380    0.356\n\n\n\n3.1.3 Understanding measurements\n\nobject_contour(img) %>% # get the contour of objects\n  poly_mass() %>% # computes the center of mass and minimum and maximum radii\n  plot_mass() # plot the measurements\n\n\n\n\n\nLarger square:\nThe minimum diameter(a = 9.97) can be considered as the side of the square\nThe maximum diameter, given by \\(a \\sqrt {2}\\) can be considered the diagonal of the square (\\(9.97 \\sqrt {2} = 14,099 \\approx 14,105\\)\n\n\n\nt(img_res_cor)\n\n                           1        2        3        4\nid                     1.000    2.000    3.000    4.000\nx                    668.995 1737.518 1737.571 1737.966\ny                    797.992  452.998 1296.354  939.007\narea                  99.812   24.994    7.006    7.934\narea_ch               99.686   24.911    7.008    7.892\nperimeter             39.926   19.964   10.083   11.902\nradius_mean            5.728    2.863    1.489    1.666\nradius_min             4.984    2.489    1.477    0.987\nradius_max             7.057    3.528    1.502    2.222\nradius_sd              0.629    0.314    0.004    0.422\ndiam_mean             11.456    5.726    2.979    3.332\ndiam_min               9.967    4.978    2.955    1.974\ndiam_max              14.114    7.055    3.005    4.445\nmajor_axis            11.546    5.778    2.987    4.604\nminor_axis            11.526    5.768    2.986    2.297\nlength                11.121    6.514    2.994    3.990\nwidth                 11.107    6.503    2.996    1.985\nradius_ratio           1.416    1.417    1.017    2.252\neccentricity           0.997    0.996    0.994    0.348\ntheta                 -0.007    1.563   -1.547    0.000\nsolidity               1.001    1.003    1.000    1.005\nconvexity              0.750    0.749    0.905    0.836\nelongation             0.001    0.002   -0.001    0.502\ncircularity           15.971   15.946   14.512   17.854\ncircularity_haralick   9.111    9.127  423.369    3.947\ncircularity_norm       1.273    1.273    1.161    1.430\ncoverage               0.427    0.107    0.030    0.034\nasm                    0.949    0.913    0.829    0.853\ncon                    0.016    0.051    0.078    0.069\ncor                    0.797    0.731    0.781    0.786\nvar                    1.040    1.095    1.178    1.161\nidm                    0.995    0.987    0.975    0.979\nsav                   21.946   21.901   21.821   21.828\nsva                  478.992  475.312  468.297  470.245\nsen                    0.063    0.106    0.196    0.156\nent                    0.069    0.116    0.220    0.176\ndva                    0.016    0.051    0.078    0.069\nden                    0.024    0.054    0.090    0.076\nf12                    0.674    0.518    0.523    0.555\nf13                    0.260    0.279    0.380    0.356"
  },
  {
    "objectID": "03_analyze.html#texture-features",
    "href": "03_analyze.html#texture-features",
    "title": "Analyze objects",
    "section": "\n3.2 Texture features",
    "text": "3.2 Texture features\nThe function computes 13 Haralick texture features for each object based on a gray-level co-occurrence matrix (Haralick et al. 1979)8. Haralick features depend on the configuration of the parameters har_nbins and har_scales. har_nbins controls the number of bins used to compute the Haralick matrix. A smaller har_nbins can give more accurate estimates of the correlation because the number of events per bin is higher. While a higher value will give more sensitivity. har_scales controls the number of scales used to compute the Haralick features. Since Haralick features compute the correlation of intensities of neighboring pixels, it is possible to identify textures with different scales, e.g., a texture that is repeated every two pixels or 10 pixels. By default, the Haralick features are computed with the R band. To change this default, use the argument har_band. For example, har_band = 2 will compute the features with the green band.\nThe following measures are returned (for more details, see this post)\n\n\nasm: The angular second-moment feature.\n\ncon: The contrast feature\n\ncor: Correlation measures the linear dependency of gray levels of neighboring pixels.\n\nvar: The variance of gray levels pixels.\n\nidm: The Inverse Difference Moment (IDM), i.e., the local homogeneity.\n\nsav: The Sum Average.\n\nsva: The Sum Variance.\n\nsen: Sum Entropy.\n\ndva: Difference Variance.\n\nden: Difference Entropy\n\nf12: Difference Variance.\n\nf13: The angular second-moment feature."
  },
  {
    "objectID": "03_analyze.html#single-image-processing",
    "href": "03_analyze.html#single-image-processing",
    "title": "Analyze objects",
    "section": "\n3.3 Single image processing",
    "text": "3.3 Single image processing\nThe analyze_objects() function calculates a range of measurements that can be used to study the shape and texture of objects, such as leaves. In the following example, I show how to plot the length and width of each leaf in the following image.\n\nleaves <- image_import(\"folhas.jpg\", plot = TRUE)\n\nleaves_meas <-\n  analyze_objects(leaves,\n                  watershed = FALSE)\n\nleaves_cor <- get_measures(leaves_meas, dpi = 300)\n\nt(leaves_cor)\n\n                            1       2\nid                      1.000   2.000\nx                     528.542 234.020\ny                     299.984 825.798\narea                    5.862   3.879\narea_ch                 5.946   4.227\nperimeter              12.157   9.942\nradius_mean             1.591   1.145\nradius_min              0.735   0.838\nradius_max              2.683   1.677\nradius_sd               0.582   0.219\ndiam_mean               3.181   2.290\ndiam_min                1.470   1.675\ndiam_max                5.366   3.353\nmajor_axis              4.843   2.864\nminor_axis              1.563   1.744\nlength                  5.241   3.210\nwidth                   1.602   1.883\nradius_ratio            3.650   2.002\neccentricity            0.136   0.425\ntheta                  -1.057  -0.087\nsolidity                0.986   0.918\nconvexity               0.913   0.791\nelongation              0.694   0.413\ncircularity            25.209  25.478\ncircularity_haralick    2.735   5.219\ncircularity_norm        2.021   2.047\ncoverage                0.104   0.069\nasm                     0.044   0.172\ncon                     1.120   0.495\ncor                     0.942   0.814\nvar                    10.687   2.328\nidm                     0.778   0.814\nsav                    38.905  28.391\nsva                  1449.029 763.014\nsen                     1.337   0.856\nent                     1.573   1.002\ndva                     1.120   0.495\nden                     0.407   0.328\nf12                     0.526   0.352\nf13                     0.822   0.590\n\n# plot width and length\nplot_measures(leaves_cor , measure = \"width\")\nplot_measures(leaves_cor , measure = \"length\", vjust = 50)\n\n\n\n\nHere, we will count the grains in the grains.jpg image. This image has a cyan background and contains 90 soybeans that touch each other. The analyze_objects() function segments the image using the normalized blue index by default, as follows \\(NB =(B /(R + G + B))\\), where R, G and B are the red, green and blue bands. Note that if the image is contained in the default directory, it is not necessary to import it. Just enter the image name in quotes in the img argument(e.g., img = \"grains\").\nIn this example, objects are counted and segmented objects are colored with random colors using the show_segmentation = TRUE argument. Users can set show_contour = FALSE to remove the contour line and identify the objects (in this example, the grains) using the marker = \"id\" arguments. The background color can also be changed with col_background.\n\ncount <-\n  analyze_objects(img = \"grains\",\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\n\n\n\ncount$statistics\n\n       stat       value\n1         n    90.00000\n2  min_area   446.00000\n3 mean_area   675.45556\n4  max_area   842.00000\n5   sd_area    71.65494\n6  sum_area 60791.00000\n\n\n\n# Get the measurements of the object\nget_measures(count) |> \n  head() |> \n  t()\n\n                            1        2        3        4       5       6\nid                      1.000    2.000    3.000    4.000   5.000   6.000\nx                     351.890  824.970  811.263  710.004 807.122 818.892\ny                     411.183  264.736  198.825  262.800 341.979 714.864\narea                  842.000  822.000  738.000  761.000 757.000 742.000\narea_ch               810.000  801.000  712.000  733.000 724.000 714.000\nperimeter             104.497  107.083   98.497  100.255  98.841  98.841\nradius_mean            15.911   15.740   14.876   15.112  15.072  14.906\nradius_min             14.847   13.563   14.129   12.886  13.745  13.775\nradius_max             16.897   17.782   15.379   17.048  16.714  16.272\nradius_sd               0.465    1.201    0.309    1.175   0.771   0.635\ndiam_mean              31.822   31.480   29.752   30.224  30.144  29.812\ndiam_min               29.695   27.126   28.258   25.773  27.489  27.550\ndiam_max               33.793   35.565   30.759   34.097  33.428  32.543\nmajor_axis             33.506   35.775   30.739   34.365  33.056  32.191\nminor_axis             32.027   29.288   30.581   28.228  29.186  29.373\nlength                 33.480   35.413   30.445   33.818  33.005  31.766\nwidth                  32.195   29.731   30.323   27.708  29.399  29.094\nradius_ratio            1.138    1.311    1.088    1.323   1.216   1.181\neccentricity            0.938    0.742    0.975    0.749   0.812   0.864\ntheta                   1.224   -0.327   -1.283   -0.261   0.544  -1.197\nsolidity                1.040    1.026    1.037    1.038   1.046   1.039\nconvexity               0.936    0.923    0.904    0.882   0.867   0.886\nelongation              0.038    0.160    0.004    0.181   0.109   0.084\ncircularity            12.969   13.950   13.146   13.208  12.906  13.166\ncircularity_haralick   34.181   13.107   48.152   12.857  19.539  23.486\ncircularity_norm        1.092    1.179    1.112    1.117   1.091   1.115\ncoverage                0.001    0.001    0.001    0.001   0.001   0.001\nasm                     0.066    0.080    0.059    0.053   0.065   0.058\ncon                     0.850    0.975    0.888    0.917   0.855   0.847\ncor                     0.912    0.883    0.920    0.911   0.909   0.924\nvar                     5.837    5.179    6.566    6.166   5.681   6.564\nidm                     0.733    0.746    0.706    0.724   0.727   0.720\nsav                    32.747   33.476   34.419   33.375  32.003  30.684\nsva                  1014.530 1061.010 1121.793 1052.364 967.498 889.380\nsen                     1.187    1.145    1.247    1.241   1.187   1.223\nent                     1.418    1.356    1.482    1.478   1.407   1.446\ndva                     0.850    0.975    0.888    0.917   0.855   0.847\nden                     0.421    0.429    0.428    0.429   0.416   0.419\nf12                     0.445    0.445    0.461    0.456   0.447   0.465\nf13                     0.745    0.735    0.767    0.763   0.745   0.764\n\n\nIn the following example, we will select objects with an area above the average of all objects using lower_size = 675.\n\n#\n\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                topn_upper = 5)\n\n\n\n\nUsers can also use the topn _* arguments to select the n objects based on the smallest or largest areas. Let’s see how to select the 5 grains with the smallest area, showing the original grains on a blue background. We will also use the my_index argument to choose a custom index to segment the image. Just for comparison, we will explicitly set the normalized blue index by calling my_index = \"B /(R + G + B)\".\n\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                topn_lower = 5,\n                col_background = \"black\",\n                index = \"B /(R + G + B)\") # normalized blue(NB)\n\nIndex 'B /(R + G + B)' is not available. Trying to compute your own index."
  },
  {
    "objectID": "03_analyze.html#batch-processing",
    "href": "03_analyze.html#batch-processing",
    "title": "Analyze objects",
    "section": "\n3.4 Batch processing",
    "text": "3.4 Batch processing\nIn image analysis, it is often necessary to process more than one image. For example, in plant breeding, the number of grains per plant(eg wheat) is often used in the indirect selection of high-yielding plants. In pliman, batch processing can be done when the user declares the pattern argument.\nTo speed up processing time, especially for large numbers of images, the parallel = TRUE argument can be used. In this case, images are processed asynchronously (in parallel) in separate R sessions running in the background on the same machine. The number of sections is set to 50% of available cores. This number can be explicitly controlled with the workers argument.\n\nsystem.time(\n  list_res <- analyze_objects(pattern = \"img_sb\", show_image = FALSE)\n)\n\nProcessing image img_sb_50_1 |===                                | 8% 00:00:00 \nProcessing image img_sb_50_10 |=====                             | 15% 00:00:01 \nProcessing image img_sb_50_11 |========                          | 23% 00:00:01 \nProcessing image img_sb_50_12 |==========                        | 31% 00:00:02 \nProcessing image img_sb_50_13 |=============                     | 38% 00:00:02 \nProcessing image img_sb_50_2 |================                   | 46% 00:00:03 \nProcessing image img_sb_50_3 |===================                | 54% 00:00:04 \nProcessing image img_sb_50_4 |======================             | 62% 00:00:05 \nProcessing image img_sb_50_5 |========================           | 69% 00:00:06 \nProcessing image img_sb_50_6 |===========================        | 77% 00:00:07 \nProcessing image img_sb_50_7 |==============================     | 85% 00:00:08 \nProcessing image img_sb_50_8 |================================   | 92% 00:00:09 \nProcessing image img_sb_50_9 |===================================| 100% 00:00:09 \n--------------------------------------------\n        Image Objects\n  img_sb_50_1     100\n img_sb_50_10      29\n img_sb_50_11      23\n img_sb_50_12      15\n img_sb_50_13       7\n  img_sb_50_2      90\n  img_sb_50_3      83\n  img_sb_50_4      75\n  img_sb_50_5      70\n  img_sb_50_6      60\n  img_sb_50_7      57\n  img_sb_50_8      48\n  img_sb_50_9      36\n--------------------------------------------\n\n\nDone!\n\n\n  usuário   sistema decorrido \n     9.83      0.70     10.53 \n\n# parallel processing\n# 6 multiple sections (50% of my pc's cores)\nsystem.time(\n  list_res <-\n    analyze_objects(pattern = \"img_sb\",\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\nImage processing using multiple sessions (6). Please wait.\n\n\n--------------------------------------------\n        Image Objects\n  img_sb_50_1     100\n img_sb_50_10      29\n img_sb_50_11      23\n img_sb_50_12      15\n img_sb_50_13       7\n  img_sb_50_2      90\n  img_sb_50_3      83\n  img_sb_50_4      75\n  img_sb_50_5      70\n  img_sb_50_6      60\n  img_sb_50_7      57\n  img_sb_50_8      48\n  img_sb_50_9      36\n--------------------------------------------\n\n\nDone!\n\n\n  usuário   sistema decorrido \n     0.06      0.00     14.76"
  },
  {
    "objectID": "03_analyze.html#known-resolution",
    "href": "03_analyze.html#known-resolution",
    "title": "Analyze objects",
    "section": "\n8.1 Known resolution",
    "text": "8.1 Known resolution\n\nleaves <- image_import(image = \"ref_leaves.jpg\", plot = TRUE)\n\n\n\naf <-\n  analyze_objects(leaves,\n                  index = \"B-G\",\n                  watershed = FALSE,\n                  col_background = \"black\",\n                  marker = \"id\")\n\n# using images with known resolution\naf_cor <- get_measures(af, dpi = 45.8)\nplot_measures(af_cor ,\n              measure = \"area\",\n              vjust = -20,\n              col = \" cyan \")\n\n# declaring the measure of a known object\naf_cor2 <- \n  get_measures(af,\n               id = 18,\n               measure = area ~ 25)\n\n-----------------------------------------\nmeasures corrected with:\nobject id: 18\narea     : 25\n-----------------------------------------\nTotal    : 796.214 \nAverage  : 36.192 \n-----------------------------------------\n\nplot_measures(af_cor2 ,\n              measure = \"area\",\n              vjust = -35,\n              col = \"salmon\")"
  },
  {
    "objectID": "03_analyze.html#reference-object-dev-version",
    "href": "03_analyze.html#reference-object-dev-version",
    "title": "Analyze objects",
    "section": "\n8.2 Reference object (dev version)",
    "text": "8.2 Reference object (dev version)\n\n8.2.1 Single images\nThe reference argument can now be used to correct the object measures even when images with different shooting distances are used. This differs from the previous example (declaring the object with the known area) in a subtle, but crucial aspect: when reference is informed, batch processing can be used! In this example, the leaf area of the ref_leaves image is quantified and corrected considering a 5 x 5 (25 cm\\(^2\\)) red square as the reference object. When reference = TRUE is informed in analyze_objects() the function will perform a two-step process of object segmentation; so, the time processing is a bit slower.\nThe first step consists in segmenting the foreground (leaves and reference object) from the background. To do that, an image index is used and can be declared in the back_fore_index. The default (back_fore_index = \"R/(G/B)\") is optimized to segment white backgrounds from green leaves and a blue reference object. Let’s see how this index performs in this example.\n\nlibrary(pliman)\nimg <- image_import(\"ref_leaves.jpg\", plot = TRUE)\n\n\n\nind <- image_index(img, index = \"R/(G/B)\", show_image = FALSE)[[1]]\n\nIndex 'R/(G/B)' is not available. Trying to compute your own index.\n\nbin <- image_binary(img, index = \"R/(G/B)\", show_image = FALSE)[[1]]\n\nIndex 'R/(G/B)' is not available. Trying to compute your own index.\n\nimage_combine(ind, bin)\n\n\n\n\nThis index definitively is not the better option in this case. Will some other available index be better?\n\nimage_index(img, index = \"all\")\n\n\n\n\nThe B-G index seems to be a good candidate.\n\nind <- image_index(img, index = \"B-G\", show_image = FALSE)[[1]]\nseg1 <- image_segment(img, index = \"B-G\", show_image = FALSE)\nimage_combine(ind, seg1)\n\n\n\n\nGood job! now, we have the background removed. The next step is to segment the objects and the reference template. We basically need to repeat the previous step isolating the reference.\n\n# see the better index\nimage_index(seg1, index = \"all\")\n\n\n\n\nThe R-G is a good candidate. So, I’ll perform the second segmentation using this index.\n\nseg2 <- \n  image_binary(seg1,\n               index = \"R-G\")\n\n\n\n# number of pixels in the reference object\nlength(which(seg2$`R-G` != 1))\n\n[1] 8147\n\n\nNow that we know the indexes to be used for each segmentation, we can use the function analyze_objects to get the corrected measures based on the reference object.\n\nres1 <- \n  analyze_objects(img, \n                  reference = TRUE,\n                  reference_area = 25,\n                  back_fore_index = \"B-G\",\n                  fore_ref_index = \"R-G\",\n                  watershed = FALSE,\n                  marker = \"area\")\n\n# plot the measures corrected by the image resolution\nplot_measures(af_cor ,\n              measure = \"area\",\n              vjust = -20,\n              col = \" cyan \")\n\n\n\n\n\n8.2.2 Multiple images\nIf users need to analyze multiple images from the same sample, the images must share the same filename prefix, which is defined as the part of the filename that precedes the first hyphen (-) or underscore (_). Then, when using get_measures(), measurements from leaf images called, for example, F1-1.jpeg, F1_2.jpeg and F1-3.jpeg will be combined into a single image (F1), displayed in the merge object. This is useful, for example, for analyzing large sheets that need to be split into multiple images or multiple sheets belonging to the same sample that cannot be scanned into a single image.\nIn the following example, 36 images will be analyzed. These images contain flax leaves from 12 evaluation dates, with three replications10. Note that to ensure that all images are processed, all images must share a common pattern, in this case (\"A\"). Here, I will use the pattern = \"A\" to indicate that all images with this pattern name should be merged.\n\nres <-\n  analyze_objects(pattern = \"A\",\n                  dir_original = \"linhaca\",\n                  reference = TRUE,\n                  reference_area = 20,\n                  watershed = FALSE,\n                  filter = 2,\n                  parallel = TRUE)\n\nImage processing using multiple sessions (6). Please wait.\n\n\n--------------------------------------------\n     Image Objects\n   A1_28_1      18\n   A1_28_2      29\n   A1_28_3      28\n  A10_90_1     149\n  A10_90_2     116\n  A10_90_3      77\n  A11_98_1     133\n  A11_98_2     154\n  A11_98_3     119\n A12_105_1     111\n A12_105_2     127\n A12_105_3     155\n   A2_32_1      24\n   A2_32_2      25\n   A2_32_3      31\n   A3_42_1      39\n   A3_42_2      47\n   A3_42_3      54\n   A4_46_1      57\n   A4_46_2      38\n   A4_46_3      56\n   A5_55_1      53\n   A5_55_2      74\n   A5_55_3      63\n   A6_63_1      68\n   A6_63_2     105\n   A6_63_3      83\n   A7_70_1      98\n   A7_70_2     111\n   A7_70_3     112\n   A8_76_1     113\n   A8_76_2     116\n   A8_76_3     113\n   A9_83_1     119\n   A9_83_2      89\n   A9_83_3     100\n--------------------------------------------\n\n\nDone!\n\nmerged <- get_measures(res)\n\nNote that the merged is a list with three objects:\n\n\nresults: a data frame that contains the measurements of each individual object (in this case, an individual leaf) of each analyzed image.\n\n\nmerged$results |> head(n = 5) |> t()\n\n                     1         2         3         4         5        \nimg                  \"A1_28_1\" \"A1_28_1\" \"A1_28_1\" \"A1_28_1\" \"A1_28_1\"\nid                   \"1\"       \"2\"       \"3\"       \"4\"       \"5\"      \nx                    \"373.184\" \"422.529\" \"163.995\" \"127.295\" \"267.451\"\ny                    \"316.718\" \"320.344\" \"350.678\" \"387.751\" \"400.642\"\narea                 \"0.116\"   \"0.159\"   \"0.157\"   \"0.195\"   \"0.202\"  \narea_ch              \"0.151\"   \"0.190\"   \"0.151\"   \"0.193\"   \"0.226\"  \nperimeter            \"2.095\"   \"2.115\"   \"1.707\"   \"2.298\"   \"2.131\"  \nradius_mean          \"0.249\"   \"0.262\"   \"0.230\"   \"0.302\"   \"0.263\"  \nradius_min           \"0.010\"   \"0.065\"   \"0.117\"   \"0.099\"   \"0.116\"  \nradius_max           \"0.478\"   \"0.453\"   \"0.368\"   \"0.517\"   \"0.430\"  \nradius_sd            \"0.126\"   \"0.111\"   \"0.076\"   \"0.130\"   \"0.091\"  \ndiam_mean            \"0.499\"   \"0.523\"   \"0.461\"   \"0.603\"   \"0.526\"  \ndiam_min             \"0.019\"   \"0.129\"   \"0.233\"   \"0.198\"   \"0.231\"  \ndiam_max             \"0.956\"   \"0.905\"   \"0.736\"   \"1.034\"   \"0.859\"  \nmajor_axis           \"0.981\"   \"0.908\"   \"0.727\"   \"1.046\"   \"0.838\"  \nminor_axis           \"0.221\"   \"0.264\"   \"0.281\"   \"0.243\"   \"0.341\"  \nlength               \"0.909\"   \"0.872\"   \"0.723\"   \"1.025\"   \"0.802\"  \nwidth                \"0.233\"   \"0.310\"   \"0.283\"   \"0.238\"   \"0.427\"  \nradius_ratio         \"49.553\"  \" 7.015\"  \" 3.155\"  \" 5.228\"  \" 3.716\" \neccentricity         \"0.070\"   \"0.117\"   \"0.220\"   \"0.080\"   \"0.250\"  \ntheta                \"-1.485\"  \" 1.345\"  \" 0.064\"  \"-0.582\"  \"-1.202\" \nsolidity             \"0.768\"   \"0.836\"   \"1.042\"   \"1.010\"   \"0.893\"  \nconvexity            \"0.552\"   \"0.554\"   \"0.916\"   \"0.915\"   \"0.743\"  \nelongation           \"0.744\"   \"0.645\"   \"0.609\"   \"0.768\"   \"0.468\"  \ncircularity          \"37.928\"  \"28.087\"  \"18.532\"  \"27.089\"  \"22.494\" \ncircularity_haralick \"1.985\"   \"2.361\"   \"3.026\"   \"2.316\"   \"2.901\"  \ncircularity_norm     \"3.495\"   \"2.486\"   \"1.608\"   \"2.347\"   \"1.939\"  \ncoverage             \"0.001\"   \"0.002\"   \"0.002\"   \"0.002\"   \"0.002\"  \nasm                  \"0.083\"   \"0.132\"   \"0.214\"   \"0.161\"   \"0.136\"  \ncon                  \"2.799\"   \"2.712\"   \"1.913\"   \"2.177\"   \"2.307\"  \ncor                  \"0.658\"   \"0.500\"   \"0.494\"   \"0.578\"   \"0.679\"  \nvar                  \"5.087\"   \"3.714\"   \"2.889\"   \"3.581\"   \"4.597\"  \nidm                  \"0.660\"   \"0.736\"   \"0.799\"   \"0.743\"   \"0.739\"  \nsav                  \" 9.204\"  \" 8.431\"  \"10.223\"  \"10.163\"  \"11.343\" \nsva                  \" 79.651\" \" 64.489\" \" 94.518\" \" 93.948\" \"119.774\"\nsen                  \"1.073\"   \"0.924\"   \"0.795\"   \"0.900\"   \"0.965\"  \nent                  \"1.466\"   \"1.196\"   \"0.993\"   \"1.135\"   \"1.242\"  \ndva                  \"2.799\"   \"2.712\"   \"1.913\"   \"2.177\"   \"2.307\"  \nden                  \"0.586\"   \"0.503\"   \"0.429\"   \"0.498\"   \"0.499\"  \nf12                  \"0.246\"   \"0.242\"   \"0.263\"   \"0.235\"   \"0.270\"  \nf13                  \"0.580\"   \"0.529\"   \"0.509\"   \"0.511\"   \"0.567\"  \n\n\n\n\nsummary : a data frame that contains the summary of the results, containing the number of objects in each image (n) the sum, mean and standard deviation of the area of each image, as well as the average value for all others measurements (perimeter, radius, etc.)\n\n\nmerged$summary |> head(n = 5) |> t()\n\n                     1            2            3            4            \nimg                  \"imgA1_28_1\" \"imgA1_28_2\" \"imgA1_28_3\" \"imgA10_90_1\"\nn                    \" 18\"        \" 29\"        \" 28\"        \"149\"        \narea_sum             \"  2.571\"    \"  6.294\"    \"  7.048\"    \"172.420\"    \narea_mean            \"0.143\"      \"0.217\"      \"0.252\"      \"1.157\"      \narea_sd              \"0.058\"      \"0.075\"      \"0.095\"      \"0.441\"      \narea_ch              \"0.163\"      \"0.219\"      \"0.274\"      \"1.217\"      \nperimeter            \"2.005\"      \"2.717\"      \"2.715\"      \"6.558\"      \nradius_mean          \"0.248\"      \"0.343\"      \"0.338\"      \"0.812\"      \nradius_min           \"0.076\"      \"0.079\"      \"0.107\"      \"0.187\"      \nradius_max           \"0.434\"      \"0.625\"      \"0.602\"      \"1.511\"      \nradius_sd            \"0.106\"      \"0.165\"      \"0.148\"      \"0.402\"      \ndiam_mean            \"0.497\"      \"0.685\"      \"0.677\"      \"1.625\"      \ndiam_min             \"0.152\"      \"0.158\"      \"0.214\"      \"0.374\"      \ndiam_max             \"0.869\"      \"1.251\"      \"1.204\"      \"3.023\"      \nmajor_axis           \"0.872\"      \"1.278\"      \"1.188\"      \"3.070\"      \nminor_axis           \"0.250\"      \"0.225\"      \"0.294\"      \"0.511\"      \nlength               \"0.837\"      \"1.232\"      \"1.176\"      \"2.978\"      \nwidth                \"0.263\"      \"0.228\"      \"0.301\"      \"0.517\"      \nradius_ratio         \" 8.777\"     \"10.306\"     \" 5.729\"     \" 9.602\"     \neccentricity         \"0.132\"      \"0.052\"      \"0.096\"      \"0.044\"      \ntheta                \" 0.011\"     \"-0.105\"     \" 0.261\"     \" 0.070\"     \nsolidity             \"0.954\"      \"0.987\"      \"0.988\"      \"1.018\"      \nconvexity            \"0.769\"      \"0.773\"      \"0.850\"      \"0.858\"      \nelongation           \"0.690\"      \"0.813\"      \"0.747\"      \"0.830\"      \ncircularity          \"30.133\"     \"36.250\"     \"29.783\"     \"38.436\"     \ncircularity_haralick \"2.391\"      \"2.090\"      \"2.320\"      \"2.025\"      \ncircularity_norm     \"2.725\"      \"3.221\"      \"2.547\"      \"3.410\"      \ncoverage             \"0.001\"      \"0.001\"      \"0.001\"      \"0.001\"      \nasm                  \"0.141\"      \"0.165\"      \"0.144\"      \"0.208\"      \ncon                  \"2.407\"      \"2.376\"      \"2.175\"      \"2.664\"      \ncor                  \"0.547\"      \"0.564\"      \"0.579\"      \"0.361\"      \nvar                  \"3.784\"      \"3.829\"      \"3.795\"      \"3.346\"      \nidm                  \"0.711\"      \"0.717\"      \"0.730\"      \"0.737\"      \nsav                  \"11.336\"     \"11.796\"     \"11.258\"     \" 9.961\"     \nsva                  \"120.987\"    \"130.715\"    \"117.729\"    \" 99.047\"    \nsen                  \"0.935\"      \"0.915\"      \"0.924\"      \"0.820\"      \nent                  \"1.240\"      \"1.210\"      \"1.197\"      \"1.088\"      \ndva                  \"2.407\"      \"2.376\"      \"2.175\"      \"2.664\"      \nden                  \"0.518\"      \"0.519\"      \"0.495\"      \"0.499\"      \nf12                  \"0.228\"      \"0.220\"      \"0.225\"      \"0.166\"      \nf13                  \"0.512\"      \"0.501\"      \"0.506\"      \"0.416\"      \n                     5            \nimg                  \"imgA10_90_2\"\nn                    \"116\"        \narea_sum             \"119.335\"    \narea_mean            \"1.029\"      \narea_sd              \"0.338\"      \narea_ch              \"1.136\"      \nperimeter            \"6.390\"      \nradius_mean          \"0.780\"      \nradius_min           \"0.164\"      \nradius_max           \"1.466\"      \nradius_sd            \"0.392\"      \ndiam_mean            \"1.559\"      \ndiam_min             \"0.329\"      \ndiam_max             \"2.932\"      \nmajor_axis           \"2.997\"      \nminor_axis           \"0.497\"      \nlength               \"2.881\"      \nwidth                \"0.505\"      \nradius_ratio         \"10.337\"     \neccentricity         \"0.047\"      \ntheta                \" 0.037\"     \nsolidity             \"0.995\"      \nconvexity            \"0.855\"      \nelongation           \"0.825\"      \ncircularity          \"40.106\"     \ncircularity_haralick \"2.009\"      \ncircularity_norm     \"3.593\"      \ncoverage             \"0.001\"      \nasm                  \"0.180\"      \ncon                  \"2.563\"      \ncor                  \"0.327\"      \nvar                  \"3.034\"      \nidm                  \"0.723\"      \nsav                  \" 9.046\"     \nsva                  \" 75.195\"    \nsen                  \"0.824\"      \nent                  \"1.104\"      \ndva                  \"2.563\"      \nden                  \"0.510\"      \nf12                  \"0.146\"      \nf13                  \"0.395\"      \n\n\nThe area_sum of img A1_28_1 is the sum of the 18 leaves.\n\nsum(merged$results$area[1:18])\n\n[1] 2.57\n\n\n\n\nmerge: a data frame that contains the results merged by image prefix (In this case, A1 to A12).\n\n\nmerged$merge |> head(n = 5) |> t()\n\n                     1         2         3         4         5        \nimg                  \"imgA1\"   \"imgA10\"  \"imgA11\"  \"imgA12\"  \"imgA2\"  \nn                    \" 75\"     \"342\"     \"406\"     \"393\"     \" 80\"    \narea_sum             \" 15.913\" \"364.917\" \"479.003\" \"370.213\" \" 21.485\"\narea_mean            \"0.204\"   \"1.045\"   \"1.205\"   \"0.961\"   \"0.269\"  \narea_sd              \"0.076\"   \"0.296\"   \"0.447\"   \"0.341\"   \"0.120\"  \narea_ch              \"0.218\"   \"1.098\"   \"1.256\"   \"0.991\"   \"0.305\"  \nperimeter            \"2.479\"   \"6.578\"   \"6.773\"   \"6.175\"   \"2.836\"  \nradius_mean          \"0.310\"   \"0.807\"   \"0.832\"   \"0.761\"   \"0.351\"  \nradius_min           \"0.087\"   \"0.163\"   \"0.186\"   \"0.155\"   \"0.097\"  \nradius_max           \"0.554\"   \"1.522\"   \"1.556\"   \"1.429\"   \"0.626\"  \nradius_sd            \"0.140\"   \"0.410\"   \"0.414\"   \"0.385\"   \"0.157\"  \ndiam_mean            \"0.620\"   \"1.614\"   \"1.663\"   \"1.523\"   \"0.702\"  \ndiam_min             \"0.175\"   \"0.327\"   \"0.372\"   \"0.309\"   \"0.194\"  \ndiam_max             \"1.108\"   \"3.044\"   \"3.111\"   \"2.857\"   \"1.253\"  \nmajor_axis           \"1.113\"   \"3.108\"   \"3.149\"   \"2.948\"   \"1.253\"  \nminor_axis           \"0.256\"   \"0.464\"   \"0.509\"   \"0.431\"   \"0.304\"  \nlength               \"1.082\"   \"3.003\"   \"3.071\"   \"2.819\"   \"1.218\"  \nwidth                \"0.264\"   \"0.468\"   \"0.515\"   \"0.432\"   \"0.321\"  \nradius_ratio         \" 8.271\"  \"10.634\"  \"10.306\"  \" 9.934\"  \"10.012\" \neccentricity         \"0.093\"   \"0.038\"   \"0.047\"   \"0.041\"   \"0.102\"  \ntheta                \"0.055\"   \"0.026\"   \"0.102\"   \"0.197\"   \"0.090\"  \nsolidity             \"0.976\"   \"1.009\"   \"1.004\"   \"1.008\"   \"0.969\"  \nconvexity            \"0.797\"   \"0.853\"   \"0.840\"   \"0.834\"   \"0.831\"  \nelongation           \"0.750\"   \"0.844\"   \"0.831\"   \"0.841\"   \"0.733\"  \ncircularity          \"32.055\"  \"42.404\"  \"40.067\"  \"40.807\"  \"30.634\" \ncircularity_haralick \"2.267\"   \"1.979\"   \"2.020\"   \"1.998\"   \"2.307\"  \ncircularity_norm     \"2.831\"   \"3.777\"   \"3.531\"   \"3.618\"   \"2.642\"  \ncoverage             \"0.001\"   \"0.001\"   \"0.001\"   \"0.001\"   \"0.002\"  \nasm                  \"0.150\"   \"0.170\"   \"0.156\"   \"0.134\"   \"0.150\"  \ncon                  \"2.320\"   \"2.464\"   \"2.395\"   \"2.643\"   \"2.646\"  \ncor                  \"0.563\"   \"0.394\"   \"0.504\"   \"0.546\"   \"0.543\"  \nvar                  \"3.803\"   \"3.213\"   \"3.635\"   \"4.226\"   \"4.120\"  \nidm                  \"0.719\"   \"0.718\"   \"0.720\"   \"0.691\"   \"0.724\"  \nsav                  \"11.463\"  \" 9.342\"  \" 9.938\"  \"11.514\"  \"10.155\" \nsva                  \"123.144\" \" 85.159\" \"104.154\" \"125.472\" \" 98.704\"\nsen                  \"0.924\"   \"0.856\"   \"0.901\"   \"0.949\"   \"0.927\"  \nent                  \"1.216\"   \"1.142\"   \"1.183\"   \"1.272\"   \"1.207\"  \ndva                  \"2.320\"   \"2.464\"   \"2.395\"   \"2.643\"   \"2.646\"  \nden                  \"0.510\"   \"0.510\"   \"0.508\"   \"0.543\"   \"0.511\"  \nf12                  \"0.224\"   \"0.164\"   \"0.201\"   \"0.196\"   \"0.222\"  \nf13                  \"0.506\"   \"0.422\"   \"0.473\"   \"0.484\"   \"0.505\"  \n\n\nBelow, I will fit a non-linear model (Logistic) to model the leaf area evolution across the crop cycle.\n\nCodelibrary(tidyverse)\n\ndf_plot <- \n  merged$summary |> \n  separate_col(img, \n               into = c(\"avaliacao\", \"das\", \"bloco\")) |> \n  mutate(das = as.numeric(das))\n\n# plot \n\nmy_theme <- \n  theme_bw(base_size = 14) +\n  theme(panel.grid.major = element_blank())\n\n# leaf area\nformula <- y ~ b1/(1 + exp(b2 - b3 * x))\n\nggplot(df_plot, aes(das, area_sum)) + \n  geom_smooth(method = \"nls\",\n              method.args = list(formula = formula,\n                                 start = c(b1 = 248,\n                                           b2 = 6,\n                                           b3 = 0.07)),\n              se = FALSE,\n              color = \"red\") +\n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.5) +\n  stat_summary(fun = mean,\n               geom = \"point\",\n               col = \"blue\",\n               size = 3) +\n  scale_x_continuous(breaks = unique(df_plot$das)) +\n  scale_y_continuous(breaks = seq(0, 150, by = 25)) +\n  labs(x = \"Days after sowing\",\n       y = expression(Área~foliar~média~(cm^2~planta^{-1}))) +\n  my_theme\n# number of leaves\nformula <- y ~ b1/(1 + exp(b2 - b3 * x))\n\nggplot(df_plot, aes(das, n)) + \n  geom_smooth(method = \"nls\",\n              method.args = list(formula = formula,\n                                 start = c(b1 = 188,\n                                           b2 = 3,\n                                           b3 = 0.05)),\n              se = FALSE,\n              color = \"red\") +\n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.5) +\n  stat_summary(fun = mean,\n               geom = \"point\",\n               col = \"blue\",\n               size = 3) +\n  scale_x_continuous(breaks = unique(df_plot$das)) +\n  scale_y_continuous(breaks = seq(0, 150, by = 25)) +\n  labs(x = \"Days after sowing\",\n       y = \"Number of leaves per plant\") +\n  my_theme"
  },
  {
    "objectID": "03_analyze.html#filling-holes",
    "href": "03_analyze.html#filling-holes",
    "title": "Analyze objects",
    "section": "\n8.3 Filling ‘holes’",
    "text": "8.3 Filling ‘holes’\nAn important aspect to consider in leaf area measures is when leaves present ‘holes’. This can occur, for example, by the attack of pests. In this case, the area would have to be considered, because it was there! The image bellow is used as an example.\n\nholes <- image_import(\"holes.jpg\", plot = TRUE)\n\n\n\n\nIn this case, the missing area will not be computed using the default settings of analyze_objects(). To include this area as the leaf area, we can use the argument fill_hull(). Note that this will only work for missing areas within a closed object. If the missing area includes the original leaf contour, there is no (yet available) way to reconstruct the leaf perimeter.\n\naf <-\n  analyze_objects(holes,\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\n# fill the missing area\naf2 <-\n  analyze_objects(holes,\n                  fill_hull = TRUE, # fill ' holes '\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  prefix = \"proc2_\",\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\nimgs <- image_import(pattern = \"proc\", path = tempdir())\nimage_combine(imgs)\n\n\n\n\nWe can simply use the ratio between proc_img and proc_img2 to compute the injured area in this leaflet.\n\n# percent of the injured area\n100 - 86432 / 99186 * 100\n\n[1] 12.85867"
  },
  {
    "objectID": "03_analyze.html#compound-leaves",
    "href": "03_analyze.html#compound-leaves",
    "title": "Analyze objects",
    "section": "\n8.4 Compound leaves",
    "text": "8.4 Compound leaves\nA simple leaf blade is undivided. The blade of a compound leaf is divided into several leaflets. In the following examples, I will show how to analyze simple and compound leaves with analyze_objects(), mainly if the goal is to obtain the measures for each leaf (e.g., mean area), where the number of objects (leaves) will influence the results.\nThe following images by Daniel Saueressig were obtained from the Sistema de Identificação Dendrológica Online - Floresta Ombrófila Mista11 and show examples of simple and compound leaves.\n\nimgs <- \n  image_import(c(\"simple.jpg\", \"compound.jpg\")) |> \n  image_horizontal()\nimage_combine(imgs)\n\n\n\n\nAnalyzing non-touching simple leaves is fairly simple. We already did that. The squares in the background have 4 cm\\(^2\\). With this information, it is possible to obtain the image resolution with dpi(simple), which will be useful to adjust the measures. In this case, the estimated dpi is 48.65.\n\nsimple <- imgs$simple.jpg\nsarea <- analyze_objects(simple, marker = \"id\")\n\n\n\n\nNote that with the default settings, the simple leaf was partitioned into small, segmented leaves. This can be solved by either using object_size = \"large\" or watershed = FALSE, to omit the watershed segmentation algorithm. The last is used here.\n\nsarea <- \n  analyze_objects(simple,\n                  watershed = FALSE,\n                  marker = \"id\",\n                  show_chull = TRUE,\n                  contour_size = 6)\n\n\n\nsarea_cor <- get_measures(sarea, dpi = 48.65)\nsarea_cor |> t()\n\n                           2       3\nid                     2.000   3.000\nx                    183.241 178.843\ny                     68.637 184.643\narea                  20.035  41.417\narea_ch               31.852  56.267\nperimeter             31.560  41.287\nradius_mean            3.030   4.285\nradius_min             1.095   1.070\nradius_max             5.717   7.953\nradius_sd              1.215   1.801\ndiam_mean              6.060   8.570\ndiam_min               2.190   2.139\ndiam_max              11.433  15.906\nmajor_axis             9.237  13.661\nminor_axis             3.194   4.225\nlength                11.068  15.474\nwidth                  4.698   6.041\nradius_ratio           5.220   7.435\neccentricity           0.147   0.133\ntheta                 -0.018  -0.082\nsolidity               0.629   0.736\nconvexity              0.779   0.675\nelongation             0.576   0.610\ncircularity           49.715  41.157\ncircularity_haralick   2.493   2.379\ncircularity_norm       4.106   3.353\ncoverage               0.088   0.182\nasm                    0.048   0.043\ncon                    3.761   1.671\ncor                    0.811   0.845\nvar                   10.970   6.401\nidm                    0.647   0.663\nsav                   22.952  23.134\nsva                  507.260 499.010\nsen                    1.246   1.246\nent                    1.663   1.618\ndva                    3.761   1.671\nden                    0.603   0.516\nf12                    0.287   0.319\nf13                    0.654   0.677\n\n\nFor compound leaves, if the watershed segmentation is used, leaflets will probably be considered as different leaves, as can be seen below.\n\ncompound <- imgs$compound.jpg\ncarea <- \n  analyze_objects(compound,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\n\n\n\n\nTherefore, using watershed = FALSE will solve this problem, since all leaflets connected by at least one pixel will be considered part of the same leaf.\n\ncarea <- \n  analyze_objects(compound,\n                  watershed = FALSE,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  show_chull = TRUE,\n                  marker = \"id\")\n\n\n\ncarea_cor <- get_measures(carea, dpi = 49.5)\ncarea_cor |> t()\n\n                           3       4\nid                     3.000   4.000\nx                     90.218 243.787\ny                    113.124 114.593\narea                  18.895  15.890\narea_ch               43.161  33.168\nperimeter             54.501  48.779\nradius_mean            2.548   2.254\nradius_min             0.056   0.018\nradius_max             5.940   4.964\nradius_sd              1.260   1.148\ndiam_mean              5.097   4.509\ndiam_min               0.112   0.035\ndiam_max              11.879   9.929\nmajor_axis             8.404   6.954\nminor_axis             6.577   5.552\nlength                 9.339   8.135\nwidth                  7.142   6.435\nradius_ratio         105.791 280.481\neccentricity           0.656   0.506\ntheta                 -0.862   1.308\nsolidity               0.438   0.479\nconvexity              0.383   0.412\nelongation             0.235   0.209\ncircularity          157.203 149.739\ncircularity_haralick   2.023   1.964\ncircularity_norm      13.363  12.783\ncoverage               0.086   0.072\nasm                    0.054   0.047\ncon                    1.100   2.223\ncor                    0.838   0.753\nvar                    4.386   5.507\nidm                    0.711   0.666\nsav                   18.751  27.342\nsva                  322.551 700.322\nsen                    1.141   1.179\nent                    1.448   1.559\ndva                    1.100   2.223\nden                    0.456   0.543\nf12                    0.328   0.279\nf13                    0.658   0.630"
  },
  {
    "objectID": "03_analyze.html#functions",
    "href": "03_analyze.html#functions",
    "title": "Analyze objects",
    "section": "\n10.1 Functions",
    "text": "10.1 Functions\nThe functions were adapted from Claude (2088)12\n\nShow functions# Core function for elliptical Fourier analyses\n# Elliptical Fourier transform (and its normalization)\n# adapted from https://momx.github.io/Momocs/reference/fourier.html\nfourier <- function(x, nhm = 10, ...) {\n  coo <- poly_check(x) |> poly_unclose()\n  nr <- nrow(coo)\n  if (nhm * 2 > nr) {\n    nhm <- floor(nr/2)\n    if (.is_verbose()) {\n      message(\"'nhm' must be lower than half the number of points, and has been set to \", nhm, \"harmonics\")\n    }\n  }\n  if (nhm == -1) {\n    nhm = floor(nr/2)\n    if (.is_verbose()) {\n      message(\"the number of harmonics used has been set to: \", nhm)\n    }\n  }\n  Dx <- coo[, 1] - coo[, 1][c(nr, (1:(nr - 1)))]\n  Dy <- coo[, 2] - coo[, 2][c(nr, (1:(nr - 1)))]\n  Dt <- sqrt(Dx^2 + Dy^2)\n  Dt[Dt < 1e-10] <- 1e-10  # to avoid Nan\n  t1 <- cumsum(Dt)\n  t1m1 <- c(0, t1[-nr])\n  T <- sum(Dt)\n  an <- bn <- cn <- dn <- numeric(nhm)\n  for (i in 1:nhm) {\n    Ti <- (T/(2 * pi^2 * i^2))\n    r <- 2 * i * pi\n    an[i] <- Ti * sum((Dx/Dt) * (cos(r * t1/T) - cos(r * t1m1/T)))\n    bn[i] <- Ti * sum((Dx/Dt) * (sin(r * t1/T) - sin(r * t1m1/T)))\n    cn[i] <- Ti * sum((Dy/Dt) * (cos(r * t1/T) - cos(r * t1m1/T)))\n    dn[i] <- Ti * sum((Dy/Dt) * (sin(r * t1/T) - sin(r * t1m1/T)))\n  }\n  ao <- 2 * sum(coo[, 1] * Dt/T)\n  co <- 2 * sum(coo[, 2] * Dt/T)\n  return(list(an = an, bn = bn, cn = cn, dn = dn, ao = ao,\n              co = co,\n              nr = nr,\n              coords = coo))\n}\n\n# Normalized coefficients\nfourier_norm <- function(ef, start = FALSE) {\n  A1 <- ef$an[1]\n  B1 <- ef$bn[1]\n  C1 <- ef$cn[1]\n  D1 <- ef$dn[1]\n  nhm <- length(ef$an)\n  theta <- 0.5 * atan(2 * (A1 * B1 + C1 * D1)/(A1^2 + C1^2 -\n                                                 B1^2 - D1^2))%%pi\n  phaseshift <- matrix(c(cos(theta), sin(theta), -sin(theta),\n                         cos(theta)), 2, 2)\n  M2 <- matrix(c(A1, C1, B1, D1), 2, 2) %*% phaseshift\n  v <- apply(M2^2, 2, sum)\n  if (v[1] < v[2]) {\n    theta <- theta + pi/2\n  }\n  theta <- (theta + pi/2)%%pi - pi/2\n  Aa <- A1 * cos(theta) + B1 * sin(theta)\n  Cc <- C1 * cos(theta) + D1 * sin(theta)\n  scale <- sqrt(Aa^2 + Cc^2)\n  psi <- atan(Cc/Aa)%%pi\n  if (Aa < 0) {\n    psi <- psi + pi\n  }\n  size <- 1/scale\n  rotation <- matrix(c(cos(psi), -sin(psi), sin(psi), cos(psi)),\n                     2, 2)\n  A <- B <- C <- D <- numeric(nhm)\n  if (start) {\n    theta <- 0\n  }\n  for (i in 1:nhm) {\n    mat <- size * rotation %*%\n      matrix(c(ef$an[i], ef$cn[i],\n               ef$bn[i], ef$dn[i]), 2, 2) %*%\n      matrix(c(cos(i * theta), sin(i * theta),\n               -sin(i * theta), cos(i * theta)), 2, 2)\n    A[i] <- mat[1, 1]\n    B[i] <- mat[1, 2]\n    C[i] <- mat[2, 1]\n    D[i] <- mat[2, 2]\n    lnef <- c(A[i], B[i], C[i], D[i])\n  }\n  list(A = A, B = B, C = C, D = D, size = scale, theta = theta,\n       psi = psi, ao = ef$ao, co = ef$co, lnef = lnef)\n}\n\n# inverse fourier\nfourier_inv <- function(ef, nhm, nb.pts = 120) {\n  if (is.null(ef$ao))\n    ef$ao <- 0\n  if (is.null(ef$co))\n    ef$co <- 0\n  an <- ef$an\n  bn <- ef$bn\n  cn <- ef$cn\n  dn <- ef$dn\n  ao <- ef$ao\n  co <- ef$co\n  if (missing(nhm)) {\n    nhm <- length(an)\n  }\n  theta <- seq(0, 2 * pi, length = nb.pts + 1)[-(nb.pts + 1)]\n  hx <- matrix(NA, nhm, nb.pts)\n  hy <- matrix(NA, nhm, nb.pts)\n  for (i in 1:nhm) {\n    hx[i, ] <- an[i] * cos(i * theta) + bn[i] * sin(i * theta)\n    hy[i, ] <- cn[i] * cos(i * theta) + dn[i] * sin(i * theta)\n  }\n  x <- (ao/2) + apply(hx, 2, sum)\n  y <- (co/2) + apply(hy, 2, sum)\n  coo <- cbind(x, y)\n  colnames(coo) <- c(\"x\", \"y\")\n  return(coo)\n}"
  },
  {
    "objectID": "03_analyze.html#elliptical-fourier",
    "href": "03_analyze.html#elliptical-fourier",
    "title": "Analyze objects",
    "section": "\n10.2 Elliptical fourier",
    "text": "10.2 Elliptical fourier\n\nlibrary(pliman)\nimgs <- image_import(pattern = \"img\", path = \"fourier\")\nnames(imgs) <- paste0(\"ind\", 1:9)\n\nconts <- \n  object_contour(imgs,\n                 index = \"B\",\n                 watershed = FALSE,\n                 show_image = FALSE)\n\n\nd <- fourier(conts$ind1$`2`, nhm = 100)\nplot(imgs$ind1)\n# 10 harmônicas\nd_i <- fourier_inv(d, 10, nb.pts = 1000)\nplot_contour(d_i, lwd = 2)\n# 20 harmônicas\nd_i <- fourier_inv(d, 20, nb.pts = 1000)\nplot_contour(d_i, lwd = 2, col = \"blue\")\n# 40 harmônicas\nd_i <- fourier_inv(d, 80, nb.pts = 1000)\nplot_contour(d_i, lwd = 2, col = \"red\")"
  },
  {
    "objectID": "03_analyze.html#rotation-and-size",
    "href": "03_analyze.html#rotation-and-size",
    "title": "Analyze objects",
    "section": "\n10.3 Rotation and size",
    "text": "10.3 Rotation and size\n\nlibrary(pliman)\nimg <- image_import(\"changes.png\", path = \"fourier\")\ncont <- \n  object_contour(img,\n                 index = \"B\",\n                 watershed = FALSE,\n                 show_image = FALSE)\n\n\nf1 <- fourier(cont$`1`, nhm = 5)\nf2 <- fourier(cont$`2`, nhm = 5)\nf3 <- fourier(cont$`3`, nhm = 5)\nf1$an\n\n[1] 12.0989673  0.3642945  2.3491815 -1.3170290 -1.0623448\n\nf2$an\n\n[1] 167.329018  45.411721 -47.133350  12.902906  -8.440965\n\nf3$an\n\n[1]  6.5592562  0.3521776  1.2573074 -0.6858838 -0.5661625\n\nf1n <- fourier_norm(f1)\nf2n <- fourier_norm(f2)\nf3n <- fourier_norm(f3)\nf1n$A\n\n[1]  1.000000000 -0.020752286 -0.001967149 -0.022437848 -0.010519230\n\nf2n$A\n\n[1] -1.000000000  0.053474289  0.005280597  0.038000242  0.011862582\n\nf3n$A\n\n[1]  1.000000000 -0.013163949 -0.002955584 -0.017501282 -0.012917222"
  },
  {
    "objectID": "03_analyze.html#morphological-diversity",
    "href": "03_analyze.html#morphological-diversity",
    "title": "Analyze objects",
    "section": "\n10.4 Morphological diversity",
    "text": "10.4 Morphological diversity\n\nconts <- \n  object_contour(imgs,\n                 index = \"B\",\n                 watershed = FALSE,\n                 show_image = FALSE)\n\neff <- lapply(conts, function(x){\n  fourier(x[[1]], nhm = 15) |> fourier_norm()\n})\n\nan <- do.call(rbind, lapply(eff, function(x){x[[\"A\"]]}))\nbn <- do.call(rbind, lapply(eff, function(x){x[[\"B\"]]}))\ncn <- do.call(rbind, lapply(eff, function(x){x[[\"C\"]]}))\ndn <- do.call(rbind, lapply(eff, function(x){x[[\"D\"]]}))\n\ncoefs <- \n  cbind(an, bn, cn, dn) |> \n  transform(specie = c(rep(paste0(\"specie\", 1:3), each = 3)))\n\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\n\nAttaching package: 'factoextra'\n\n\nThe following object is masked from 'package:metan':\n\n    get_dist\n\nlibrary(FactoMineR)\n\nWarning: package 'FactoMineR' was built under R version 4.2.1\n\npca <- PCA(coefs, quali.sup = 61, graph = FALSE)\nfviz_pca_ind(pca, habillage = 61, repel = TRUE)\n\n\n\nimage_combine(imgs)"
  },
  {
    "objectID": "03_analyze.html#cluster-objects",
    "href": "03_analyze.html#cluster-objects",
    "title": "Analyze objects",
    "section": "\n11.1 Cluster objects",
    "text": "11.1 Cluster objects\n\nimg <- image_import(\"distance.png\", path = \"fourier\")\ncont <- \n  object_contour(img,\n                 index = \"B\",\n                 watershed = FALSE,\n                 show_image = FALSE)\nplot_polygon(cont, aspect_ratio = 1)\n\n\n\ndfour <- lapply(cont, function(x){\n  fourier(x, nhm = 15) |> fourier_norm()\n})\n\nan <- do.call(rbind, lapply(dfour, function(x){x[[\"A\"]]}))\nbn <- do.call(rbind, lapply(dfour, function(x){x[[\"B\"]]}))\ncn <- do.call(rbind, lapply(dfour, function(x){x[[\"C\"]]}))\ndn <- do.call(rbind, lapply(dfour, function(x){x[[\"D\"]]}))\n\ncoefs <- cbind(an, bn, cn, dn)\n\n\nlibrary(factoextra)\nlibrary(FactoMineR)\nlibrary(NbClust)\npca <- PCA(coefs, graph = FALSE)\nfviz_pca_ind(pca, repel = TRUE)\n\n\n\n# distance\ndistance <- dist(coefs) |> hclust()\nfviz_dend(distance, k = 3)\n\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead."
  },
  {
    "objectID": "03_analyze.html#distance-to-an-ideotype-1",
    "href": "03_analyze.html#distance-to-an-ideotype-1",
    "title": "Analyze objects",
    "section": "\n11.2 Distance to an ideotype",
    "text": "11.2 Distance to an ideotype\n\ndesc_ide <- coefs[1,]\ndesc_objs <- coefs[-1,]\n\n# compute the differences between each object and the ideotype\ngen_ide <- sweep(desc_objs, 2, desc_ide, \"-\")\n\ndistances <- \n  apply(gen_ide, 1, function(x){sqrt(sum(x^2))}) %>% \n  sort(decreasing = FALSE)\ndistances\n\n          2           6           3           5           4 \n0.002405437 0.130426948 2.332612482 2.429309481 2.458666804"
  },
  {
    "objectID": "04_phytopathometry.html",
    "href": "04_phytopathometry.html",
    "title": "Phytopathometry",
    "section": "",
    "text": "setwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")"
  },
  {
    "objectID": "04_phytopathometry.html#producing-sample-palettes",
    "href": "04_phytopathometry.html#producing-sample-palettes",
    "title": "Phytopathometry",
    "section": "\n4.1 Producing sample palettes",
    "text": "4.1 Producing sample palettes\nUsers can produce these palettes with pick_palette() function.\n\nh2 <- pick_palette(img)\nd2 <- pick_palette(img)\nb2 <- pick_palette(img)\nimage_combine(h2, d2, b2, ncol = 3)\n\n\n4.1.1 Defaults settings\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b)\n\n\n\nsev$severity\n\n   healthy symptomatic\n1 85.66133    14.33867\n\n\n\n4.1.2 Filling lesions\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_contour = FALSE)\n\n\n\n\n\n4.1.3 Showing a mask\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_original = FALSE,\n                  col_lesions = \"brown\") # default is \"black\"\n\n\n\n\n\n4.1.4 Segmenting and analyzing lesions\nWhen using show_features = TRUE, the function analyzes the lesions and returns results such as number of lesions, area, perimeter, etc. With show_segmentation = TRUE, segmented lesions are shown.\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_features = TRUE,\n                  watershed = TRUE,\n                  show_segmentation = TRUE)\n\n\n\n# correct the measures (dpi = 150)\nsev_corrected <- get_measures(sev, dpi = 150)"
  }
]