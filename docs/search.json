[
  {
    "objectID": "00_about.html",
    "href": "00_about.html",
    "title": "Useful info!",
    "section": "",
    "text": "1  Software and instalation\n Download do R\n Download do RStudio\n\n\n\n2  Author\n\n\n\n\n\n3  Overview\n\n{pliman} (plant image analysis) is designed (but not limited) to analyze plant images, especially related to leaf and seed analysis. The package will help you to:\n\nMeasure the severity of foliar diseases;\nCount the number of injuries;\nObtain characteristics of the shape of the lesions;\nCount objects in an image;\nObtain characteristics of objects (area, perimeter, radius, circularity, eccentricity, solidity, elongation);\nGet the RGB values for each object in an image;\nGet the coordinates of objects;\nGet the outlines of objects;\nGet the convex hull;\nIsolate objects;\nPlot object measurements.\n\n4  Instalation\nInstall the released version of pliman from CRAN with:\n\ninstall.packages (\"pliman\")\n\nOr install the development version from GitHub\n\n# instalação do github\nif(!require(devtools)){\n  install.packages(\"devtools\")\n}\n\ninstall_github (\"TiagoOlivoto/pliman\")\n\n# Para instalar a vinheta HTML, use\ndevtools::install_github (\"TiagoOlivoto/pliman\", build_vignettes = TRUE)\n\nNote: If you are a Windows user, it is suggested to first download and install the latest version of Rtools. For the latest release notes on this development version, see the NEWS file.\n\n5  Citation\nTo cite the pliman package in your studies, please, use the following reference:\n\nOlivoto, Tiago. 2022. “Lights, Camera, Pliman! An R Package for Plant Image Analysis”. Methods in Ecology and Evolution 13(4): 789–98 doi: 10.1111/2041-210X.13803\n\n\n\ncitation(\"pliman\")\n\n\nPlease, support this project by citing it in your publications!\n\n  Olivoto, T.(2022). Lights, camera, pliman! An R package for plant\n  image analysis. Methods Ecol Evol. 13:789-798\n  doi:10.1111/2041-210X.13803\n\nA BibTeX entry for LaTeX users is\n\n  @Article{Olivoto2022,\n    author = {Tiago Olivoto},\n    title = {Lights, camera, pliman! An R package for plant image analysis},\n    journal = {Methods in Ecology and Evolution},\n    volume = {13},\n    number = {4},\n    pages = {789-798},\n    year = {2022},\n    doi = {10.1111/2041-210X.13803},\n  }\n\n\n\n6  Useful packages\nThe results generated by the pliman package are returned as data.frame objects, which allows future manipulation within R. Therefore, it is suggested that the following packages be installed.\n\nlibrary(tidyverse)  # data manipulation\nlibrary(metan)      # descriptive statistics / arrange graphics\nlibrary(pliman)     # image analysis\n\n\n7  How to reproduce\nFirst, donwload the .zip file that contains the static website.\n  Download the images and scripts \nThe folder img has the following structure.\n\n\nE:/Desktop/UFSC/cursos/pliman_tut/imgs\n├── bean.jpg\n├── black.jpeg\n├── compound.jpg\n├── disease.jpeg\n├── exemp_1.jpeg\n├── exem_b.png\n├── exem_d.png\n├── exem_h.png\n├── feijao_b.png\n├── feijao_h.png\n├── feijao_s.png\n├── folhalin.png\n├── folhas.jpg\n├── fundolin.png\n├── fungo.JPG\n├── grains.JPG\n├── green.jpg\n├── holes.jpg\n├── img_exported.jpg\n├── img_sb_50_1.jpg\n├── img_sb_50_10.jpg\n├── img_sb_50_11.jpg\n├── img_sb_50_12.jpg\n├── img_sb_50_13.jpg\n├── img_sb_50_2.jpg\n├── img_sb_50_3.jpg\n├── img_sb_50_4.jpg\n├── img_sb_50_5.jpg\n├── img_sb_50_6.jpg\n├── img_sb_50_7.jpg\n├── img_sb_50_8.jpg\n├── img_sb_50_9.jpg\n├── L1_1.jpg\n├── L1_2.jpg\n├── L2_1.jpg\n├── L2_2.jpg\n├── L3_1.jpg\n├── L3_2.jpg\n├── L3_3.jpg\n├── L4_1.jpg\n├── L4_2.jpg\n├── L4_3.jpg\n├── L5_1.jpg\n├── L5_2.jpg\n├── leaf1.jpg\n├── leaf2.jpg\n├── leaf3.jpg\n├── leaf4.jpg\n├── leaf5.jpg\n├── linhaca\n│   ├── img_A1_B1.jpg\n│   ├── img_A1_B2.jpg\n│   ├── img_A2_B1.jpg\n│   ├── img_A2_B2.jpg\n│   ├── img_A3_B1.jpg\n│   ├── img_A3_B2.jpg\n│   ├── img_A4_B1.jpg\n│   └── img_A4_B2.jpg\n├── lista_exportada\n│   ├── img_sb_1.jpg\n│   ├── img_sb_2.jpg\n│   ├── img_sb_3.jpg\n│   ├── img_sb_4.jpg\n│   ├── img_sb_5.jpg\n│   ├── img_sb_50_1.jpg\n│   ├── img_sb_50_10.jpg\n│   ├── img_sb_50_11.jpg\n│   ├── img_sb_50_12.jpg\n│   ├── img_sb_50_13.jpg\n│   ├── img_sb_50_2.jpg\n│   ├── img_sb_50_3.jpg\n│   ├── img_sb_50_4.jpg\n│   ├── img_sb_50_5.jpg\n│   ├── img_sb_50_6.jpg\n│   ├── img_sb_50_7.jpg\n│   ├── img_sb_50_8.jpg\n│   └── img_sb_50_9.jpg\n├── multiplas_01.jpeg\n├── multiplas_02.jpeg\n├── multiplas_03.jpeg\n├── multiplas_04.jpeg\n├── multiplas_05.jpg\n├── objects_300.jpg\n├── reflin.png\n├── ref_back.jpg\n├── ref_folha.jpg\n├── ref_leaves.jpg\n├── ref_ref.jpg\n├── resultado.xlsx\n├── Rplots.pdf\n├── rule.jpg\n├── samples.png\n├── scripts_pliman_rmd_files\n│   └── figure-html\n├── sev_back.png\n├── sev_disease.png\n├── sev_healthy.png\n├── simple.jpg\n├── site.png\n├── soja_b.png\n├── soja_h.png\n├── soja_s.png\n├── soy_1.jpg\n├── soy_10.jpg\n├── soy_11.jpg\n├── soy_12.jpg\n├── soy_13.jpg\n├── soy_14.jpg\n├── soy_15.jpg\n├── soy_16.jpg\n├── soy_17.jpg\n├── soy_18.jpg\n├── soy_19.jpg\n├── soy_2.jpg\n├── soy_20.jpg\n├── soy_21.jpg\n├── soy_22.jpg\n├── soy_23.jpg\n├── soy_24.jpg\n├── soy_25.jpg\n├── soy_26.jpg\n├── soy_27.jpg\n├── soy_28.jpg\n├── soy_29.jpg\n├── soy_3.jpg\n├── soy_30.jpg\n├── soy_31.jpg\n├── soy_32.jpg\n├── soy_33.jpg\n├── soy_34.jpg\n├── soy_35.jpg\n├── soy_36.jpg\n├── soy_37.jpg\n├── soy_38.jpg\n├── soy_39.jpg\n├── soy_4.jpg\n├── soy_40.jpg\n├── soy_41.jpg\n├── soy_42.jpg\n├── soy_43.jpg\n├── soy_44.jpg\n├── soy_45.jpg\n├── soy_46.jpg\n├── soy_47.jpg\n├── soy_48.jpg\n├── soy_49.jpg\n├── soy_5.jpg\n├── soy_50.jpg\n├── soy_6.jpg\n├── soy_7.jpg\n├── soy_8.jpg\n├── soy_9.jpg\n├── TRAT1_1.jpg\n├── TRAT1_2.jpg\n├── TRAT1_3.jpg\n├── TRAT1_4.jpg\n├── TRAT2_1.jpg\n├── TRAT2_2.jpg\n├── TRAT2_3.jpg\n├── TRAT2_4.jpg\n├── TRAT3_1.jpg\n├── TRAT3_2.jpg\n├── TRAT3_3.jpg\n├── TRAT3_4.jpg\n├── TRAT4_1.jpg\n├── TRAT4_2.jpg\n├── TRAT4_3.jpg\n├── TRAT4_4.jpg\n└── vicia.jpg\n\n\nThe html material (_site/index.html) will give access to the site. Within it, it will be possible to visualize all the examples, with codes and outputs. To reproduce the material, just use the *.qmd files.\nFor rendering, it is suggested that the folder imgs be set as the default directory. In my case, I set the directory using the following command.\n\n# change according to your folder\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n\n\n\n8  Slides\nSee the slides here \n\n\n\n\n\n9  License\nThis content is licensed under a Creative Commons - Atribuição-NãoComercial-CompartilhaIgual 4.0 Internacional. The readable license summary states that you have the right to:\n Share — copy and redistribute material in any medium or format\nAdapt — remix, transform, and build upon material\nAttribution — You must give appropriate credit, provide a link to the license and indicate if changes have been made. You must do so under any reasonable circumstances, but in no way that suggests that the licensor endorses you or your use.\nAccording to the following terms\n\nNon-Commercial — You may not use the material for commercial purposes.\nShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo Additional Restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license allows.\n\n\n\n\nSource Code\n---\ntitle: \"Useful info!\"\n---\n\n\n# <i class=\"fas fa-laptop-code\"></i> Software and instalation\n\n<a class=\"btn btn-success\" href=\"https://cran.r-project.org/bin/windows/base/\" target=\"_blank\"><i class=\"fa fa-save\"></i> Download do R</a>\n\n\n<a class=\"btn btn-success\" href=\"https://www.rstudio.com/products/rstudio/download/\" target=\"_blank\"><i class=\"fa fa-save\"></i> Download do RStudio</a>\n\n\n<iframe width=\"940\" height=\"530\" src=\"https://www.youtube.com/embed/e89kyYJgWqc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n# <i class=\"fas fa-chalkboard-teacher\"></i> Author\n\n[![](imgs/site.png)](https://olivoto.netlify.app/){target=\"_blank\"}\n\n\n\n# <i class=\"fas fa-glasses\"></i> Overview\n\n<img src=\"https://raw.githubusercontent.com/TiagoOlivoto/pliman/master/man/figures/logo_pliman.svg\" align=\"right\" width=\"250\" height=\"250\"/>\n\n{pliman} (**pl**ant **im**age **an**alysis) is designed (but not limited) to analyze plant images, especially related to leaf and seed analysis. The package will help you to:\n\n* Measure the severity of foliar diseases;\n* Count the number of injuries;\n* Obtain characteristics of the shape of the lesions;\n* Count objects in an image;\n* Obtain characteristics of objects (area, perimeter, radius, circularity, eccentricity, solidity, elongation);\n* Get the RGB values for each object in an image;\n* Get the coordinates of objects;\n* Get the outlines of objects;\n* Get the *convex hull*;\n* Isolate objects;\n* Plot object measurements.\n\n\n\n\n# <i class=\"fas fa-tools\"></i> Instalation\n\nInstall the released version of pliman from [CRAN](https://CRAN.R-project.org/package=pliman) with:\n\n```{r, eval = FALSE}\ninstall.packages (\"pliman\")\n```\n\nOr install the development version from [GitHub](https://github.com/TiagoOlivoto/pliman)\n\n```{r, eval = FALSE}\n# instalação do github\nif(!require(devtools)){\n  install.packages(\"devtools\")\n}\n\ninstall_github (\"TiagoOlivoto/pliman\")\n\n# Para instalar a vinheta HTML, use\ndevtools::install_github (\"TiagoOlivoto/pliman\", build_vignettes = TRUE)\n\n```\n\n*Note*: If you are a Windows user, it is suggested to first download and install the latest version of [Rtools](https://cran.r-project.org/bin/windows/Rtools/). For the latest release notes on this development version, see the [NEWS file](https://tiagoolivoto.github.io/metan/news/index.html).\n\n\n# <i class=\"fas fa-book\"></i> Citation \n\nTo cite the `pliman` package in your studies, please, use the following reference:\n\n> Olivoto, Tiago. 2022. “Lights, Camera, Pliman! An R Package for Plant Image Analysis”. Methods in Ecology and Evolution 13(4): 789–98 <A HREF = \"https://onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13803\">doi: 10.1111/2041-210X.13803</A>\n\n<a href=\"https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13803\" target=\"_blank\" rel=\"noopener\"><img src=\"https://raw.githubusercontent.com/TiagoOlivoto/tiagoolivoto/master/static/tutorials/pliman_ufsc_fito/paper.png\" width=\"1000\" height=\"273\"/></a>\n\n```{r}\ncitation(\"pliman\")\n```\n\n\n\n# <i class=\"fas fa-box-open\"></i> Useful packages\n\nThe results generated by the `pliman` package are returned as `data.frame` objects, which allows future manipulation within R. Therefore, it is suggested that the following packages be installed.\n\n```{r warning=FALSE, message = FALSE}\nlibrary(tidyverse)  # data manipulation\nlibrary(metan)      # descriptive statistics / arrange graphics\nlibrary(pliman)     # image analysis\n```\n\n\n\n\n# <i class=\"fas fa-database\"></i> How to reproduce\n\nFirst, donwload the `.zip` file that contains the static website.\n\n<a href=\"https://github.com/TiagoOlivoto/pliman_tut/archive/refs/heads/master.zip\">\n<button class=\"btn btn-success\"><i class=\"fa fa-save\"></i> Download the images and scripts</button>\n</a>\n\n\nThe folder `img` has the following structure.\n\n```{r echo=FALSE}\nlibrary(fs)\nfs::dir_tree(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\", recurse = 1)\n```\n\n\n\nThe html material (`_site/index.html`) will give access to the site. Within it, it will be possible to visualize all the examples, with codes and outputs. To reproduce the material, just use the `*.qmd` files.\n\nFor rendering, it is suggested that the folder `imgs` be set as the default directory. In my case, I set the directory using the following command.\n\n```{r eval=FALSE}\n# change according to your folder\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n\n\n\n<br>\n\n# <i class=\"fas fa-tv\"></i> Slides\n\nSee the slides here <a href=\"https://tiagoolivoto.github.io/slides_R/slides/pliman_inta/index.html#1\" target=\"_blank\"><i class=\"fas fa-external-link-alt\"></i></a>\n\n```{r echo=FALSE}\nknitr::include_url('https://tiagoolivoto.github.io/slides_R/slides/pliman_inta')\n\n```\n\n\n\n# <i class=\"fab fa-creative-commons\"></i> License\n\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\" target=\"_blank\" rel=\"noopener\"><img alt=\"Licença Creative Commons\" style=\"border-width:0\" src=\"https://raw.githubusercontent.com/TiagoOlivoto/tiagoolivoto/master/static/img/gemsr/license.jpg\" width=\"300\" height=\"214\" /></a><br />This content is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons - Atribuição-NãoComercial-CompartilhaIgual 4.0 Internacional</a>. The readable license summary states that you have the right to:\n\n\n\n<i class=\"fas fa-check\"></i> **Share** — copy and redistribute material in any medium or format\n\n<i class=\"fas fa-check\"></i>**Adapt** — remix, transform, and build upon material\n\n<i class=\"fas fa-check\"></i>**Attribution** — You must give appropriate credit, provide a link to the license and indicate if changes have been made. You must do so under any reasonable circumstances, but in no way that suggests that the licensor endorses you or your use.\n\n<i class=\"fas fa-check\"></i>**According to the following terms**\n\n* **Non-Commercial** — You may not use the material for commercial purposes.\n\n* **ShareAlike** — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\n\n* **No Additional Restrictions** — You may not apply legal terms or technological measures that legally restrict others from doing anything the license allows."
  },
  {
    "objectID": "01_manipulate.html",
    "href": "01_manipulate.html",
    "title": "Import and manipulate",
    "section": "",
    "text": "1 Directory\n\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n\n\n2 Import images\n\nlibrary(pliman)\nlibrary(tidyverse)\nlibrary(patchwork)\nimg <- image_import(\"folhas.jpg\")\n\nTo import a list of images, use a vector of image names, or the pattern argument. In the latter, all images that match the pattern name are imported into a list.\n\nimg_list1 <- image_import(c(\"img_sb_50_1.jpg\", \"img_sb_50_2.jpg\"))\nimg_list2 <- image_import(pattern = \"img_sb_\")\nstr(img_list2)\n\nList of 13\n $ img_sb_50_1.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.365 0.361 0.361 0.349 0.365 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_10.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.42 0.408 0.416 0.416 0.416 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_11.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.388 0.38 0.384 0.38 0.369 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_12.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.38 0.376 0.392 0.384 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_13.jpg:Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.392 0.392 0.412 0.384 0.4 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_2.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.376 0.384 0.392 0.388 0.396 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_3.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.369 0.376 0.361 0.361 0.365 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_4.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.4 0.408 0.404 0.396 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_5.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.396 0.404 0.396 0.396 0.388 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_6.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.4 0.38 0.396 0.384 0.388 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_7.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.349 0.361 0.365 0.365 0.373 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_8.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.361 0.373 0.376 0.388 0.384 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n $ img_sb_50_9.jpg :Formal class 'Image' [package \"EBImage\"] with 2 slots\n  .. ..@ .Data    : num [1:816, 1:612, 1:3] 0.373 0.365 0.373 0.384 0.392 ...\n  .. ..@ colormode: int 2\n  .. ..$ dim: int [1:3] 816 612 3\n\n\n\n3 Displaying imagens\nIndividual images are displayed with plot(). To combine images, the image_combine() function is used. Users can enter a comma-separated list of objects or a list of objects of the Image class.\n\n# Imagens individuais\nplot(img)\n\n\n\n\n\n# Combine imagens\nimage_combine(img_list1)\n\n\n\n\npliman provides a set of image_*() functions to perform image manipulation and transformation of unique images or an image list based on EBImage package.\n\n4 Resize an image\nSometimes resizing high-resolution images is necessary to reduce computational effort and processing time. The image_resize() function is used to resize an image. The rel_size argument can be used to resize the image by relative size. For example, setting rel_size = 50 for an image of width 1280 x 720, the new image will have a size of 640 x 360.\n\nimage_dimension(img)\n\n\n----------------------\nImage dimension\n----------------------\nWidth :  783 \nHeight:  1005 \n\nimg_resized <- image_resize(img, rel_size = 50)\nimage_dimension(img_resized)\n\n\n----------------------\nImage dimension\n----------------------\nWidth :  392 \nHeight:  502 \n\n\n\n5 Image resolution (DPI)\nThe dpi() function executes an interactive function to calculate the image resolution given a known distance entered by the user. To calculate the image resolution (dpi), the user must use the left mouse button to create a line of known distance. This can be done, for example, using a model with known distance, as follows.\n\n#  this only works in an interactive section\nrule <- image_import(\"rule.jpg\", plot = TRUE)\n(dpi <- dpi(rule))\n\nrule2 <- \n  image_crop(rule,\n             width = 130:1390, \n             height = 582:1487, \n             plot = TRUE)\n\nanalyze_objects(rule2,\n                watershed = FALSE,\n                marker = \"area\") |> \n  get_measures(dpi = 518) |> \n  plot_measures(measure = \"area\", vjust = -100, size = 2)\n\n\n6 Filter, blur, contrast, dilatation, erosion, opening, and closing\n\nimg_filter <- image_filter(img)\nimg_blur <- image_blur(img)\nimg_contrast <- image_contrast(img)\nimg_dilatation <- image_dilate(img)\nimg_erosion <- image_erode(img)\nimg_opening <- image_opening(img)\nimg_closing <- image_closing(img)\nimage_combine(img,\n              img_filter,\n              img_blur,\n              img_contrast,\n              img_dilatation,\n              img_erosion,\n              img_opening,\n              img_closing,\n              ncol = 4)\n\n\n\n\n\n7 Export\nTo export images to the current directory, use the image_export() function. If an image list is exported, the images will be saved considering the name and extension present in the list. If no extension is present, images will be saved as *.jpg files.\n\nimage_export(img, \"imgs/img_exported.jpg\")\n# ou subpasta\nimage_export(img, \"imgs/test/img_exported.jpg\")\n\n\n\n\nSource Code\n---\ntitle: \"Import and manipulate\"\n---\n\n```{r include = FALSE}\nknitr::opts_knit$set(root.dir = \"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n# Directory\n```{r eval=FALSE}\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n# Import images\n```{r collapse = TRUE, message=FALSE, warning=FALSE}\nlibrary(pliman)\nlibrary(tidyverse)\nlibrary(patchwork)\nimg <- image_import(\"folhas.jpg\")\n\n```\n\n\n\nTo import a list of images, use a vector of image names, or the `pattern` argument. In the latter, all images that match the pattern name are imported into a list.\n\n```{r import2}\nimg_list1 <- image_import(c(\"img_sb_50_1.jpg\", \"img_sb_50_2.jpg\"))\nimg_list2 <- image_import(pattern = \"img_sb_\")\nstr(img_list2)\n```\n\n\n# Displaying imagens\nIndividual images are displayed with `plot()`. To combine images, the `image_combine()` function is used. Users can enter a comma-separated list of objects or a list of objects of the `Image` class.\n\n```{r display1, fig.width = 10, fig.height=6}\n# Imagens individuais\nplot(img)\n```\n\n\n\n```{r display2, fig.width = 10, fig.height=5}\n# Combine imagens\nimage_combine(img_list1)\n```\n\n\n`pliman` provides a set of `image_*()` functions to perform image manipulation and transformation of unique images or an image list based on [EBImage package](https://www.bioconductor.org/packages/release /bioc/vignettes/EBImage/inst/doc/EBImage-Introduction.html).\n\n\n# Resize an image\n\nSometimes resizing high-resolution images is necessary to reduce computational effort and processing time. The `image_resize()` function is used to resize an image. The `rel_size` argument can be used to resize the image by relative size. For example, setting `rel_size = 50` for an image of width 1280 x 720, the new image will have a size of 640 x 360.\n\n```{r manipulate1}\nimage_dimension(img)\nimg_resized <- image_resize(img, rel_size = 50)\nimage_dimension(img_resized)\n```\n\n\n\n# Image resolution (DPI) {#dpi}\nThe `dpi()` function executes an interactive function to calculate the image resolution given a known distance entered by the user. To calculate the image resolution (dpi), the user must use the left mouse button to create a line of known distance. This can be done, for example, using a model with known distance, as follows.\n\n\n```{r eval = FALSE}\n#  this only works in an interactive section\nrule <- image_import(\"rule.jpg\", plot = TRUE)\n(dpi <- dpi(rule))\n\nrule2 <- \n  image_crop(rule,\n             width = 130:1390, \n             height = 582:1487, \n             plot = TRUE)\n\nanalyze_objects(rule2,\n                watershed = FALSE,\n                marker = \"area\") |> \n  get_measures(dpi = 518) |> \n  plot_measures(measure = \"area\", vjust = -100, size = 2)\n```\n\n\n\n\n\n# Filter, blur, contrast, dilatation, erosion, opening, and closing\n\n```{r manipulate6, fig.width = 10, fig.height = 10}\nimg_filter <- image_filter(img)\nimg_blur <- image_blur(img)\nimg_contrast <- image_contrast(img)\nimg_dilatation <- image_dilate(img)\nimg_erosion <- image_erode(img)\nimg_opening <- image_opening(img)\nimg_closing <- image_closing(img)\nimage_combine(img,\n              img_filter,\n              img_blur,\n              img_contrast,\n              img_dilatation,\n              img_erosion,\n              img_opening,\n              img_closing,\n              ncol = 4)\n```\n\n\n# Export\nTo export images to the current directory, use the `image_export()` function. If an image list is exported, the images will be saved considering the name and extension present in the list. If no extension is present, images will be saved as `*.jpg` files.\n\n```{r export, eval=FALSE}\nimage_export(img, \"imgs/img_exported.jpg\")\n# ou subpasta\nimage_export(img, \"imgs/test/img_exported.jpg\")\n\n```"
  },
  {
    "objectID": "02_segment.html",
    "href": "02_segment.html",
    "title": "Segment objects",
    "section": "",
    "text": "1 Directory\n\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n\n\n2 Import images\n\nlibrary(pliman) \nimg <- \n  image_import(\"folhas.jpg\") |> \n  image_horizontal(plot = TRUE)\n\n\n\nimg_r <- image_resize(img, rel_size = 30) #fast processing\n\n\n3 Segment images\nIn pliman, the following functions can be used to segment an image.\n\n\nimage_binary() to produce a binary (black and white) image.\n\nimage_segment() to produce a segmented image (image objects and a white background).\n\nimage_segment_iter() to segment an image interactively.\n\nBoth functions segment the image based on the value of some image index, which can be one of the RGB bands or any operation with these bands. Internally, these functions call image_index() to calculate these indices.\nHere, we use the index\"argument to test segmentation based on RGB and its normalized values. Users can also provide their index with the my_index argument.\n\n# Calcule os índices\nindexes <- image_index(img_r, index = c(\"R, G, B, NR, NG, NB\"))\n\n\n\n# Crie um gráfico raster com os valores RGB\nplot(indexes)\n\n\n\n# Crie um histograma com os valores RGB\nplot(indexes, type = \"density\")\n\n\n\n\nThe two peaks represent the leaf (smallest peak) and the background (larger peak). The clearer the difference between these peaks, the better the image segmentation.\n\n4 Producing a binary image\nTo segment objects, pliman uses the threshold technique (Otsu, 1979)1, that is, a cut-off point (considering the pixel values) is chosen and the image is classified into two classes (foreground and background). We then have a binary image. We can produce this image with image_binary(). This binarization is the key process to all object analysis steps. The better the binarization, the better the results.\nBy default, image binary applies median filtering in the binary mask so that noises (for example, small dust points) are removed. Users can control whether the filter is applied and its intensity. Let’s to produce a binary image using the index \"B\" with no filter applied.\n\nbinary <- \n  image_binary(img,\n               index = \"B\",\n               filter = FALSE)\n\n\n\n\nNote that some pixels within the bottom leaf were considered as background and some pixels at the bottom-right corner were considered as foreground. We can improve this binarization by applying a median filter. The default is image_binary() is filter = 2, but this value can be adjusted to obtain better results. Note how the change in the filter argument impact the results.\n\nbin <- image_binary(img, \n                    index = \"B\", \n                    show_image = FALSE)[[1]]\nbin2 <- image_binary(img, \n                     index = \"B\", \n                     filter = 5,\n                     show_image = FALSE)[[1]]\nbin3 <- image_binary(img, \n                     index = \"B\", \n                     filter = 30,\n                     show_image = FALSE)[[1]]\n\nimage_combine(bin, bin2, bin3, ncol = 3)\n\n\n\n\nThe image_segment() function is used to segment images using image indices. In this example, we will use compare the B and NB index to segment the leaves.\n\nsegmented <- \n  image_segment(img,\n                index = c(\"B, NB\"))\n\n\n\n\n\n5 Iterative segmentation\nThe function image_segment_iter() provides an iterative image segmentation. Users can choose how many segmentation to perform, using the argument nseg. Note that the same results can be obtained with image_segment_iter() using an iterative section.\n\n# Only run iteratively\nimage_segment_iter(img, nseg = 1)\n\n\n6 Segmentation with a mask\nBy using image_segment_mask() it is possible to segment an object using a mask.\n\nimg <- image_import(\"objects_300.jpg\", plot = TRUE)\n\n\n\nimage_segment_mask(img,\n                   size = 1171,\n                   rel_pos_y = 0.6,\n                   rel_pos_x = 0.08,\n                   shape = \"box\")\n\n\n\n\nImage \n  colorMode    : Color \n  storage.mode : double \n  dim          : 2126 1535 3 \n  frames.total : 3 \n  frames.render: 1 \n\nimageData(object)[1:5,1:6,1]\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    1    1    1    1    1\n[2,]    1    1    1    1    1    1\n[3,]    1    1    1    1    1    1\n[4,]    1    1    1    1    1    1\n[5,]    1    1    1    1    1    1\n\n\n\n\n\nSource Code\n---\ntitle: \" Segment objects\"\n---\n\n```{r include = FALSE}\nknitr::opts_knit$set(root.dir = \"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n# Directory\n```{r eval=FALSE}\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n# Import images\n```{r collapse = TRUE, message=FALSE, warning=FALSE}\nlibrary(pliman) \nimg <- \n  image_import(\"folhas.jpg\") |> \n  image_horizontal(plot = TRUE)\nimg_r <- image_resize(img, rel_size = 30) #fast processing\n```\n\n\n# Segment images\n\nIn `pliman`, the following functions can be used to segment an image.\n\n* `image_binary()` to produce a binary (black and white) image.\n* `image_segment()` to produce a segmented image (image objects and a white background).\n* `image_segment_iter()` to segment an image interactively.\n\nBoth functions segment the image based on the value of some image index, which can be one of the RGB bands or any operation with these bands. Internally, these functions call `image_index()` to calculate these indices.\n\nHere, we use the `index\" `argument to test segmentation based on RGB and its normalized values. Users can also provide their index with the `my_index` argument.\n\n\n```{r segmentação2, fig.width = 10, fig.height = 6}\n# Calcule os índices\nindexes <- image_index(img_r, index = c(\"R, G, B, NR, NG, NB\"))\n\n# Crie um gráfico raster com os valores RGB\nplot(indexes)\n\n# Crie um histograma com os valores RGB\nplot(indexes, type = \"density\")\n\n```\n\nThe two peaks represent the leaf (smallest peak) and the background (larger peak). The clearer the difference between these peaks, the better the image segmentation.\n\n\n\n# Producing a binary image\n\nTo segment objects, `pliman` uses the `threshold` technique (Otsu, 1979)^[Otsu, N. 1979. Threshold selection method from gray-level histograms. IEEE Trans Syst Man Cybern SMC-9(1): 62–66. doi: 10.1109/tsmc.1979.4310076.], that is, a cut-off point (considering the pixel values) is chosen and the image is classified into two classes (foreground and background). We then have a binary image. We can produce this image with `image_binary()`. This binarization is the key process to all object analysis steps. The better the binarization, the better the results.\n\nBy default, image binary applies median filtering in the binary mask so that noises (for example, small dust points) are removed. Users can control whether the filter is applied and its intensity. Let's to produce a binary image using the index `\"B\"` with no filter applied.\n\n```{r binary3, fig.width = 10, fig.height = 5}\nbinary <- \n  image_binary(img,\n               index = \"B\",\n               filter = FALSE)\n\n```\n\nNote that some pixels within the bottom leaf were considered as background and some pixels at the bottom-right corner were considered as foreground. We can improve this binarization by applying a median filter. The default is `image_binary()` is `filter = 2`, but this value can be adjusted to obtain better results. Note how the change in the `filter` argument impact the results.\n\n```{r binary2, fig.width = 10, fig.height = 5}\nbin <- image_binary(img, \n                    index = \"B\", \n                    show_image = FALSE)[[1]]\nbin2 <- image_binary(img, \n                     index = \"B\", \n                     filter = 5,\n                     show_image = FALSE)[[1]]\nbin3 <- image_binary(img, \n                     index = \"B\", \n                     filter = 30,\n                     show_image = FALSE)[[1]]\n\nimage_combine(bin, bin2, bin3, ncol = 3)\n```\n\n\n\nThe `image_segment()` function is used to segment images using image indices. In this example, we will use compare the `B` and `NB` index to segment the leaves.\n\n```{r segmentação3, fig.width = 10, fig.height = 5}\nsegmented <- \n  image_segment(img,\n                index = c(\"B, NB\"))\n\n```\n\n\n\n# Iterative segmentation\n\nThe function `image_segment_iter()` provides an iterative image segmentation. Users can choose how many segmentation to perform, using the argument `nseg`. Note that the same results can be obtained with `image_segment_iter()` using an iterative section.\n\n```{r segmentation7, eval=FALSE}\n# Only run iteratively\nimage_segment_iter(img, nseg = 1)\n```\n\n\n# Segmentation with a mask\n\nBy using `image_segment_mask()` it is possible to segment an object using a mask.\n\n```{r}\nimg <- image_import(\"objects_300.jpg\", plot = TRUE)\n\nimage_segment_mask(img,\n                   size = 1171,\n                   rel_pos_y = 0.6,\n                   rel_pos_x = 0.08,\n                   shape = \"box\")\n```\n\n\n\nFootnotes\n\nOtsu, N. 1979. Threshold selection method from gray-level histograms. IEEE Trans Syst Man Cybern SMC-9(1): 62–66. doi: 10.1109/tsmc.1979.4310076.↩︎"
  },
  {
    "objectID": "03_analyze.html#area",
    "href": "03_analyze.html#area",
    "title": "Analyze objects",
    "section": "\n2.1 Area",
    "text": "2.1 Area\nThe area of a shape is calculated using Shoelace ’s formula (Lee and Lim, 2017)5, as follows\n\\[\nA=\\frac{1}{2}\\left |\\sum_{i=1}^{n}\\left(x_{i} y_{i+1}-x_{i+1}y_{i}\\right)\\right|\n\\]\n\npoly_area(cont)\n\n      1       3      12      24 \n22619.5 46388.5 11087.0  1768.0"
  },
  {
    "objectID": "03_analyze.html#perimeter",
    "href": "03_analyze.html#perimeter",
    "title": "Analyze objects",
    "section": "\n2.2 Perimeter",
    "text": "2.2 Perimeter\nThe perimeter is calculated as the sum of the Euclidean distance between all points on a shape. Distances can be obtained with poly_distpts().\n\npoly_perimeter(cont)\n\n       1        3       12       24 \n669.5412 896.6783 514.5290 175.5097 \n\n# perimeter of a circle with radius 2\ncircle <- draw_circle(radius = 2, plot = FALSE)\npoly_perimeter(circle)\n\n[1] 12.56635\n\n# check the result\n2*pi*2\n\n[1] 12.56637"
  },
  {
    "objectID": "03_analyze.html#radius",
    "href": "03_analyze.html#radius",
    "title": "Analyze objects",
    "section": "\n2.3 Radius",
    "text": "2.3 Radius\nThe radius of a pixel on the object’s contour is calculated as its distance from the object’s centroid(also called ‘center of mass’). These distances can be obtained with poly_centdist().\n\ndist <- poly_centdist(cont)\n\n# stats for radius\nmean_list(dist)\n\n        1         3        12        24 \n 88.75563 124.90380  62.67764  24.21182 \n\nmin_list(dist)\n\n       1        3       12       24 \n63.58162 88.99496 39.17004 16.46777 \n\nmax_list(dist)\n\n        1         3        12        24 \n134.19687 185.49516  98.89383  36.25669 \n\nsd_list(dist)\n\n        1         3        12        24 \n17.399797 27.191664 15.269774  5.728793 \n\n# average radius of circle above\npoly_centdist(circle) |> mean_list()\n\n[1] 1.999998"
  },
  {
    "objectID": "03_analyze.html#length-and-width",
    "href": "03_analyze.html#length-and-width",
    "title": "Analyze objects",
    "section": "\n2.4 Length and width",
    "text": "2.4 Length and width\nThe length and width of an object are calculated with poly_lw(), as the difference between the maximum and minimum of the x and y coordinates after the object has been aligned with poly_align().\n\npoly_lw(cont)\n\n     length     width\n1  254.5408 139.27127\n3  352.6398 186.09592\n12 170.3480 126.74856\n24  70.0622  35.30868"
  },
  {
    "objectID": "03_analyze.html#circularity-eccentricity-diameter-and-elongation",
    "href": "03_analyze.html#circularity-eccentricity-diameter-and-elongation",
    "title": "Analyze objects",
    "section": "\n2.5 Circularity, eccentricity, diameter and elongation",
    "text": "2.5 Circularity, eccentricity, diameter and elongation\nCircularity(Montero et al. 2009)6 is also called shape compactness, or measure of roundness of an object. It is given by \\(C = P^2 / A\\), where \\(P\\) is the perimeter and \\(A\\) is the area of the object.\n\npoly_circularity(cont)\n\n       1        3       12       24 \n19.81854 17.33257 23.87842 17.42288 \n\n\nAs the above measurement depends on the scale, normalized roundness can be used. In this case, a perfect circle is assumed to have circularity equal to 1. This measure is invariant under translation, rotation and scale transformations, given \\(Cn = P^2 / 4 \\pi A\\)\n\npoly_circularity_norm(cont)\n\n       1        3       12       24 \n1.577109 1.379282 1.900185 1.386468 \n\n# normalized circularity for different shapes\ndraw_square(plot =FALSE) |> poly_circularity_norm()\n\n[1] 1.27324\n\ndraw_circle(plot=FALSE) |> poly_circularity_norm()\n\n[1] 1.000003\n\n\npoly_circularity_haralick() calculates the circularity of Haralick , CH(Haralick , 1974)7. The method is based on calculating all Euclidean distances from the object’s centroid to each contour pixel. With this set of distances, the mean(\\(m\\)) and the standard deviation(\\(s\\)) are calculated. These statistical parameters are used in a ratio that calculates CH as $CH = m/ sd $.\n\npoly_circularity_haralick(cont)\n\n       1        3       12       24 \n5.100958 4.593459 4.104687 4.226340 \n\n\npoly_convexity() Calculates the convexity of a shape using a ratio of the perimeter of the convex hull to the perimeter of the polygon.\n\npoly_convexity(cont)\n\n        1         3        12        24 \n0.8541852 0.9065881 0.8338600 0.8891777 \n\n\npoly_eccentricity() Calculates the eccentricity of a shape using the ratio of the eigenvalues(coordinate inertia axes).\n\npoly_eccentricity(cont)\n\n        1         3        12        24 \n0.3886748 0.3941193 0.5431220 0.3815938 \n\n\npoly_elongation() Calculates the elongation of an object as 1 - width / length\n\npoly_elongation(cont)\n\n        1         3        12        24 \n0.4528529 0.4722776 0.2559433 0.4960381 \n\n\npoly_caliper() Calculates the gauge(also called Feret’s diameter).\n\npoly_caliper(cont)\n\n        1         3        12        24 \n254.56826 352.75062 173.30320  70.06426 \n\n\nUsers can use the poly_measures() function to calculate most object measurements in a single call.\n\nmeasures <- poly_measures(cont) |> round_cols()\nt(measures)\n\n                            1        3       12      24\nid                       1.00     2.00     3.00    4.00\nx                      534.76   275.03   593.92  613.97\ny                      164.70   220.22   375.49  509.49\narea                 22619.50 46388.50 11087.00 1768.00\narea_ch              23834.00 46946.50 12775.00 1818.00\nperimeter              669.54   896.68   514.53  175.51\nradius_mean             88.76   124.90    62.68   24.21\nradius_min              63.58    88.99    39.17   16.47\nradius_max             134.20   185.50    98.89   36.26\nradius_sd               17.40    27.19    15.27    5.73\nradius_ratio             2.11     2.08     2.52    2.20\ndiam_mean              177.51   249.81   125.36   48.42\ndiam_min               127.16   177.99    78.34   32.94\ndiam_max               268.39   370.99   197.79   72.51\ncaliper                254.57   352.75   173.30   70.06\nlength                 254.54   352.64   170.35   70.06\nwidth                  139.27   186.10   126.75   35.31\nsolidity                 0.95     0.99     0.87    0.97\nconvexity                0.85     0.91     0.83    0.89\nelongation               0.45     0.47     0.26    0.50\ncircularity             19.82    17.33    23.88   17.42\ncircularity_haralick     3.65     3.27     2.57    2.87\ncircularity_norm         1.58     1.38     1.90    1.39\neccentricity             0.39     0.39     0.54    0.38\n\n\nIf the image resolution is known, the measurements can be corrected with get_measures(). Image resolution can be obtained using a known distance in the image. In the example, the white square has a side of 5 cm. So using dpi() the resolution can be obtained. In this case, the dpi is ~50.\n\n(color_measures <- get_measures(measures, dpi = 50))\n\n   id      x      y    area area_ch perimeter radius_mean radius_min radius_max\n1   1 534.76 164.70  58.373  61.507    34.013       4.509      3.230      6.817\n3   2 275.03 220.22 119.712 121.152    45.551       6.345      4.521      9.423\n12  3 593.92 375.49  28.612  32.968    26.138       3.184      1.990      5.024\n24  4 613.97 509.49   4.563   4.692     8.916       1.230      0.837      1.842\n   radius_sd radius_ratio diam_mean diam_min diam_max caliper length width\n1      0.884        0.107     9.018    6.460   13.634  12.932 12.931 7.075\n3      1.381        0.106    12.690    9.042   18.846  17.920 17.914 9.454\n12     0.776        0.128     6.368    3.980   10.048   8.804  8.654 6.439\n24     0.291        0.112     2.460    1.673    3.684   3.559  3.559 1.794\n   solidity convexity elongation circularity circularity_haralick\n1      0.95      0.85       0.45       19.82                 3.65\n3      0.99      0.91       0.47       17.33                 3.27\n12     0.87      0.83       0.26       23.88                 2.57\n24     0.97      0.89       0.50       17.42                 2.87\n   circularity_norm eccentricity\n1              1.58         0.39\n3              1.38         0.39\n12             1.90         0.54\n24             1.39         0.38\n\n\nSome useful functions can be used to manipulate coordinates. In the following example I will show some features implemented in pliman. Just for simplicity, I’ll just use object 2.\n\no2 <- cont[[\"3\"]]\nplot_polygon(o2)"
  },
  {
    "objectID": "03_analyze.html#rotate-polygons",
    "href": "03_analyze.html#rotate-polygons",
    "title": "Analyze objects",
    "section": "\n2.6 Rotate polygons",
    "text": "2.6 Rotate polygons\npoly_rotate() can be used to rotate the polygon coordinates by an angle (0-360 degrees) in the trigonometric (anti-clockwise) direction.\n\nrot <- poly_rotate(o2, angle = 45)"
  },
  {
    "objectID": "03_analyze.html#invert-polygons",
    "href": "03_analyze.html#invert-polygons",
    "title": "Analyze objects",
    "section": "\n2.7 Invert polygons",
    "text": "2.7 Invert polygons\npoly_flip_x() and poly_flip_y() can be used to flip shapes along the x and y axis, respectively.\n\nflipped <- \n  list(fx = poly_flip_x(o2), \n       fy = poly_flip_y(o2))\n\nplot_polygon(flipped, merge = FALSE, aspect_ratio = 1)"
  },
  {
    "objectID": "03_analyze.html#perimeter-sampling",
    "href": "03_analyze.html#perimeter-sampling",
    "title": "Analyze objects",
    "section": "\n2.8 Perimeter sampling",
    "text": "2.8 Perimeter sampling\npoly_sample() samples n coordinates between existing points, and poly_sample_prop() samples a proportion of coordinates between existing ones.\n\n# sample 50 coordinates\npoly_sample(o2, n=10) |> plot_polygon()\n\n\n\n# sample 10% of coordinates\npoly_sample_prop(o2, prop = 0.1) |> plot_polygon()"
  },
  {
    "objectID": "03_analyze.html#smoothing",
    "href": "03_analyze.html#smoothing",
    "title": "Analyze objects",
    "section": "\n2.9 smoothing",
    "text": "2.9 smoothing\npoly_smooth() smooths the contour of a polygon by combining prop coordinate point samples and interpolating them using vertices vertices(default is 1000) .\n\nsmoothed <-\n  list( original = o2,\n        s1 = poly_smooth(o2, prop = 0.2, plot = FALSE),\n        s2 = poly_smooth(o2, prop = 0.1, plot = FALSE),\n        s1 = poly_smooth(o2, prop = 0.04, plot = FALSE)\n  )\n\nplot_polygon(smoothed, merge = FALSE, ncol = 2, aspect_ratio = 1)"
  },
  {
    "objectID": "03_analyze.html#noises",
    "href": "03_analyze.html#noises",
    "title": "Analyze objects",
    "section": "\n2.10 Noises",
    "text": "2.10 Noises\npoly_jitter() adds a small amount of noise to a set of coordinates. See base::jitter() for more details.\n\nset.seed(1)\nc1 <- draw_circle(n = 200, plot = FALSE)\nc2 <- draw_circle(n = 200, plot = FALSE) |>\n  poly_jitter(noise_x = 100,\n              noise_y = 100,\n              plot = FALSE)\n\nplot_polygon(list(c1, c2), merge = FALSE)"
  },
  {
    "objectID": "03_analyze.html#adjusting-object-measurements",
    "href": "03_analyze.html#adjusting-object-measurements",
    "title": "Analyze objects",
    "section": "\n3.1 Adjusting object measurements",
    "text": "3.1 Adjusting object measurements\nThe results were stored in img_res. Since there is no scale declared in the example above, we have no idea about the actual area of objects in cm\\(^2\\), only in pixels. In this case, we use get_measures() to adjust pixel measurements to metric units.\nThere are two main ways to adjust object measurements (from pixels to cm, for example). The first is to declare the known area, perimeter or radius of a given object. The measure for the other objects will then be calculated by a simple rule of three. The second is by declaring a known image resolution in dpi(dots per inch). In this case, perimeter, area and radius will be adjusted by the dpi informed.\n\n3.1.1 Declaring a known value\nSince we know the area of the larger square (object 1), let’s adjust the area of the other objects in the image using this.\n\nget_measures(img_res ,\n             id = 1,\n             area ~ 100)\n\n-----------------------------------------\nmeasures corrected with:\nobject id: 1\narea     : 100\n-----------------------------------------\nTotal    : 40.009 \nAverage  : 13.336 \n-----------------------------------------\n\n\n  id        x        y   area area_ch perimeter radius_mean radius_min\n2  2 1737.518  452.998 25.041  24.958    19.983       2.866      2.492\n3  3 1737.571 1296.354  7.019   7.022    10.093       1.491      1.479\n4  4 1737.966  939.007  7.949   7.907    11.913       1.668      0.988\n  radius_max radius_sd diam_mean diam_min diam_max major_axis minor_axis length\n2      3.531     0.314     5.732    4.983    7.062      5.783      5.773  6.520\n3      1.504     0.004     2.982    2.957    3.008      2.990      2.989  2.996\n4      2.224     0.423     3.335    1.976    4.449      4.609      2.299  3.994\n  width radius_ratio eccentricity  theta solidity convexity elongation\n2 6.509        1.417        0.996  1.563    1.003     0.749      0.002\n3 2.999        1.017        0.994 -1.547    1.000     0.905     -0.001\n4 1.987        2.252        0.348  0.000    1.005     0.836      0.502\n  circularity circularity_haralick circularity_norm   asm   con   cor   var\n2      15.946                9.127            1.273 0.913 0.051 0.731 1.095\n3      14.512              423.369            1.161 0.829 0.078 0.781 1.178\n4      17.854                3.947            1.430 0.853 0.069 0.786 1.161\n    idm    sav     sva   sen   ent   dva   den   f12   f13\n2 0.987 21.901 475.312 0.106 0.116 0.051 0.054 0.518 0.279\n3 0.975 21.821 468.297 0.196 0.220 0.078 0.090 0.523 0.380\n4 0.979 21.828 470.245 0.156 0.176 0.069 0.076 0.555 0.356\n\n\n\n3.1.2 Declaring the image resolution\nIf the image resolution is known, all measurements will be adjusted accordingly. Let’s see a numerical example with pixels_to_cm(). This function converts the number of pixels(* px *) into cm, considering the image resolution in dpi, as follows: \\(cm = px \\times(2.54 / dpi)\\). As we know the number of pixels of the larger square, its perimeter in cm is given by\n\n# number of pixels for the perimeter of the largest square\n\nls_px <- img_res$results$perimeter [1]\npixels_to_cm(px = ls_px , dpi = 300)\n\n[1] 39.9265\n\n\nThe perimeter of object 1 adjusted by image resolution is very close to the known value (40 cm). Below, the values of all measures are adjusted by declaring the dpi argument in get_measures().\n\nimg_res_cor <- get_measures(img_res , dpi = 300)\n\nt(img_res_cor)\n\n                           1        2        3        4\nid                     1.000    2.000    3.000    4.000\nx                    668.995 1737.518 1737.571 1737.966\ny                    797.992  452.998 1296.354  939.007\narea                  99.812   24.994    7.006    7.934\narea_ch               99.686   24.911    7.008    7.892\nperimeter             39.926   19.964   10.083   11.902\nradius_mean            5.728    2.863    1.489    1.666\nradius_min             4.984    2.489    1.477    0.987\nradius_max             7.057    3.528    1.502    2.222\nradius_sd              0.629    0.314    0.004    0.422\ndiam_mean             11.456    5.726    2.979    3.332\ndiam_min               9.967    4.978    2.955    1.974\ndiam_max              14.114    7.055    3.005    4.445\nmajor_axis            11.546    5.778    2.987    4.604\nminor_axis            11.526    5.768    2.986    2.297\nlength                11.121    6.514    2.994    3.990\nwidth                 11.107    6.503    2.996    1.985\nradius_ratio           1.416    1.417    1.017    2.252\neccentricity           0.997    0.996    0.994    0.348\ntheta                 -0.007    1.563   -1.547    0.000\nsolidity               1.001    1.003    1.000    1.005\nconvexity              0.750    0.749    0.905    0.836\nelongation             0.001    0.002   -0.001    0.502\ncircularity           15.971   15.946   14.512   17.854\ncircularity_haralick   9.111    9.127  423.369    3.947\ncircularity_norm       1.273    1.273    1.161    1.430\nasm                    0.949    0.913    0.829    0.853\ncon                    0.016    0.051    0.078    0.069\ncor                    0.797    0.731    0.781    0.786\nvar                    1.040    1.095    1.178    1.161\nidm                    0.995    0.987    0.975    0.979\nsav                   21.946   21.901   21.821   21.828\nsva                  478.992  475.312  468.297  470.245\nsen                    0.063    0.106    0.196    0.156\nent                    0.069    0.116    0.220    0.176\ndva                    0.016    0.051    0.078    0.069\nden                    0.024    0.054    0.090    0.076\nf12                    0.674    0.518    0.523    0.555\nf13                    0.260    0.279    0.380    0.356\n\n\n\n3.1.3 Understanding measurements\n\nobject_contour(img) %>% # get the contour of objects\n  poly_mass() %>% # computes center of mass and minimum and maximum radii\n  plot_mass() # plot the measurements\n\n\n\n\n\nLarger square:\nThe minimum diameter(a = 9.97) can be considered as the side of the square\nThe maximum diameter, given by \\(a \\sqrt {2}\\) can be considered the diagonal of the square (\\(9.97 \\sqrt {2} = 14,099 \\approx 14,105\\)\n\n\n\nt(img_res_cor)\n\n                           1        2        3        4\nid                     1.000    2.000    3.000    4.000\nx                    668.995 1737.518 1737.571 1737.966\ny                    797.992  452.998 1296.354  939.007\narea                  99.812   24.994    7.006    7.934\narea_ch               99.686   24.911    7.008    7.892\nperimeter             39.926   19.964   10.083   11.902\nradius_mean            5.728    2.863    1.489    1.666\nradius_min             4.984    2.489    1.477    0.987\nradius_max             7.057    3.528    1.502    2.222\nradius_sd              0.629    0.314    0.004    0.422\ndiam_mean             11.456    5.726    2.979    3.332\ndiam_min               9.967    4.978    2.955    1.974\ndiam_max              14.114    7.055    3.005    4.445\nmajor_axis            11.546    5.778    2.987    4.604\nminor_axis            11.526    5.768    2.986    2.297\nlength                11.121    6.514    2.994    3.990\nwidth                 11.107    6.503    2.996    1.985\nradius_ratio           1.416    1.417    1.017    2.252\neccentricity           0.997    0.996    0.994    0.348\ntheta                 -0.007    1.563   -1.547    0.000\nsolidity               1.001    1.003    1.000    1.005\nconvexity              0.750    0.749    0.905    0.836\nelongation             0.001    0.002   -0.001    0.502\ncircularity           15.971   15.946   14.512   17.854\ncircularity_haralick   9.111    9.127  423.369    3.947\ncircularity_norm       1.273    1.273    1.161    1.430\nasm                    0.949    0.913    0.829    0.853\ncon                    0.016    0.051    0.078    0.069\ncor                    0.797    0.731    0.781    0.786\nvar                    1.040    1.095    1.178    1.161\nidm                    0.995    0.987    0.975    0.979\nsav                   21.946   21.901   21.821   21.828\nsva                  478.992  475.312  468.297  470.245\nsen                    0.063    0.106    0.196    0.156\nent                    0.069    0.116    0.220    0.176\ndva                    0.016    0.051    0.078    0.069\nden                    0.024    0.054    0.090    0.076\nf12                    0.674    0.518    0.523    0.555\nf13                    0.260    0.279    0.380    0.356"
  },
  {
    "objectID": "03_analyze.html#texture-features",
    "href": "03_analyze.html#texture-features",
    "title": "Analyze objects",
    "section": "\n3.2 Texture features",
    "text": "3.2 Texture features\nThe function computes 13 Haralick texture features for each object based on a gray-level co-occurrence matrix (Haralick et al. 1979)8. Haralick features depend on the configuration of the parameters har_nbins and har_scales. har_nbins controls the number of bins used to compute the Haralick matrix. A smaller har_nbins can give more accurate estimates of the correlation because the number of events per bin is higher. While a higher value will give more sensitivity. har_scales controls the number of scales used to compute the Haralick features. Since Haralick features compute the correlation of intensities of neighboring pixels, it is possible to identify textures with different scales, e.g., a texture that is repeated every two pixels or 10 pixels. By default, the Haralick features are computed with the R band. To chance this default, use the argument har_band. For example, har_band = 2 will compute the features with the green band.\nThe followig measures are returned (fore more details, see this post)\n\n\nasm: The angular second-moment feature.\n\ncon: The contrast feature\n\ncor: Correlation measures the linear dependency of gray levels of neighboring pixels.\n\nvar: The variance of gray levels pixels.\n\nidm: The Inverse Difference Moment (IDM), i.e., the local homogeneity.\n\nsav: The Sum Average.\n\nsva: The Sum Variance.\n\nsen: Sum Entropy.\n\ndva: Difference Variance.\n\nden: Difference Entropy\n\nf12: Difference Variance.\n\nf13: The angular second-moment feature."
  },
  {
    "objectID": "03_analyze.html#single-image-processing",
    "href": "03_analyze.html#single-image-processing",
    "title": "Analyze objects",
    "section": "\n3.3 Single image processing",
    "text": "3.3 Single image processing\nThe analyze_objects() function calculates a range of measurements that can be used to study the shape and texture of objects, such as leaves. In the following example, I show how to plot the length and width of each leaf in the following image.\n\nleaves <- image_import(\"folhas.jpg\", plot = TRUE)\n\n\n\nleaves_meas <-\n  analyze_objects(leaves ,\n                  watershed = FALSE,\n                  col_background = \"black\")\n\nleaves_cor <- get_measures(leaves_meas , dpi = 300)\n\nt(leaves_cor)\n\n                            1       2\nid                      1.000   2.000\nx                     528.542 234.020\ny                     299.984 825.798\narea                    5.862   3.879\narea_ch                 5.946   4.227\nperimeter              12.157   9.942\nradius_mean             1.591   1.145\nradius_min              0.735   0.838\nradius_max              2.683   1.677\nradius_sd               0.582   0.219\ndiam_mean               3.181   2.290\ndiam_min                1.470   1.675\ndiam_max                5.366   3.353\nmajor_axis              4.843   2.864\nminor_axis              1.563   1.744\nlength                  5.241   3.210\nwidth                   1.602   1.883\nradius_ratio            3.650   2.002\neccentricity            0.136   0.425\ntheta                  -1.057  -0.087\nsolidity                0.986   0.918\nconvexity               0.913   0.791\nelongation              0.694   0.413\ncircularity            25.209  25.478\ncircularity_haralick    2.735   5.219\ncircularity_norm        2.021   2.047\nasm                     0.044   0.172\ncon                     1.120   0.495\ncor                     0.942   0.814\nvar                    10.687   2.328\nidm                     0.778   0.814\nsav                    38.905  28.391\nsva                  1449.029 763.014\nsen                     1.337   0.856\nent                     1.573   1.002\ndva                     1.120   0.495\nden                     0.407   0.328\nf12                     0.526   0.352\nf13                     0.822   0.590\n\n# plot width and length\nplot_measures(leaves_cor , measure = \"width\")\nplot_measures(leaves_cor , measure = \"length\", vjust = 50)\n\n\n\n\nHere, we will count the grains in the grains.jpg image. This image has a cyan background and contains 90 soybeans that touch each other. The analyze_objects() function segments the image using the normalized blue index by default, as follows \\(NB =(B /(R + G + B))\\), where R, G and B  are the red, green and blue bands. Note that if the image is contained in the default directory, it is not necessary to import it. Just enter the image name in quotes in the img argument(e.g., img = \"grains\").\nIn this example, objects are counted and segmented objects are colored with random colors using the show_segmentation = TRUE argument. Users can set show_contour = FALSE to remove the contour line and identify the objects (in this example, the grains) using the marker = \"id\" arguments. The background color can also be changed with col_background.\n\ncount <-\n  analyze_objects(\"grains\",\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\n\n\n\ncount$statistics\n\n       stat       value\n1         n    90.00000\n2  min_area   446.00000\n3 mean_area   675.45556\n4  max_area   842.00000\n5   sd_area    71.65494\n6  sum_area 60791.00000\n\n\n\n# Get the measurements of the object\nmeasurements <- get_measures(count)\nhead(measurements)\n\n  id       x       y area area_ch perimeter radius_mean radius_min radius_max\n1  1 351.890 411.183  842     810   104.497      15.911     14.847     16.897\n2  2 824.970 264.736  822     801   107.083      15.740     13.563     17.782\n3  3 811.263 198.825  738     712    98.497      14.876     14.129     15.379\n4  4 710.004 262.800  761     733   100.255      15.112     12.886     17.048\n5  5 807.122 341.979  757     724    98.841      15.072     13.745     16.714\n6  6 818.892 714.864  742     714    98.841      14.906     13.775     16.272\n  radius_sd diam_mean diam_min diam_max major_axis minor_axis length  width\n1     0.465    31.822   29.695   33.793     33.506     32.027 33.480 32.195\n2     1.201    31.480   27.126   35.565     35.775     29.288 35.413 29.731\n3     0.309    29.752   28.258   30.759     30.739     30.581 30.445 30.323\n4     1.175    30.224   25.773   34.097     34.365     28.228 33.818 27.708\n5     0.771    30.144   27.489   33.428     33.056     29.186 33.005 29.399\n6     0.635    29.812   27.550   32.543     32.191     29.373 31.766 29.094\n  radius_ratio eccentricity  theta solidity convexity elongation circularity\n1        1.138        0.938  1.224    1.040     0.936      0.038      12.969\n2        1.311        0.742 -0.327    1.026     0.923      0.160      13.950\n3        1.088        0.975 -1.283    1.037     0.904      0.004      13.146\n4        1.323        0.749 -0.261    1.038     0.882      0.181      13.208\n5        1.216        0.812  0.544    1.046     0.867      0.109      12.906\n6        1.181        0.864 -1.197    1.039     0.886      0.084      13.166\n  circularity_haralick circularity_norm   asm   con   cor   var   idm    sav\n1               34.181            1.092 0.066 0.850 0.912 5.837 0.733 32.747\n2               13.107            1.179 0.080 0.975 0.883 5.179 0.746 33.476\n3               48.152            1.112 0.059 0.888 0.920 6.566 0.706 34.419\n4               12.857            1.117 0.053 0.917 0.911 6.166 0.724 33.375\n5               19.539            1.091 0.065 0.855 0.909 5.681 0.727 32.003\n6               23.486            1.115 0.058 0.847 0.924 6.564 0.720 30.684\n       sva   sen   ent   dva   den   f12   f13\n1 1014.530 1.187 1.418 0.850 0.421 0.445 0.745\n2 1061.010 1.145 1.356 0.975 0.429 0.445 0.735\n3 1121.793 1.247 1.482 0.888 0.428 0.461 0.767\n4 1052.364 1.241 1.478 0.917 0.429 0.456 0.763\n5  967.498 1.187 1.407 0.855 0.416 0.447 0.745\n6  889.380 1.223 1.446 0.847 0.419 0.465 0.764\n\n\nIn the following example, we will select objects with an area above the average of all objects using lower_size = 719.1.\n\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                lower_size = 719.1)\n\n\n\n\nUsers can also use the topn _* arguments to select the n objects based on the smallest or largest areas. Let’s see how to select the 5 grains with the smallest area, showing the original grains on a blue background. We will also use the my_index argument to choose a custom index to segment the image. Just for comparison, we will explicitly set the normalized blue index by calling my_index = \"B /(R + G + B)\".\n\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                topn_lower = 5,\n                col_background = \"salmon\",\n                my_index = \"B /(R + G + B)\") # normalized blue(NB)"
  },
  {
    "objectID": "03_analyze.html#batch-processing",
    "href": "03_analyze.html#batch-processing",
    "title": "Analyze objects",
    "section": "\n3.4 Batch processing",
    "text": "3.4 Batch processing\nIn image analysis, it is often necessary to process more than one image. For example, in plant breeding, the number of grains per plant(eg wheat) is often used in indirect selection of high-yielding plants. In pliman, batch processing can be done when the user declares the pattern argument.\nTo speed up processing time, especially for large numbers of images, the parallel = TRUE argument can be used. In this case, images are processed asynchronously (in parallel) in separate R sessions running in the background on the same machine. The number of sections is set to 50% of available cores. This number can be explicitly controlled with the workers argument.\n\nsystem.time(\n  list_res <- analyze_objects(pattern = \"img_sb\", show_image = FALSE)\n)\n\nProcessing image img_sb_50_1 |===                                | 8% 00:00:00 \nProcessing image img_sb_50_10 |=====                             | 15% 00:00:01 \nProcessing image img_sb_50_11 |========                          | 23% 00:00:01 \nProcessing image img_sb_50_12 |==========                        | 31% 00:00:02 \nProcessing image img_sb_50_13 |=============                     | 38% 00:00:02 \nProcessing image img_sb_50_2 |================                   | 46% 00:00:02 \nProcessing image img_sb_50_3 |===================                | 54% 00:00:04 \nProcessing image img_sb_50_4 |======================             | 62% 00:00:05 \nProcessing image img_sb_50_5 |========================           | 69% 00:00:06 \nProcessing image img_sb_50_6 |===========================        | 77% 00:00:07 \nProcessing image img_sb_50_7 |==============================     | 85% 00:00:08 \nProcessing image img_sb_50_8 |================================   | 92% 00:00:08 \nProcessing image img_sb_50_9 |===================================| 100% 00:00:09 \n--------------------------------------------\n        Image Objects\n  img_sb_50_1     100\n img_sb_50_10      29\n img_sb_50_11      23\n img_sb_50_12      15\n img_sb_50_13       7\n  img_sb_50_2      90\n  img_sb_50_3      83\n  img_sb_50_4      75\n  img_sb_50_5      70\n  img_sb_50_6      60\n  img_sb_50_7      57\n  img_sb_50_8      48\n  img_sb_50_9      36\n--------------------------------------------\n\n\nDone!\n\n\n  usuário   sistema decorrido \n     9.49      0.69     10.18 \n\n# parallel processing\n# 6 multiple sections (50% of my pc's cores)\nsystem.time(\n  list_res <-\n    analyze_objects(pattern = \"img_sb\",\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\nImage processing using multiple sessions (6). Please wait.\n\n\n--------------------------------------------\n        Image Objects\n  img_sb_50_1     100\n img_sb_50_10      29\n img_sb_50_11      23\n img_sb_50_12      15\n img_sb_50_13       7\n  img_sb_50_2      90\n  img_sb_50_3      83\n  img_sb_50_4      75\n  img_sb_50_5      70\n  img_sb_50_6      60\n  img_sb_50_7      57\n  img_sb_50_8      48\n  img_sb_50_9      36\n--------------------------------------------\n\n\nDone!\n\n\n  usuário   sistema decorrido \n     0.09      0.01      5.39"
  },
  {
    "objectID": "03_analyze.html#known-resolution",
    "href": "03_analyze.html#known-resolution",
    "title": "Analyze objects",
    "section": "\n8.1 Known resolution",
    "text": "8.1 Known resolution\n\nleaves <- image_import(image = \"ref_leaves.jpg\", plot = TRUE)\n\n\n\naf <-\n  analyze_objects(leaves ,\n                  watershed = FALSE,\n                  show_contour = FALSE,\n                  col_background = \"black\",\n                  marker = \"id\")\naf_cor <- get_measures(af, dpi = 50.5)\n\nplot_measures(af_cor ,\n              measure = \"area\",\n              vjust = -30,\n              col = \" red \")"
  },
  {
    "objectID": "03_analyze.html#reference-object-dev-version",
    "href": "03_analyze.html#reference-object-dev-version",
    "title": "Analyze objects",
    "section": "\n8.2 Reference object (dev version)",
    "text": "8.2 Reference object (dev version)\n\n8.2.1 Single images\nThe reference argument can now be used to correct the object measures even when images with different shooting distances are used. In this example, the leaf area of the ref_leaves image is quantified and corrected considering a 5 x 5 (25 cm\\(^2\\)) white square as the reference object. For this, it is necessary to provide color palettes referring to the background (background), leaves (foreground) and the reference object (reference). Also, the area of the reference object needs to be informed in reference_area.\n\nlibrary(pliman)\nimg <- image_import(pattern = \"ref_\", plot = TRUE)\n\n\n\narea <-\n  analyze_objects(img = \"ref_leaves\",\n                  foreground = \"ref_folha\",\n                  background = \"ref_back\",\n                  reference = \"ref_ref\",\n                  reference_area = 25,\n                  marker = \"area\",\n                  watershed = FALSE)\n\n\n\n\n\n8.2.2 Multiple images\n\nres <-\n  analyze_objects(pattern = \"img_\",\n                  dir_original = \"linhaca\",\n                  foreground = \"folhalin\",\n                  background = \"fundolin\",\n                  reference = \"reflin\",\n                  reference_area = 20,\n                  watershed = FALSE,\n                  filter = 3)\n\nProcessing image img_A1_B1 |=====                                | 12% 00:00:00 \n\n\n\n\n\nProcessing image img_A1_B2 |=========                            | 25% 00:00:01 \n\n\n\n\n\nProcessing image img_A2_B1 |==============                       | 38% 00:00:03 \n\n\n\n\n\nProcessing image img_A2_B2 |==================                   | 50% 00:00:06 \n\n\n\n\n\nProcessing image img_A3_B1 |=======================              | 62% 00:00:08 \n\n\n\n\n\nProcessing image img_A3_B2 |============================         | 75% 00:00:11 \n\n\n\n\n\nProcessing image img_A4_B1 |================================     | 88% 00:00:14 \n\n\n\n\n\nProcessing image img_A4_B2 |=====================================| 100% 00:00:16 \n\n\n--------------------------------------------\n     Image Objects\n img_A1_B1      19\n img_A1_B2      22\n img_A2_B1      33\n img_A2_B2      23\n img_A3_B1      65\n img_A3_B2      44\n img_A4_B1      56\n img_A4_B2      57\n--------------------------------------------\n\n\nDone!\n\n\n\n\narea <- \n  res$results |> \n  separate_col(img, \n               into = c(\"img\", \"avaliacao\", \"block\"))\n\n\ndf_plot <- \n  area |> \n  sum_by(avaliacao, block, .vars = area) |> \n  group_by(avaliacao) |> \n  desc_stat(area, stats = c(\"mean, sd.amo\"))\n\n\n\n\nggplot(df_plot, aes(avaliacao, mean)) + \n  geom_point() +\n  geom_errorbar(aes(ymin = mean - sd.amo, \n                    ymax = mean + sd.amo),\n                width = 0.2) +\n  labs(x = \"Período de avaliação\",\n       y = \"Área foliar (cm2 por planta)\") +\n  theme_bw(base_size = 16)"
  },
  {
    "objectID": "03_analyze.html#filling-holes",
    "href": "03_analyze.html#filling-holes",
    "title": "Analyze objects",
    "section": "\n8.3 Filling ‘holes’",
    "text": "8.3 Filling ‘holes’\nAn important aspect to consider in leaf area measures is when leaves present ‘holes’. This can occur, for example, by the attack of pests. In this case, the area would have to be considered, because it was there! The image bellow is used as an example.\n\nholes <- image_import(\"holes.jpg\", plot = TRUE)\n\n\n\n\nIn this case, the missing area will not be computed using the default settings of analyze_objects(). To include this area as the leaf area, we can use the argument fill_hull(). Note that this will only work for missing areas within a closed object. If the missing area includes the original leaf contour, there is no (yet available) way to reconstruct the leaf perimeter.\n\naf <-\n  analyze_objects(holes,\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\n# fill the missing area\naf2 <-\n  analyze_objects(holes,\n                  fill_hull = TRUE, # fill ' holes '\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  prefix = \"proc2_\",\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\nimgs <- image_import(pattern = \"proc\", path = tempdir())\nimage_combine(imgs)\n\n\n\n\nWe can simply use the ratio between proc_img and proc_img2 to compute the injured area in this leaflet.\n\n# percent of injuried area\n100 - 88379 / 99189 * 100\n\n[1] 10.89839"
  },
  {
    "objectID": "03_analyze.html#compound-leaves",
    "href": "03_analyze.html#compound-leaves",
    "title": "Analyze objects",
    "section": "\n8.4 Compound leaves",
    "text": "8.4 Compound leaves\nA simple leaf blade is undivided. The blade of a compound leaf is divided into several leaflets. In the following examples, I will show how to analyze simple and compound leaves with analyze_objects(), mainly if the goal is to obtain the measures for each leaf (e.g., mean area), where the number of objects (leaves) will influence the results.\nThe following images by Daniel Saueressig were obtained from the Sistema de Identificação Dendrológica Online - Floresta Ombrófila Mista9 and show examples of simple and compound leaves.\n\nimgs <- \n  image_import(c(\"simple.jpg\", \"compound.jpg\"),\n               plot = TRUE)\n\n\n\n\nAnalyzing non-touching simple leaves is fairly simple. We already did that. The squares in the background have 4 cm\\(^2\\). With this information, it is possible to obtain the image resolution with dpi(simple), which will be useful to adjust the measures. In this case, the estimated dpi is 48.65.\n\nsimple <- imgs$simple.jpg\nsarea <- analyze_objects(simple, marker = \"id\")\n\n\n\n\nNote that with the default settings, the simple leaf was partitioned into small, segmented leaves. This can be solved by either using object_size = \"large\" or watershed = FALSE, to omit the watershed segmentation algorithm. The last is used here.\n\nsarea <- \n  analyze_objects(simple,\n                  watershed = FALSE,\n                  marker = \"id\",\n                  show_chull = TRUE)\n\n\n\nsarea_cor <- get_measures(sarea, dpi = 48.65)\nsarea_cor\n\n  id       x       y   area area_ch perimeter radius_mean radius_min radius_max\n1  1 184.643 156.157 41.417  56.267    41.308       4.285      1.070      7.953\n2  2  68.637 151.759 20.035  31.852    31.560       3.030      1.095      5.717\n  radius_sd diam_mean diam_min diam_max major_axis minor_axis length width\n1     1.801      8.57    2.139   15.906     13.661      4.225 15.474 6.041\n2     1.215      6.06    2.190   11.433      9.237      3.194 11.068 4.698\n  radius_ratio eccentricity theta solidity convexity elongation circularity\n1        7.435        0.133 1.489    0.736     0.685      0.610      41.200\n2        5.220        0.147 1.552    0.629     0.638      0.576      49.715\n  circularity_haralick circularity_norm   asm   con   cor    var   idm    sav\n1                2.379            3.356 0.043 1.671 0.845  6.401 0.663 23.134\n2                2.493            4.106 0.048 3.761 0.811 10.970 0.647 22.952\n     sva   sen   ent   dva   den   f12   f13\n1 499.01 1.246 1.618 1.671 0.516 0.319 0.677\n2 507.26 1.246 1.663 3.761 0.603 0.287 0.654\n\n\nFor compound leaves, if the watershed segmentation is used, leaflets will probably be considered as different leaves, as can be seen below.\n\ncompound <- imgs$compound.jpg\ncarea <- \n  analyze_objects(compound,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\n\n\n\n\nTherefore, using watershed = FALSE will solve this problem, since all leaflets connected by at least one pixel will be considered part of the same leaf.\n\ncarea <- \n  analyze_objects(compound,\n                  watershed = FALSE,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  show_chull = TRUE,\n                  marker = \"id\")\n\n\n\ncarea_cor <- get_measures(carea, dpi = 49.5)\ncarea_cor\n\n  id       x       y   area area_ch perimeter radius_mean radius_min radius_max\n2  1 114.593  91.213 15.890  33.168    48.779       2.254      0.018      4.964\n3  2 113.124 244.782 18.895  43.161    54.501       2.548      0.056      5.940\n  radius_sd diam_mean diam_min diam_max major_axis minor_axis length width\n2     1.148     4.509    0.035    9.929      6.954      5.552  8.135 6.435\n3     1.260     5.097    0.112   11.879      8.404      6.577  9.339 7.142\n  radius_ratio eccentricity  theta solidity convexity elongation circularity\n2      280.481        0.506 -0.263    0.479     0.425      0.209     149.739\n3      105.791        0.656  0.709    0.438     0.479      0.235     157.203\n  circularity_haralick circularity_norm   asm   con   cor   var   idm    sav\n2                1.964           12.783 0.047 2.223 0.753 5.507 0.666 27.342\n3                2.023           13.363 0.054 1.100 0.838 4.386 0.711 18.751\n      sva   sen   ent   dva   den   f12   f13\n2 700.322 1.179 1.559 2.223 0.543 0.279 0.630\n3 322.551 1.141 1.448 1.100 0.456 0.328 0.658"
  },
  {
    "objectID": "03_analyze.html#multiple-images-of-the-same-sample",
    "href": "03_analyze.html#multiple-images-of-the-same-sample",
    "title": "Analyze objects",
    "section": "\n8.5 Multiple images of the same sample",
    "text": "8.5 Multiple images of the same sample\nIf users need to analyze multiple images from the same sample, the images must share the same filename prefix, which is defined as the part of the filename that precedes the first hyphen (-) or underscore (_). Then, when using get_measures(), measurements from leaf images called, for example, F1-1.jpeg, F1_2.jpeg and F1-3.jpeg will be combined into a single image (F1), displayed in the merge object. This is useful, for example, for analyzing large sheets that need to be split into multiple images or multiple sheets belonging to the same sample that cannot be scanned into a single image.\nIn the following example, five images will be used as examples. Each image has leaves of different species. The images have been split into different images that share the same prefix (eg L1_*, L2_*, and so on). Note that to ensure that all images are processed, all images must share a common pattern, in this case (\"L\"). The three dots in the lower right corner have a known distance of 5 cm between them, which can be used to extract the dpi of the image with dpi(). For teaching purposes only, I will assume that all images are 100 dpi resolution .\n\n# entire images\nimgs <-\n  image_import(pattern = \"leaf\",\n               plot = TRUE,\n               ncol = 2)\n\n\n\n# images of the same sample\nsample_imgs <-\n  image_import(pattern = \"L\",\n               plot = TRUE,\n               ncol = 5)\n\n\n\n\nHere, I will use the pattern = \"L\" to indicate that all images with this pattern name should be merged. The green index (\"G\") is used to segment the leaves and watershed = FALSE is used to omit the watershed segmentation algorithm.\n\nmerged <-\n  analyze_objects(pattern = \"L\",\n                  index = \"B\",\n                  watershed = FALSE)\n\nProcessing image L1_1 |====                                      | 8% 00:00:00 \n\n\n\n\n\nProcessing image L1_2 |=======                                   | 17% 00:00:00 \n\n\n\n\n\nProcessing image L2_1 |==========                                | 25% 00:00:01 \n\n\n\n\n\nProcessing image L2_2 |==============                            | 33% 00:00:01 \n\n\n\n\n\nProcessing image L3_1 |==================                        | 42% 00:00:01 \n\n\n\n\n\nProcessing image L3_2 |=====================                     | 50% 00:00:02 \n\n\n\n\n\nProcessing image L3_3 |========================                  | 58% 00:00:02 \n\n\n\n\n\nProcessing image L4_1 |============================              | 67% 00:00:02 \n\n\n\n\n\nProcessing image L4_2 |================================          | 75% 00:00:03 \n\n\n\n\n\nProcessing image L4_3 |===================================       | 83% 00:00:03 \n\n\n\n\n\nProcessing image L5_1 |======================================    | 92% 00:00:03 \n\n\n\n\n\nProcessing image L5_2 |==========================================| 100% 00:00:04 \n\n\n--------------------------------------------\n Image Objects\n  L1_1       1\n  L1_2       1\n  L2_1       2\n  L2_2       3\n  L3_1       1\n  L3_2       1\n  L3_3       1\n  L4_1       2\n  L4_2       2\n  L4_3       3\n  L5_1       3\n  L5_2       3\n--------------------------------------------\n\n\nDone!\n\n\n\n\n\nUsing the get_measures() function it is possible to convert measurements from pixel units to metric units(cm\\(^ 2\\)).\n\nmerged_cor <- get_measures(merged, dpi = 100)\n\nNote that the merged_cor` is a list with three objects:\n\n\nresults: a data frame that contains the measurements of each individual object (in this case, leaf) of each analyzed image.\n\n\nmerged_cor$results\n\n    img id       x       y    area area_ch perimeter radius_mean radius_min\n1  L1_1  1 427.651 516.720 102.091   7.427   133.758       6.213      0.565\n2  L1_2  1 372.493 526.103  92.764   5.262   124.363       5.335      1.048\n3  L2_1  1 251.395 282.805  46.317   1.188    28.464       3.937      2.525\n4  L2_1  2 146.358 701.888  35.300   0.918    25.697       3.441      2.314\n5  L2_2  1 326.111 391.144  19.027   0.488    19.495       2.614      1.660\n6  L2_2  2 113.863 755.333  38.151   0.983    25.176       3.535      2.517\n7  L2_2  3 376.185 784.765  16.317   0.418    17.262       2.367      1.530\n8  L3_1  1 253.948 480.245  64.030   2.994    92.378       4.204      0.408\n9  L3_2  1 200.085 436.480  30.204   1.462    63.319       2.829      0.065\n10 L3_3  1 204.972 363.480  51.966   2.219    93.421       3.495      0.073\n11 L4_1  1 270.224 326.531  54.353   1.392    29.454       4.181      3.401\n12 L4_1  3 252.939 845.147  61.670   1.626    34.277       4.536      3.678\n13 L4_2  1 291.918 235.531  61.482   1.597    33.038       4.544      3.158\n14 L4_2  2 260.741 799.763  73.238   1.915    36.282       4.938      3.761\n15 L4_3  1 206.165 213.369  29.187   0.752    22.372       3.097      2.053\n16 L4_3  2 219.504 552.867  19.512   0.520    19.495       2.598      1.609\n17 L4_3  3 229.146 937.131  34.152   0.900    27.177       3.471      2.211\n18 L5_1  1 225.324 275.743  52.788   1.383    35.509       4.591      2.262\n19 L5_1  2 120.375 887.851  30.186   0.821    30.527       3.827      1.648\n20 L5_1  3 335.521 884.863  31.673   0.828    28.115       3.621      1.731\n21 L5_2  1 338.958 300.167  45.584   1.189    34.031       4.329      2.190\n22 L5_2  2 205.349 802.627  42.838   1.114    33.268       4.266      2.049\n23 L5_2  3 535.296 819.587  44.986   1.175    33.299       4.300      1.992\n   radius_max radius_sd diam_mean diam_min diam_max major_axis minor_axis\n1      11.927     2.899    12.426    1.130   23.853     19.865     15.143\n2      10.164     2.189    10.669    2.096   20.327     15.129     13.217\n3       5.915     0.911     7.873    5.049   11.830     10.478      5.708\n4       5.204     0.819     6.882    4.627   10.408      9.307      4.873\n5       4.134     0.736     5.227    3.320    8.268      7.300      3.375\n6       5.093     0.665     7.070    5.035   10.185      8.955      5.462\n7       3.609     0.606     4.734    3.060    7.219      6.510      3.237\n8       9.466     2.050     8.407    0.817   18.932     15.228      8.684\n9       6.578     1.425     5.658    0.130   13.155      9.857      7.103\n10      7.816     1.656     6.990    0.146   15.632     12.405      8.416\n11      5.708     0.559     8.362    6.803   11.415      9.917      7.035\n12      6.506     0.705     9.071    7.356   13.012     10.548      7.549\n13      6.585     0.821     9.088    6.316   13.170     10.968      7.277\n14      6.971     0.780     9.875    7.521   13.941     11.609      8.148\n15      4.379     0.668     6.195    4.107    8.758      8.257      4.534\n16      3.939     0.648     5.196    3.218    7.879      7.069      3.549\n17      5.147     0.799     6.943    4.422   10.294      8.810      5.089\n18      7.740     1.623     9.182    4.523   15.481     13.610      5.029\n19      6.794     1.523     7.654    3.297   13.589     11.055      3.579\n20      6.200     1.321     7.241    3.463   12.399     10.717      3.823\n21      7.462     1.610     8.659    4.379   14.925     13.162      4.461\n22      7.335     1.584     8.533    4.098   14.670     12.765      4.353\n23      7.465     1.584     8.600    3.983   14.930     13.069      4.449\n   length   width radius_ratio eccentricity  theta solidity convexity\n1  21.589 722.973       21.109        0.638  0.158    0.349     0.402\n2  16.895 579.711        9.696        0.805  0.600    0.448     0.387\n3  11.347 234.524        2.343        0.390  1.502    0.990     0.928\n4  10.313 198.853        2.249        0.371 -1.533    0.977     0.908\n5   8.154 140.030        2.491        0.272  1.560    0.990     0.911\n6   9.780 222.355        2.023        0.475  1.556    0.986     0.915\n7   7.151 137.698        2.359        0.325  1.395    0.992     0.928\n8  15.717 391.913       23.182        0.369 -1.550    0.543     0.384\n9  10.814 323.238      101.214        0.511  1.564    0.525     0.395\n10 13.411 365.216      107.425        0.467  1.539    0.595     0.385\n11 10.444 285.934        1.678        0.610  1.484    0.992     0.903\n12 11.942 313.755        1.769        0.552  1.428    0.964     0.871\n13 12.132 297.157        2.085        0.473 -1.332    0.978     0.907\n14 12.743 326.311        1.854        0.520  1.527    0.971     0.842\n15  8.531 181.471        2.133        0.411 -1.535    0.986     0.895\n16  7.552 145.609        2.448        0.322  1.537    0.954     0.868\n17  9.491 210.669        2.328        0.344  1.471    0.964     0.845\n18 15.329 204.320        3.423        0.174 -1.479    0.970     0.888\n19 13.489 149.278        4.122        0.109 -1.564    0.934     0.917\n20 12.264 159.481        3.581        0.156  1.382    0.971     0.901\n21 14.760 183.121        3.408        0.152 -1.547    0.974     0.894\n22 14.614 179.397        3.580        0.144  1.508    0.976     0.912\n23 14.488 185.910        3.748        0.155 -1.450    0.973     0.916\n   elongation circularity circularity_haralick circularity_norm   asm   con\n1       0.149     175.249                2.143           14.149 0.169 0.302\n2       0.128     166.727                2.437           13.463 0.189 0.347\n3       0.475      17.492                4.320            1.401 0.168 0.244\n4       0.510      18.706                4.199            1.500 0.255 0.168\n5       0.564      19.975                3.549            1.608 0.177 0.172\n6       0.423      16.613                5.318            1.331 0.200 0.189\n7       0.511      18.263                3.907            1.470 0.212 0.224\n8       0.367     133.276                2.051           10.649 0.262 0.238\n9       0.241     132.739                1.985           10.813 0.231 0.295\n10      0.308     167.949                2.111           13.621 0.399 0.204\n11      0.305      15.961                7.481            1.278 0.277 0.136\n12      0.333      19.052                6.431            1.525 0.366 0.113\n13      0.378      17.753                5.534            1.421 0.253 0.172\n14      0.350      17.974                6.327            1.438 0.300 0.162\n15      0.460      17.148                4.636            1.376 0.427 0.149\n16      0.510      19.478                4.010            1.567 0.380 0.164\n17      0.436      21.627                4.346            1.736 0.294 0.152\n18      0.661      23.886                2.829            1.915 0.267 0.184\n19      0.719      30.872                2.512            2.485 0.304 0.181\n20      0.670      24.957                2.741            2.006 0.378 0.165\n21      0.685      25.406                2.690            2.039 0.311 0.218\n22      0.688      25.836                2.694            2.074 0.393 0.228\n23      0.674      24.648                2.714            1.978 0.302 0.188\n     cor   var   idm    sav    sva   sen   ent   dva   den   f12   f13\n1  0.912 2.707 0.896  8.593 65.679 0.902 0.995 0.302 0.247 0.590 0.752\n2  0.881 2.455 0.879  7.598 50.922 0.856 0.963 0.347 0.270 0.516 0.699\n3  0.922 2.557 0.899  9.682 83.240 0.892 0.977 0.244 0.236 0.593 0.749\n4  0.936 2.305 0.933  7.446 49.798 0.756 0.813 0.168 0.182 0.659 0.742\n5  0.946 2.596 0.922 10.430 97.784 0.861 0.920 0.172 0.197 0.663 0.774\n6  0.941 2.598 0.923  7.647 52.459 0.846 0.911 0.189 0.199 0.658 0.768\n7  0.888 2.003 0.905  6.667 38.384 0.785 0.858 0.224 0.223 0.561 0.699\n8  0.912 2.355 0.918  5.438 27.026 0.765 0.840 0.238 0.213 0.607 0.720\n9  0.898 2.442 0.891  5.250 25.212 0.807 0.903 0.295 0.252 0.525 0.689\n10 0.905 2.069 0.937  3.221 11.024 0.585 0.645 0.204 0.181 0.607 0.656\n11 0.913 1.784 0.938  7.577 50.688 0.671 0.718 0.136 0.168 0.641 0.701\n12 0.882 1.478 0.950  7.710 52.805 0.568 0.606 0.113 0.146 0.639 0.659\n13 0.907 1.923 0.929  6.449 36.264 0.727 0.787 0.172 0.188 0.625 0.715\n14 0.884 1.699 0.935  7.157 44.739 0.668 0.723 0.162 0.179 0.615 0.688\n15 0.899 1.735 0.939  4.710 20.011 0.560 0.611 0.149 0.170 0.582 0.628\n16 0.879 1.680 0.936  5.071 22.756 0.576 0.630 0.164 0.176 0.583 0.636\n17 0.890 1.694 0.939  5.520 26.487 0.635 0.687 0.152 0.172 0.622 0.680\n18 0.883 1.781 0.946  4.571 18.167 0.669 0.723 0.184 0.161 0.680 0.725\n19 0.838 1.556 0.937  6.308 34.419 0.618 0.675 0.181 0.176 0.601 0.664\n20 0.810 1.436 0.953  4.902 20.716 0.527 0.575 0.165 0.147 0.643 0.648\n21 0.882 1.919 0.945  6.987 43.417 0.666 0.723 0.218 0.166 0.673 0.721\n22 0.755 1.467 0.934  6.771 40.603 0.529 0.585 0.228 0.185 0.526 0.584\n23 0.866 1.703 0.942  6.836 40.858 0.653 0.706 0.188 0.168 0.648 0.701\n\n\n\n\nsummary : a data frame that contains the summary of the results, containing the number of objects in each image (n) the sum, mean and standard deviation of the area of each image, as well as the average value for all others measurements (perimeter, radius, etc.)\n\n\nmerged_cor$summary\n\n    img n area_sum area_mean area_sd area_ch perimeter radius_mean radius_min\n1  L1_1 1  102.091   102.091   0.000   7.427   133.758       6.213      0.565\n2  L1_2 1   92.764    92.764   0.000   5.262   124.363       5.335      1.048\n3  L2_1 2   81.617    40.809   7.790   1.053    27.080       3.689      2.419\n4  L2_2 3   73.495    24.498  11.901   0.630    20.644       2.838      1.902\n5  L3_1 1   64.030    64.030   0.000   2.994    92.378       4.204      0.408\n6  L3_2 1   30.204    30.204   0.000   1.462    63.319       2.829      0.065\n7  L3_3 1   51.966    51.966   0.000   2.219    93.421       3.495      0.073\n8  L4_1 2  116.023    58.011   5.174   1.509    31.866       4.358      3.540\n9  L4_2 2  134.720    67.360   8.313   1.756    34.660       4.741      3.459\n10 L4_3 3   82.851    27.617   7.445   0.724    23.015       3.056      1.958\n11 L5_1 3  114.648    38.216  12.642   1.011    31.384       4.013      1.880\n12 L5_2 3  133.409    44.470   1.444   1.159    33.533       4.299      2.077\n   radius_max radius_sd diam_mean diam_min diam_max major_axis minor_axis\n1      11.927     2.899    12.426    1.130   23.853     19.865     15.143\n2      10.164     2.189    10.669    2.096   20.327     15.129     13.217\n3       5.559     0.865     7.378    4.838   11.119      9.893      5.290\n4       4.279     0.669     5.677    3.805    8.557      7.588      4.025\n5       9.466     2.050     8.407    0.817   18.932     15.228      8.684\n6       6.578     1.425     5.658    0.130   13.155      9.857      7.103\n7       7.816     1.656     6.990    0.146   15.632     12.405      8.416\n8       6.107     0.632     8.717    7.079   12.214     10.232      7.292\n9       6.778     0.801     9.482    6.919   13.556     11.288      7.712\n10      4.488     0.705     6.111    3.915    8.977      8.046      4.391\n11      6.911     1.489     8.026    3.761   13.823     11.794      4.144\n12      7.421     1.593     8.597    4.154   14.842     12.999      4.421\n   length   width radius_ratio eccentricity  theta solidity convexity\n1  21.589 722.973       21.109        0.638  0.158    0.349     0.402\n2  16.895 579.711        9.696        0.805  0.600    0.448     0.387\n3  10.830 216.689        2.296        0.381 -0.016    0.983     0.918\n4   8.362 166.694        2.291        0.357  1.504    0.989     0.918\n5  15.717 391.913       23.182        0.369 -1.550    0.543     0.384\n6  10.814 323.238      101.214        0.511  1.564    0.525     0.395\n7  13.411 365.216      107.425        0.467  1.539    0.595     0.385\n8  11.193 299.845        1.723        0.581  1.456    0.978     0.887\n9  12.437 311.734        1.969        0.496  0.097    0.975     0.874\n10  8.525 179.250        2.303        0.359  0.491    0.968     0.869\n11 13.694 171.027        3.709        0.146 -0.554    0.958     0.902\n12 14.620 182.810        3.579        0.150 -0.496    0.974     0.908\n   elongation circularity circularity_haralick circularity_norm   asm   con\n1       0.149     175.249                2.143           14.149 0.169 0.302\n2       0.128     166.727                2.437           13.463 0.189 0.347\n3       0.493      18.099                4.259            1.451 0.211 0.206\n4       0.499      18.284                4.258            1.470 0.196 0.195\n5       0.367     133.276                2.051           10.649 0.262 0.238\n6       0.241     132.739                1.985           10.813 0.231 0.295\n7       0.308     167.949                2.111           13.621 0.399 0.204\n8       0.319      17.506                6.956            1.401 0.321 0.125\n9       0.364      17.864                5.930            1.430 0.277 0.167\n10      0.469      19.418                4.331            1.560 0.367 0.155\n11      0.683      26.572                2.694            2.135 0.317 0.176\n12      0.682      25.297                2.699            2.030 0.336 0.211\n     cor   var   idm   sav    sva   sen   ent   dva   den   f12   f13\n1  0.912 2.707 0.896 8.593 65.679 0.902 0.995 0.302 0.247 0.590 0.752\n2  0.881 2.455 0.879 7.598 50.922 0.856 0.963 0.347 0.270 0.516 0.699\n3  0.929 2.431 0.916 8.564 66.519 0.824 0.895 0.206 0.209 0.626 0.746\n4  0.925 2.399 0.917 8.248 62.876 0.831 0.896 0.195 0.206 0.627 0.747\n5  0.912 2.355 0.918 5.438 27.026 0.765 0.840 0.238 0.213 0.607 0.720\n6  0.898 2.442 0.891 5.250 25.212 0.807 0.903 0.295 0.252 0.525 0.689\n7  0.905 2.069 0.937 3.221 11.024 0.585 0.645 0.204 0.181 0.607 0.656\n8  0.897 1.631 0.944 7.644 51.747 0.620 0.662 0.125 0.157 0.640 0.680\n9  0.896 1.811 0.932 6.803 40.502 0.697 0.755 0.167 0.183 0.620 0.702\n10 0.889 1.703 0.938 5.100 23.084 0.590 0.643 0.155 0.173 0.596 0.648\n11 0.844 1.591 0.946 5.260 24.434 0.605 0.658 0.176 0.162 0.641 0.679\n12 0.834 1.696 0.941 6.865 41.626 0.616 0.672 0.211 0.173 0.616 0.669\n\n\n\n\nmerge: a data frame that contains the results merged by image prefix. Note that in this case the results are displayed by L1, L2, L3, L4 and L5.\n\n\nmerged_cor$merge\n\n  img n area_sum area_mean area_sd area_ch perimeter radius_mean radius_min\n1  L1 2  194.854    97.427   0.000   6.345   129.061       5.774      0.807\n2  L2 5  155.112    32.653   9.846   0.841    23.862       3.264      2.161\n3  L3 3  146.200    48.733   0.000   2.225    83.039       3.509      0.182\n4  L4 7  333.594    50.996   6.977   1.330    29.847       4.052      2.986\n5  L5 6  248.056    41.343   7.043   1.085    32.458       4.156      1.979\n  radius_max radius_sd diam_mean diam_min diam_max major_axis minor_axis length\n1     11.045     2.544    11.547    1.613   22.090     17.497     14.180 19.242\n2      4.919     0.767     6.527    4.322    9.838      8.741      4.657  9.596\n3      7.953     1.710     7.018    0.364   15.906     12.497      8.068 13.314\n4      5.791     0.713     8.103    5.971   11.582      9.856      6.465 10.718\n5      7.166     1.541     8.311    3.957   14.332     12.396      4.282 14.157\n    width radius_ratio eccentricity  theta solidity convexity elongation\n1 651.342       15.402        0.722  0.379    0.398     0.395      0.139\n2 191.691        2.293        0.369  0.744    0.986     0.918      0.496\n3 360.122       77.274        0.449  0.517    0.554     0.388      0.305\n4 263.609        1.999        0.479  0.681    0.973     0.877      0.384\n5 176.918        3.644        0.148 -0.525    0.966     0.905      0.683\n  circularity circularity_haralick circularity_norm   asm   con   cor   var\n1     170.988                2.290           13.806 0.179 0.324 0.896 2.581\n2      18.191                4.259            1.460 0.204 0.201 0.927 2.415\n3     144.655                2.049           11.694 0.297 0.245 0.905 2.289\n4      18.263                5.739            1.464 0.322 0.149 0.894 1.715\n5      25.934                2.697            2.083 0.326 0.194 0.839 1.644\n    idm   sav    sva   sen   ent   dva   den   f12   f13\n1 0.888 8.096 58.300 0.879 0.979 0.324 0.259 0.553 0.726\n2 0.916 8.406 64.697 0.828 0.896 0.201 0.207 0.627 0.746\n3 0.915 4.637 21.087 0.719 0.796 0.245 0.215 0.580 0.688\n4 0.938 6.515 38.444 0.636 0.686 0.149 0.171 0.618 0.677\n5 0.943 6.062 33.030 0.610 0.665 0.194 0.167 0.629 0.674\n\n\nThe area_sum of img L1 is the sum of the two sheets (one in each image).\n\nsum(merged_cor$results$area [1:2])\n\n[1] 194.855\n\n\nBelow, I will create a plot to show the distribution of leaf area\n\ndf_leaf <-\n  merged_cor$results %>%\n  separate(img , into = c(\"img\", \"code\"))\n\n# leaf area of the different species\np1 <-\n  ggplot(df_leaf, aes(img, area)) +\n  geom_boxplot() +\n  geom_jitter(color=\"red\") +\n  labs(x = \" Image \", y = expression(Area ~(cm^2)))\n\np2 <-\n  ggplot(df_leaf , aes(x = img , y = area)) +\n  stat_summary(fun = sum,\n               geom = \"bar\",\n               col = \" black \") +\n  labs(x = \" Image \", y = expression(Total~area ~(cm^2)))\n\n\n# solidity of the different species\np3 <-\n  ggplot(df_leaf , aes(x = img , y = solidity)) +\n  geom_boxplot() +\n  geom_jitter(color=\"red\") +\n  labs(x = \"Image\", y = \"Solidity\")\n\narrange_ggplot(p1, p2, p3)\n\n\n\n\n\n\n\nSource Code\n---\ntitle: \"Analyze objects\"\n---\n\n```{r include = FALSE}\nknitr::opts_knit$set(root.dir = \"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n# Directory\n```{r eval=FALSE}\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n\n# Working with polygons\n> A 'polygon' is a plane figure that is described by a finite number of straight line segments connected to form a closed polygonal chain (Singer, 1993)^[Singer, M.H. 1993. A general approach to moment calculation for polygons and line segments. Pattern Recognition 26(7): 1019–1028. doi: 10.1016/0031-3203(93)90003-F.].\n\nGiven the above, we can conclude that image objects can be expressed as polygons with `n` vertices. `pliman` has a set of functions(`draw_*()`) useful for drawing common shapes like circles, squares, triangles, rectangles and `n`- tagons . Another group of ` poly_*()` functions can be used to analyze polygons. Let's start with a simple example related to the area and perimeter of a square.\n\n```{r fig.height =6}\nlibrary(pliman)\nsquare <- draw_square(side = 1)\npoly_area(square)\npoly_perimeter(square)\n```\n\n\nNow, let's see what happens when we start with a hexagon and increase the number of sides up to 1000.\n\n```{r fig.height =6}\nshapes <- list(  side6 = draw_n_tagon(6, plot = FALSE),\n                 side12 = draw_n_tagon(12, plot = FALSE),\n                 side24 = draw_n_tagon(24, plot = FALSE),\n                 side100 = draw_n_tagon(100, plot = FALSE),\n                 side500 = draw_n_tagon(500, plot = FALSE),\n                 side100 = draw_n_tagon(1000, plot = FALSE))\n\nplot_polygon(shapes, merge = FALSE)\n\npoly_area(shapes)\npoly_perimeter(shapes)\n```\n\n\nNote that when $n \\to \\infty$, the sum of the sides becomes the circumference of the circle, given by $2 \\pi r$, and the area becomes $\\pi r^2$. This is fun, but `pliman` is primarily designed for analyzing plant image analysis. So why use polygons? Let's see how we can use these functions to get applicable information.\n\n\n```{r fig.width =8, fig.height =6}\nleaves <- image_import(\"ref_leaves.jpg\", plot = TRUE)\n\n# getting the outline of objects\ncont <- object_contour(leaves, watershed = FALSE)\n# plotting the polygon\nplot_polygon(cont)\n```\n\n\nNice! We can use the contours of any object to get useful information related to its shape. To reduce the amount of output, I will only use five samples: 1, 3, 12, and 24.\n\n```{r fig.height =6}\ncont <- cont[c(\"1\", \"3\", \"12\", \"24\")]\nplot_polygon(cont)\n\n```\n\nIn the current version of `pliman`, you can calculate the following measurements. For more details, see Chen & Wang (2005)^[Chen, C.H., and P.S.P. Wang. 2005. Handbook of Pattern Recognition and Computer Vision. 3rd ed. World Scientific.], Claude (2008)^[Claude, J. 2008. Morphometrics with R. Springer.], and Montero et al. (2009)^[Montero, R.S., E. Bribiesca, R. Santiago, and E. Bribiesca. 2009. State of the Art of Compactness and Circularity Measures. International Mathematical Forum 4(27): 1305–1335.].\n\n## Area\n\nThe area of a shape is calculated using Shoelace 's formula (Lee and Lim, 2017)^[Lee, Y., and W. Lim. 2017. Fórmula de cadarço: conectando a área de um polígono e o produto vetorial vetorial. The Mathematics Teacher 110(8): 631–636. doi: 10.5951/MATHTEACHER.110.8.0631.], as follows\n\n$$\nA=\\frac{1}{2}\\left |\\sum_{i=1}^{n}\\left(x_{i} y_{i+1}-x_{i+1}y_{i}\\right)\\right|\n$$\n\n```{r fig.height =6}\npoly_area(cont)\n```\n\n\n## Perimeter\nThe perimeter is calculated as the sum of the Euclidean distance between all points on a shape. Distances can be obtained with `poly_distpts()`.\n\n```{r}\npoly_perimeter(cont)\n\n# perimeter of a circle with radius 2\ncircle <- draw_circle(radius = 2, plot = FALSE)\npoly_perimeter(circle)\n\n# check the result\n2*pi*2\n```\n\n\n## Radius\n\nThe radius of a pixel on the object's contour is calculated as its distance from the object's centroid(also called 'center of mass'). These distances can be obtained with `poly_centdist()`.\n\n```{r}\ndist <- poly_centdist(cont)\n\n# stats for radius\nmean_list(dist)\nmin_list(dist)\nmax_list(dist)\nsd_list(dist)\n\n# average radius of circle above\npoly_centdist(circle) |> mean_list()\n```\n\n\n\n## Length and width\n\nThe length and width of an object are calculated with `poly_lw()`, as the difference between the maximum and minimum of the `x` and `y` coordinates after the object has been aligned with `poly_align()`.\n\n```{r fig.height =2, fig.width=10}\npoly_lw(cont)\n```\n\n## Circularity, eccentricity, diameter and elongation\n\nCircularity(Montero et al. 2009)^[Montero, R.S., E. Bribiesca, R. Santiago, and E. Bribiesca. 2009. State of the Art of Compactness and Circularity Measures. International Mathematical Forum 4(27): 1305–1335] is also called shape compactness, or measure of roundness of an object. It is given by $C = P^2 / A$, where $P$ is the perimeter and $A$ is the area of the object.\n\n```{r}\npoly_circularity(cont)\n```\n\nAs the above measurement depends on the scale, normalized roundness can be used. In this case, a perfect circle is assumed to have circularity equal to 1. This measure is invariant under translation, rotation and scale transformations, given $Cn = P^2 / 4 \\pi A$\n\n```{r}\npoly_circularity_norm(cont)\n\n# normalized circularity for different shapes\ndraw_square(plot =FALSE) |> poly_circularity_norm()\ndraw_circle(plot=FALSE) |> poly_circularity_norm()\n```\n\n\n` poly_circularity_haralick()` calculates the circularity of Haralick , CH(Haralick , 1974)^[Haralick, R.M. 1974. A Measure for Circularity of Digital Figures. IEEE Transactions on Systems, Man, and Cybernetics SMC-4(4): 394–396. doi: 10.1109/TSMC.1974.5408463.]. The method is based on calculating all Euclidean distances from the object's centroid to each contour pixel. With this set of distances, the mean($m$) and the standard deviation($s$) are calculated. These statistical parameters are used in a ratio that calculates CH as $CH = m/ sd $.\n\n```{r}\npoly_circularity_haralick(cont)\n```\n\n`poly_convexity()` Calculates the convexity of a shape using a ratio of the perimeter of the convex hull to the perimeter of the polygon.\n\n```{r}\npoly_convexity(cont)\n```\n\n\n`poly_eccentricity()` Calculates the eccentricity of a shape using the ratio of the eigenvalues(coordinate inertia axes).\n\n```{r}\npoly_eccentricity(cont)\n```\n\n\n`poly_elongation()` Calculates the elongation of an object as `1 - width / length`\n\n```{r}\npoly_elongation(cont)\n```\n\n\n`poly_caliper()` Calculates the gauge(also called Feret's diameter).\n\n```{r}\npoly_caliper(cont)\n```\n\n\nUsers can use the `poly_measures()` function to calculate most object measurements in a single call.\n\n```{r}\nmeasures <- poly_measures(cont) |> round_cols()\nt(measures)\n```\n\nIf the image resolution is known, the measurements can be corrected with ` get_measures()`. Image resolution can be obtained using a known distance in the image. In the example, the white square has a side of 5 cm. So using `dpi()` the resolution can be obtained. In this case, the dpi is ~50.\n\n```{r}\n(color_measures <- get_measures(measures, dpi = 50))\n\n```\n\n\nSome useful functions can be used to manipulate coordinates. In the following example I will show some features implemented in `pliman`. Just for simplicity, I'll just use object 2.\n\n\n```{r}\no2 <- cont[[\"3\"]]\nplot_polygon(o2)\n```\n\n## Rotate polygons\n\n` poly_rotate()` can be used to rotate the polygon coordinates by an `angle` (0-360 degrees) in the trigonometric (anti-clockwise) direction.\n\n\n```{r fig.width =4, fig.height =4}\nrot <- poly_rotate(o2, angle = 45)\n```\n\n\n## Invert polygons\n` poly_flip_x()` and ` poly_flip_y()` can be used to flip shapes along the x and y axis, respectively.\n\n```{r fig.width =8, fig.height =4}\nflipped <- \n  list(fx = poly_flip_x(o2), \n       fy = poly_flip_y(o2))\n\nplot_polygon(flipped, merge = FALSE, aspect_ratio = 1)\n```\n\n\n## Perimeter sampling\n\n`poly_sample()` samples `n` coordinates between existing points, and `poly_sample_prop()` samples a proportion of coordinates between existing ones.\n\n```{r fig.width =4, fig.height =4}\n# sample 50 coordinates\npoly_sample(o2, n=10) |> plot_polygon()\n\n# sample 10% of coordinates\npoly_sample_prop(o2, prop = 0.1) |> plot_polygon()\n```\n\n\n## smoothing\n\n`poly_smooth()` smooths the contour of a polygon by combining ` prop` coordinate point samples and interpolating them using ` vertices` vertices(default is 1000) .\n\n```{r fig.width =6, fig.height = 6}\nsmoothed <-\n  list( original = o2,\n        s1 = poly_smooth(o2, prop = 0.2, plot = FALSE),\n        s2 = poly_smooth(o2, prop = 0.1, plot = FALSE),\n        s1 = poly_smooth(o2, prop = 0.04, plot = FALSE)\n  )\n\nplot_polygon(smoothed, merge = FALSE, ncol = 2, aspect_ratio = 1)\n```\n\n\n## Noises\n\n\n`poly_jitter()` adds a small amount of noise to a set of coordinates. See `base::jitter()` for more details.\n\n```{r fig.width =8, fig.height =4}\nset.seed(1)\nc1 <- draw_circle(n = 200, plot = FALSE)\nc2 <- draw_circle(n = 200, plot = FALSE) |>\n  poly_jitter(noise_x = 100,\n              noise_y = 100,\n              plot = FALSE)\n\nplot_polygon(list(c1, c2), merge = FALSE)\n```\n\n\n\n\n# Analyzing objects\n\nThe functions seen so far can be used to obtain measurements of objects. However, for image analysis it is necessary to combine different functions (mainly `object_contour()` and `poly_measures()`). Also, almost always, several images need to be analyzed and repeating this process each time would be tedious and inefficient. To address these needs, users can use the ` analyze_objects()` function. Let's start with a simple example, using the `object_300dpi.png` image available on [ GitHub page](https://github.com/TiagoOlivoto/pliman/tree/master/inst/tmp_images). To facilitate importing images from this folder, an `image_pliman()` helper function is used.\n\n\n```{r collapse =TRUE}\nlibrary(pliman)\nlibrary(tidyverse)\nlibrary(metan)\n\nimg <- image_pliman(\"objects_300dpi.jpg\", plot = TRUE)\n\n```\n\n\n\nThe image above was produced with Microsoft PowerPoint. It has a known resolution of 300 dpi(dots per inch) and displays four objects\n\n- Larger square: 10 x 10 cm (100 cm$^2$)\n- Smaller square: 5 x 5 cm(25 cm$^2$)\n- Rectangle: 4 x 2 cm(8 cm$^2$)\n- Circle: 3 cm in diameter(~7.07 cm$^2$)\n\n\nTo count the objects in the image we use `analyze_objects()` and inform the image(the only required argument). By default, the `NB` index is used for object segmentation.\n\n\n```{r, fig.width = 10, fig.height = 5}\nimg_res <- analyze_objects(img, marker = \"id\")\n```\n\n\n\n## Adjusting object measurements\n\nThe results were stored in `img_res`. Since there is no scale declared in the example above, we have no idea about the actual area of objects in cm$^2$, only in pixels. In this case, we use `get_measures()` to adjust pixel measurements to metric units.\n\nThere are two main ways to adjust object measurements (from pixels to cm, for example). The first is to declare the known area, perimeter or radius of a given object. The measure for the other objects will then be calculated by a simple rule of three. The second is by declaring a known image resolution in dpi(dots per inch). In this case, perimeter, area and radius will be adjusted by the dpi informed.\n\n### Declaring a known value\n\nSince we know the area of the larger square (object 1), let's adjust the area of the other objects in the image using this.\n\n\n```{r}\nget_measures(img_res ,\n             id = 1,\n             area ~ 100)\n\n```\n\n\n\n### Declaring the image resolution\n\nIf the image resolution is known, all measurements will be adjusted accordingly. Let's see a numerical example with `pixels_to_cm()`. This function converts the number of pixels(* px *) into cm, considering the image resolution in ` dpi `, as follows: $cm = px \\times(2.54 / dpi)$. As we know the number of pixels of the larger square, its perimeter in cm is given by\n\n\n\n```{r}\n# number of pixels for the perimeter of the largest square\n\nls_px <- img_res$results$perimeter [1]\npixels_to_cm(px = ls_px , dpi = 300)\n\n\n```\n\nThe perimeter of object 1 adjusted by image resolution is very close to the known value (40 cm). Below, the values of all measures are adjusted by declaring the `dpi` argument in `get_measures()`.\n\n```{r}\nimg_res_cor <- get_measures(img_res , dpi = 300)\n\nt(img_res_cor)\n\n```\n\n\n\n### Understanding measurements\n\n```{r}\nobject_contour(img) %>% # get the contour of objects\n  poly_mass() %>% # computes center of mass and minimum and maximum radii\n  plot_mass() # plot the measurements\n```\n\n* Larger square:\n- The minimum diameter(a = 9.97) can be considered as the side of the square\n- The maximum diameter, given by $a \\sqrt {2}$ can be considered the diagonal of the square ($9.97 \\sqrt {2} = 14,099 \\approx 14,105$\n\n```{r}\nt(img_res_cor)\n```\n\n\n## Texture features\n\nThe function computes 13 Haralick texture features for each object based on a gray-level co-occurrence matrix (Haralick et al. 1979)^[Haralick, R.M., K. Shanmugam, and I. Dinstein. 1973. Textural Features for Image Classification. IEEE Transactions on Systems, Man, and Cybernetics SMC-3(6): 610–621. doi: 10.1109/TSMC.1973.4309314]. Haralick features depend on the configuration of the parameters `har_nbins` and `har_scales`. `har_nbins` controls the number of bins used to compute the Haralick matrix. A smaller `har_nbins` can give more accurate estimates of the correlation because the number of events per bin is higher. While a higher value will give more sensitivity. `har_scales` controls the number of scales used to compute the Haralick features. Since Haralick features compute the correlation of intensities of neighboring pixels, it is possible to identify textures with different scales, e.g., a texture that is repeated every two pixels or 10 pixels. By default, the Haralick features are computed with the R band. To chance this default, use the argument `har_band`. For example, `har_band = 2` will compute the features with the green band. \n\nThe followig measures are returned (fore more details, see [this post](https://earlglynn.github.io/RNotes/package/EBImage/Features-Haralick.html))\n\n- `asm`: The angular second-moment feature.\n- `con`: The contrast feature\n- `cor`: Correlation measures the linear dependency of gray levels of\nneighboring pixels.\n- `var`: The variance of gray levels pixels.\n- `idm`: The Inverse Difference Moment (IDM), i.e., the local\nhomogeneity.\n- `sav`: The Sum Average.\n- `sva`: The Sum Variance.\n- `sen`: Sum Entropy.\n- `dva`: Difference Variance.\n- `den`: Difference Entropy\n- `f12`: Difference Variance.\n- `f13`: The angular second-moment feature.\n\n\n## Single image processing\nThe `analyze_objects()` function calculates a range of measurements that can be used to study the shape and texture of objects, such as leaves. In the following example, I show how to plot the length and width of each leaf in the following image.\n\n\n```{r}\nleaves <- image_import(\"folhas.jpg\", plot = TRUE)\n\nleaves_meas <-\n  analyze_objects(leaves ,\n                  watershed = FALSE,\n                  col_background = \"black\")\n\nleaves_cor <- get_measures(leaves_meas , dpi = 300)\n\nt(leaves_cor)\n\n\n# plot width and length\nplot_measures(leaves_cor , measure = \"width\")\nplot_measures(leaves_cor , measure = \"length\", vjust = 50)\n```\n\n\n\nHere, we will count the grains in the `grains.jpg` image. This image has a cyan background and contains 90 soybeans that touch each other. The ` analyze_objects()` function segments the image using the normalized blue index by default, as follows $NB =(B /(R + G + B))$, where *R*, *G* and *B * are the red, green and blue bands. Note that if the image is contained in the default directory, it is not necessary to import it. Just enter the image name in quotes in the `img` argument(e.g., `img = \"grains\"`).\n\nIn this example, objects are counted and segmented objects are colored with random colors using the `show_segmentation = TRUE` argument. Users can set ` show_contour = FALSE` to remove the contour line and identify the objects (in this example, the grains) using the `marker = \"id\"` arguments. The background color can also be changed with `col_background`.\n\n\n\n```{r, fig.width = 12, fig.height = 6}\ncount <-\n  analyze_objects(\"grains\",\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\ncount$statistics\n```\n\n\n```{r}\n# Get the measurements of the object\nmeasurements <- get_measures(count)\nhead(measurements)\n```\n\n\nIn the following example, we will select objects with an area above the average of all objects using ` lower_size = 719.1`.\n\n\n\n```{r, fig.width = 12, fig.height = 6}\n\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                lower_size = 719.1)\n```\n\n\n\nUsers can also use the `topn _*` arguments to select the `n` objects based on the smallest or largest areas. Let's see how to select the 5 grains with the smallest area, showing the original grains on a blue background. We will also use the `my_index` argument to choose a custom index to segment the image. Just for comparison, we will explicitly set the normalized blue index by calling `my_index = \"B /(R + G + B)\"`.\n\n\n\n```{r, fig.width = 12, fig.height = 6}\nanalyze_objects(\"grains\",\n                marker = \"id\",\n                topn_lower = 5,\n                col_background = \"salmon\",\n                my_index = \"B /(R + G + B)\") # normalized blue(NB)\n```\n\n\n\n## Batch processing\n\nIn image analysis, it is often necessary to process more than one image. For example, in plant breeding, the number of grains per plant(eg wheat) is often used in indirect selection of high-yielding plants. In `pliman`, batch processing can be done when the user declares the `pattern` argument.\n\n\nTo speed up processing time, especially for large numbers of images, the `parallel = TRUE` argument can be used. In this case, images are processed asynchronously (in parallel) in separate `R` sessions running in the background on the same machine. The number of sections is set to 50% of available cores. This number can be explicitly controlled with the `workers` argument.\n\n\n```{r}\nsystem.time(\n  list_res <- analyze_objects(pattern = \"img_sb\", show_image = FALSE)\n)\n\n# parallel processing\n# 6 multiple sections (50% of my pc's cores)\nsystem.time(\n  list_res <-\n    analyze_objects(pattern = \"img_sb\",\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\n```\n\n\n\n\n# Object coordinates\nUsers can get the coordinates for all desired objects with `object_coord()`. When the `id` argument is set to `NULL` (default), a bounding rectangle is drawn including all objects. Use `id = \"all\"` to get the coordinates of all objects in the image or use a numeric vector to indicate the objects to calculate the coordinates. Note that the `watershed = FALSE` argument is used to avoid unique objects being split up into multiple objects by the watershed segmentation algorithm.\n\n\n```{r objec2}\nleaves <- image_import(\"folhas.jpg\", plot = TRUE)\n\n# get the id of each object\nobject_id(leaves, watershed = FALSE)\n\n# Get the coordinates of a bounding rectangle around all objects\nobject_coord(leaves, watershed = FALSE)\n\n# Get coordinates for all objects\nobject_coord(leaves ,\n             id = \"all\",\n             watershed = FALSE)\n\n# Get the coordinates of objects 1 and 2\n# 20 border pixels\nobject_coord(leaves ,\n             id = 1,\n             edge = 20,\n             watershed = FALSE)\n```\n\n\n\n# Isolating objects\n\nKnowing the coordinates of each object, it is possible to isolate it. The `object_isolate()` function is used for this. In the following example, I will isolate object 1 and set a 10-pixel border around the object.\n\n```{r object3}\nid1 <-\n  object_isolate(leaves ,\n                 watershed = FALSE,\n                 id = 1,\n                 edge = 10)\nplot(id1)\n```\n\n# Including objects in a list\n\n`object_split()` can be used to split up a series of objects contained in a single image into a list, where each element is one object. By default, the background is removed and shown in white.\n\n```{r fig.width =10}\nlist <- object_split(leaves, watershed = FALSE)\nstr(list)\n```\n\n\n\n# RGB values for each object\n\nTo get the RGB intensity of each object in the image, we use the `object_rgb = TRUE` argument in the `analyze_objects()` function. In the following example, we will use the R, G and B bands and their normalized values. The `pliman_indexes()` function returns the indexes available in the package. To compute a specific index, simply enter a formula containing the values of R, G, or B (e.g. `object_index = \"B/G+R\"`).\n\n\n\n```{r rgb2, fig.width = 10, fig.height = 6}\nimg <- image_import(\"green.jpg\", plot = TRUE)\n(indx <- pliman_indexes())\n\nsoy_green <-\n  analyze_objects(img ,\n                  object_index = indx [1:6], # R:NB\n                  marker = \"id\",\n                  marker_col = \"black\",\n                  col_background = \"white\",\n                  show_contour = FALSE)\n\n# PCA with the indices\nind <- summary_index(soy_green, type =\"var\")\n\n```\n\nThe `R` index provided the greatest contribution to the variation of PC1. The biplot containing the indices (variables) and the grains (individuals) can be seen below.\n\n```{r fig.width =8, fig.height =8}\nget_biplot(ind$pca_res, show = \"var\")\nget_biplot(ind$pca_res, show = \"ind\")\n\n```\n\n\nNow, let's plot the `R` index on each object\n\n```{r}\nplot(img)\nplot_measures(soy_green ,\n              measure = \"R\",\n              col = \" black \")\n```\n\n\nIt seems that grains with average red (`R`) value less than 0.6 can be considered greenish seeds. Users can then work with this feature and adapt it to their case.\n\n```{r rgb4, fig.width =10, fig.height =4}\nreport <-\n  summary_index(soy_green ,\n                index = \"R\",\n                cut_point = 0.6,\n                plot = FALSE)\nids <- report$ids\nreport$between_id\nreport$within_id[ids,]\n\n\n# ratio of pixels of each object(above and below 0.6)\nbarplot(t(report$within_id [,6:7]) |> as.matrix(),\n        legend = c(\"R < 0.6\", \"R > 0.6\"))\n```\n\n\nIn the following graph, I plot the distribution of the greenish and non-greenish R, G, and B values.\n\n```{r}\n# distribution of RGB values\nrgbs <-\n  soy_green$object_rgb |>\n  mutate(type = ifelse(id %in% ids, \" Greenish \", \" No greenish \")) |>\n  select(-id) |>\n  pivot_longer(-type)\n\nggplot(rgbs, aes(x = value)) +\n  geom_density(aes(fill = name), alpha = 0.5) +\n  facet_wrap(~ type)\n\n\n```\n\nNow, using the ids of each grain, I plot the values only in the greenish ones.\n\n\n```{r}\n# plot \nplot(img)\nplot_measures(soy_green ,\n              id = ids,\n              measure = \"R\",\n              col = \"black\")\ncont <- object_contour(img , show_image = FALSE)\n\nplot_contour(cont,\n             id = ids,\n             col = \"red\")\n\n```\n\n\n::: {.callout-tip}\nWhen there are many objects, the `parallel = TRUE` argument will speed up extracting the RGB values. In the following example, an image with 1343 grains of *Vicia cracca* is analyzed. The indices `\"R\"` and `\"R/G\"` are computed. Grains with an average red value greater than 0.25 are highlighted.\n\n```{r rgb5, eval=FALSE}\nlibrary(pliman)\nimg2 <- image_import(\"vicia.jpg\")\n\nvicia <-\n  analyze_objects(img2,\n                  index = \"B\",\n                  object_index = \"R\",\n                  show_image = FALSE,\n                  parallel = TRUE)\n\nsummary_index <-\n  summary_index(vicia ,\n                index = \"R\",\n                cut_point = 0.25,\n                select_higher = TRUE)\n\ncount2 <-\n  object_contour(img2,\n                 index = \"B\",\n                 show_image = FALSE)\n\nids2 <- summary_index$ids\nplot_contour(count2, col = \"red\")\n\n```\n\n:::\n\n\n\n\n# Leaf area\n## Known resolution\n\n```{r}\nleaves <- image_import(image = \"ref_leaves.jpg\", plot = TRUE)\n\naf <-\n  analyze_objects(leaves ,\n                  watershed = FALSE,\n                  show_contour = FALSE,\n                  col_background = \"black\",\n                  marker = \"id\")\naf_cor <- get_measures(af, dpi = 50.5)\n\nplot_measures(af_cor ,\n              measure = \"area\",\n              vjust = -30,\n              col = \" red \")\n```\n\n\n\n## Reference object (dev version)\n### Single images\nThe `reference` argument can now be used to correct the object measures even when images with different shooting distances are used. In this example, the leaf area of the `ref_leaves` image is quantified and corrected considering a 5 x 5 (25 cm$^2$) white square as the reference object. For this, it is necessary to provide color palettes referring to the background (`background`), leaves (` foreground`) and the reference object (`reference`). Also, the area of the reference object needs to be informed in `reference_area`.\n\n```{r}\nlibrary(pliman)\nimg <- image_import(pattern = \"ref_\", plot = TRUE)\n\narea <-\n  analyze_objects(img = \"ref_leaves\",\n                  foreground = \"ref_folha\",\n                  background = \"ref_back\",\n                  reference = \"ref_ref\",\n                  reference_area = 25,\n                  marker = \"area\",\n                  watershed = FALSE)\n```\n\n\n\n### Multiple images\n```{r}\nres <-\n  analyze_objects(pattern = \"img_\",\n                  dir_original = \"linhaca\",\n                  foreground = \"folhalin\",\n                  background = \"fundolin\",\n                  reference = \"reflin\",\n                  reference_area = 20,\n                  watershed = FALSE,\n                  filter = 3)\n\narea <- \n  res$results |> \n  separate_col(img, \n               into = c(\"img\", \"avaliacao\", \"block\"))\n\n\ndf_plot <- \n  area |> \n  sum_by(avaliacao, block, .vars = area) |> \n  group_by(avaliacao) |> \n  desc_stat(area, stats = c(\"mean, sd.amo\"))\n\n\n\n\nggplot(df_plot, aes(avaliacao, mean)) + \n  geom_point() +\n  geom_errorbar(aes(ymin = mean - sd.amo, \n                    ymax = mean + sd.amo),\n                width = 0.2) +\n  labs(x = \"Período de avaliação\",\n       y = \"Área foliar (cm2 por planta)\") +\n  theme_bw(base_size = 16)\n```\n\n\n\n\n\n## Filling 'holes'\n\nAn important aspect to consider in leaf area measures is when leaves present 'holes'. This can occur, for example, by the attack of pests. In this case, the area would have to be considered, because it was there! The image bellow is used as an example.\n\n```{r fig.width =10, fig.height =6}\nholes <- image_import(\"holes.jpg\", plot = TRUE)\n\n```\n\n\nIn this case, the missing area will not be computed using the default settings of `analyze_objects()`. To include this area as the leaf area, we can use the argument `fill_hull()`. Note that this will only work for missing areas within a closed object. If the missing area includes the original leaf contour, there is no (yet available) way to reconstruct the leaf perimeter.\n\n\n```{r fig.width =10, fig.height =6}\n\naf <-\n  analyze_objects(holes,\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\n# fill the missing area\naf2 <-\n  analyze_objects(holes,\n                  fill_hull = TRUE, # fill ' holes '\n                  watershed = FALSE,\n                  col_background = \"white\",\n                  marker = \"area\",\n                  marker_col = \"red\",\n                  marker_size = 3,\n                  show_image = FALSE,\n                  save_image = TRUE,\n                  prefix = \"proc2_\",\n                  dir_processed = tempdir(),\n                  contour_size = 5)\n\nimgs <- image_import(pattern = \"proc\", path = tempdir())\nimage_combine(imgs)\n```\n\nWe can simply use the ratio between `proc_img` and `proc_img2` to compute the injured area in this leaflet.\n\n```{r}\n# percent of injuried area\n100 - 88379 / 99189 * 100\n```\n\n\n\n\n## Compound leaves\n\nA simple leaf blade is undivided. The blade of a compound leaf is divided into several leaflets. In the following examples, I will show how to analyze simple and compound leaves with `analyze_objects()`, mainly if the goal is to obtain the measures for each leaf (e.g., mean area), where the number of objects (leaves) will influence the results.\n\nThe following images by [Daniel Saueressig](https://www.florestaombrofilamista.com.br/sidol/?menu=contact) were obtained from the *Sistema de Identificação Dendrológica Online - Floresta Ombrófila Mista*^[https://www.florestaombrofilamista.com.br/sidol/?menu=glossary] and show examples of simple and compound leaves.\n\n```{r sc1, fig.width=10}\nimgs <- \n  image_import(c(\"simple.jpg\", \"compound.jpg\"),\n               plot = TRUE)\n\n```\n\n\nAnalyzing non-touching simple leaves is fairly simple. We already did that. The squares in the background have 4 cm$^2$. With this information, it is possible to obtain the image resolution with `dpi(simple)`, which will be useful to adjust the measures. In this case, the estimated dpi is 48.65.\n\n```{r sc2}\nsimple <- imgs$simple.jpg\nsarea <- analyze_objects(simple, marker = \"id\")\n\n```\n\nNote that with the default settings, the simple leaf was partitioned into small, segmented leaves. This can be solved by either using `object_size = \"large\"` or `watershed = FALSE`, to omit the watershed segmentation algorithm. The last is used here.\n\n\n```{r sc3}\nsarea <- \n  analyze_objects(simple,\n                  watershed = FALSE,\n                  marker = \"id\",\n                  show_chull = TRUE)\nsarea_cor <- get_measures(sarea, dpi = 48.65)\nsarea_cor\n```\n\n\nFor compound leaves, if the watershed segmentation is used, leaflets will probably be considered as different leaves, as can be seen below.\n\n```{r sc4}\ncompound <- imgs$compound.jpg\ncarea <- \n  analyze_objects(compound,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  marker = \"id\")\n```\n\nTherefore, using `watershed = FALSE` will solve this problem, since all leaflets connected by at least one pixel will be considered part of the same leaf.\n\n```{r sc5}\ncarea <- \n  analyze_objects(compound,\n                  watershed = FALSE,\n                  show_segmentation = TRUE,\n                  show_contour = FALSE,\n                  show_chull = TRUE,\n                  marker = \"id\")\ncarea_cor <- get_measures(carea, dpi = 49.5)\ncarea_cor\n```\n\n\n\n\n## Multiple images of the same sample\n\nIf users need to analyze multiple images from the same sample, the images must share the same filename prefix, which is defined as the part of the filename that precedes the first hyphen (`-`) or underscore (`_`). Then, when using ` get_measures()`, measurements from leaf images called, for example, `F1-1.jpeg`, `F1_2.jpeg` and `F1-3.jpeg` will be combined into a single image (`F1`), displayed in the `merge` object. This is useful, for example, for analyzing large sheets that need to be split into multiple images or multiple sheets belonging to the same sample that cannot be scanned into a single image.\n\nIn the following example, five images will be used as examples. Each image has leaves of different species. The images have been split into different images that share the same prefix (eg L1_\\*, L2_\\*, and so on). Note that to ensure that all images are processed, all images must share a common pattern, in this case (`\"L\"`). The three dots in the lower right corner have a known distance of 5 cm between them, which can be used to extract the dpi of the image with `dpi()`. For teaching purposes only, I will assume that all images are 100 dpi resolution .\n\n\n```{r merge0, fig.width = 10, fig.height = 10}\n# entire images\nimgs <-\n  image_import(pattern = \"leaf\",\n               plot = TRUE,\n               ncol = 2)\n\n# images of the same sample\nsample_imgs <-\n  image_import(pattern = \"L\",\n               plot = TRUE,\n               ncol = 5)\n```\n\nHere, I will use the `pattern = \"L\"` to indicate that all images with this pattern name should be merged. The green index (`\"G\"`) is used to segment the leaves and `watershed = FALSE` is used to omit the watershed segmentation algorithm.\n\n\n```{r merge1}\nmerged <-\n  analyze_objects(pattern = \"L\",\n                  index = \"B\",\n                  watershed = FALSE)\n```\n\nUsing the `get_measures()` function it is possible to convert measurements from pixel units to metric units(cm$^ 2$).\n\n```{r merge2}\nmerged_cor <- get_measures(merged, dpi = 100)\n```\n\nNote that the  merged_cor` is a list with three objects:\n\n* `results`: a data frame that contains the measurements of each individual object (in this case, leaf) of each analyzed image.\n\n```{r merge3}\nmerged_cor$results\n```\n\n* `summary` : a data frame that contains the summary of the results, containing the number of objects in each image (`n`) the sum, mean and standard deviation of the area of each image, as well as the average value for all others measurements (perimeter, radius, etc.)\n\n\n```{r merge4}\nmerged_cor$summary\n\n```\n\n* `merge`: a data frame that contains the results merged by image prefix. Note that in this case the results are displayed by L1, L2, L3, L4 and L5.\n\n```{r merge5}\nmerged_cor$merge\n\n```\n\nThe ` area_sum` of img `L1` is the sum of the two sheets (one in each image).\n\n```{r merge6}\nsum(merged_cor$results$area [1:2])\n\n```\n\n\nBelow, I will create a plot to show the distribution of leaf area  \n\n```{r merge9, fig.width =10, fig.height =5}\ndf_leaf <-\n  merged_cor$results %>%\n  separate(img , into = c(\"img\", \"code\"))\n\n# leaf area of the different species\np1 <-\n  ggplot(df_leaf, aes(img, area)) +\n  geom_boxplot() +\n  geom_jitter(color=\"red\") +\n  labs(x = \" Image \", y = expression(Area ~(cm^2)))\n\np2 <-\n  ggplot(df_leaf , aes(x = img , y = area)) +\n  stat_summary(fun = sum,\n               geom = \"bar\",\n               col = \" black \") +\n  labs(x = \" Image \", y = expression(Total~area ~(cm^2)))\n\n\n# solidity of the different species\np3 <-\n  ggplot(df_leaf , aes(x = img , y = solidity)) +\n  geom_boxplot() +\n  geom_jitter(color=\"red\") +\n  labs(x = \"Image\", y = \"Solidity\")\n\narrange_ggplot(p1, p2, p3)\n```"
  },
  {
    "objectID": "04_phytopathometry.html#using-sample-palettes",
    "href": "04_phytopathometry.html#using-sample-palettes",
    "title": "Phytopathometry",
    "section": "\n3.1 Using sample palettes",
    "text": "3.1 Using sample palettes\nSample palettes can be made by simply manually sampling small areas of representative images and producing a composite image that will represent each of the desired classes (background, healthy, and symptomatic tissues).\n\nimg <- image_import(\"exemp_1.jpeg\", plot = TRUE)\nh <- image_import(\"exem_h.png\")\nd <- image_import(\"exem_d.png\")\nb <- image_import(\"exem_b.png\")\nimage_combine(img, h, d, b, ncol = 4)"
  },
  {
    "objectID": "04_phytopathometry.html#producing-sample-palettes",
    "href": "04_phytopathometry.html#producing-sample-palettes",
    "title": "Phytopathometry",
    "section": "\n4.1 Producing sample palettes",
    "text": "4.1 Producing sample palettes\nUsers can produce these palettes with pick_palette() function.\n\nh2 <- pick_palette(img)\nd2 <- pick_palette(img)\nb2 <- pick_palette(img)\nimage_combine(h2, d2, b2, ncol = 3)\n\n\n4.1.1 Defaults settings\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b)\n\n\n\nsev$severity\n\n   healthy symptomatic\n1 92.71941    7.280595\n\n\n\n4.1.2 Filling lesions\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_contour = FALSE)\n\n\n\n\n\n4.1.3 Showing a mask\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_original = FALSE,\n                  col_lesions = \"brown\") # padrão é \"black\"\n\n\n\n\n\n4.1.4 Segmenting and analyzing lesions\nWhen using show_features = TRUE, the function analyzes the lesions and returns results such as number of lesions, area, perimeter, etc. With show_segmentation = TRUE, segmented lesions are shown.\n\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_features = TRUE,\n                  show_segmentation = TRUE)\n\n\n\n# correct the measures (dpi = 150)\nsev_corrected <- get_measures(sev, dpi = 150)"
  },
  {
    "objectID": "04_phytopathometry.html#batch-processing",
    "href": "04_phytopathometry.html#batch-processing",
    "title": "Phytopathometry",
    "section": "\n3.3 Batch processing",
    "text": "3.3 Batch processing\nTo analyze several images from a directory, use the pattern argument to declare a pattern of filenames. Here, we Will used 50 soybean leaves available in the repository https://osf.io/4hbr6, a database of images of annotation of severity of plant diseases. Thanks to Emerson M. Del Ponte and his contributors for keeping this project publicly available. Using the save_image = TRUE argument we save the processed images in a temporary directory, defined by tempdir().\n\n# criar um diretório temporário\ntemp_dir <- tempdir()\n\nsystem.time(\n  sev_lote <- \n    measure_disease(pattern = \"soy\",\n                    img_healthy = \"soja_h\",\n                    img_symptoms = \"soja_s\",\n                    img_background = \"soja_b\",\n                    show_image = FALSE,\n                    save_image = TRUE,\n                    dir_processed = temp_dir,\n                    show_contour = FALSE,\n                    col_lesions = \"brown\")\n)\n\nProcessing image soy_1 |=                                        | 2% 00:00:00 \n\n\nProcessing image soy_10 |==                                      | 4% 00:00:02 \n\n\nProcessing image soy_11 |==                                      | 6% 00:00:04 \n\n\nProcessing image soy_12 |===                                     | 8% 00:00:06 \n\n\nProcessing image soy_13 |====                                    | 10% 00:00:07 \n\n\nProcessing image soy_14 |=====                                   | 12% 00:00:09 \n\n\nProcessing image soy_15 |======                                  | 14% 00:00:10 \n\n\nProcessing image soy_16 |======                                  | 16% 00:00:11 \n\n\nProcessing image soy_17 |=======                                 | 18% 00:00:12 \n\n\nProcessing image soy_18 |========                                | 20% 00:00:14 \n\n\nProcessing image soy_19 |=========                               | 22% 00:00:16 \n\n\nProcessing image soy_2 |==========                               | 24% 00:00:17 \n\n\nProcessing image soy_20 |==========                              | 26% 00:00:18 \n\n\nProcessing image soy_21 |===========                             | 28% 00:00:20 \n\n\nProcessing image soy_22 |============                            | 30% 00:00:22 \n\n\nProcessing image soy_23 |=============                           | 32% 00:00:23 \n\n\nProcessing image soy_24 |==============                          | 34% 00:00:23 \n\n\nProcessing image soy_25 |==============                          | 36% 00:00:25 \n\n\nProcessing image soy_26 |===============                         | 38% 00:00:27 \n\n\nProcessing image soy_27 |================                        | 40% 00:00:29 \n\n\nProcessing image soy_28 |=================                       | 42% 00:00:30 \n\n\nProcessing image soy_29 |==================                      | 44% 00:00:32 \n\n\nProcessing image soy_3 |===================                      | 46% 00:00:33 \n\n\nProcessing image soy_30 |===================                     | 48% 00:00:35 \n\n\nProcessing image soy_31 |====================                    | 50% 00:00:36 \n\n\nProcessing image soy_32 |=====================                   | 52% 00:00:36 \n\n\nProcessing image soy_33 |======================                  | 54% 00:00:38 \n\n\nProcessing image soy_34 |======================                  | 56% 00:00:40 \n\n\nProcessing image soy_35 |=======================                 | 58% 00:00:42 \n\n\nProcessing image soy_36 |========================                | 60% 00:00:43 \n\n\nProcessing image soy_37 |=========================               | 62% 00:00:45 \n\n\nProcessing image soy_38 |==========================              | 64% 00:00:46 \n\n\nProcessing image soy_39 |==========================              | 66% 00:00:47 \n\n\nProcessing image soy_4 |============================             | 68% 00:00:49 \n\n\nProcessing image soy_40 |============================            | 70% 00:00:50 \n\n\nProcessing image soy_41 |=============================           | 72% 00:00:51 \n\n\nProcessing image soy_42 |==============================          | 74% 00:00:53 \n\n\nProcessing image soy_43 |==============================          | 76% 00:00:55 \n\n\nProcessing image soy_44 |===============================         | 78% 00:00:56 \n\n\nProcessing image soy_45 |================================        | 80% 00:00:57 \n\n\nProcessing image soy_46 |=================================       | 82% 00:00:59 \n\n\nProcessing image soy_47 |==================================      | 84% 00:01:00 \n\n\nProcessing image soy_48 |==================================      | 86% 00:01:01 \n\n\nProcessing image soy_49 |===================================     | 88% 00:01:02 \n\n\nProcessing image soy_5 |=====================================    | 90% 00:01:03 \n\n\nProcessing image soy_50 |=====================================   | 92% 00:01:05 \n\n\nProcessing image soy_6 |=======================================  | 94% 00:01:06 \n\n\nProcessing image soy_7 |=======================================  | 96% 00:01:07 \n\n\nProcessing image soy_8 |======================================== | 98% 00:01:08 \n\n\nProcessing image soy_9 |=========================================| 100% 00:01:09 \n\n\n  usuário   sistema decorrido \n    62.81      8.36     71.20 \n\nsev_lote$severity\n\n      img  healthy symptomatic\n1   soy_1 92.30598    7.694025\n2  soy_10 53.80360   46.196397\n3  soy_11 88.00941   11.990592\n4  soy_12 62.49139   37.508612\n5  soy_13 51.26833   48.731667\n6  soy_14 99.79172    0.208283\n7  soy_15 71.62207   28.377926\n8  soy_16 30.37714   69.622864\n9  soy_17 20.94673   79.053265\n10 soy_18 80.94158   19.058422\n11 soy_19 38.04735   61.952654\n12  soy_2 85.63328   14.366722\n13 soy_20 33.00604   66.993959\n14 soy_21 33.37444   66.625555\n15 soy_22 75.93323   24.066765\n16 soy_23 59.91690   40.083099\n17 soy_24 72.18240   27.817601\n18 soy_25 10.42410   89.575897\n19 soy_26 26.35530   73.644700\n20 soy_27 30.76558   69.234421\n21 soy_28 52.13914   47.860864\n22 soy_29 23.45779   76.542208\n23  soy_3 15.38918   84.610817\n24 soy_30 43.90665   56.093350\n25 soy_31 13.50568   86.494320\n26 soy_32 46.16725   53.832751\n27 soy_33 89.85766   10.142338\n28 soy_34 47.03267   52.967327\n29 soy_35 58.00870   41.991303\n30 soy_36 93.53585    6.464153\n31 soy_37 36.80026   63.199742\n32 soy_38 52.98365   47.016352\n33 soy_39 39.96360   60.036400\n34  soy_4 66.48391   33.516086\n35 soy_40 68.25036   31.749641\n36 soy_41 97.24293    2.757070\n37 soy_42 84.55326   15.446743\n38 soy_43 92.03686    7.963141\n39 soy_44 58.10199   41.898013\n40 soy_45 83.62880   16.371200\n41 soy_46 83.64167   16.358326\n42 soy_47 79.41822   20.581780\n43 soy_48 75.42505   24.574951\n44 soy_49 70.22985   29.770153\n45  soy_5 77.46601   22.533989\n46 soy_50 53.19483   46.805165\n47  soy_6 64.94720   35.052799\n48  soy_7 58.30199   41.698010\n49  soy_8 42.05012   57.949881\n50  soy_9 81.74081   18.259186"
  },
  {
    "objectID": "04_phytopathometry.html#standard-area-diagrams",
    "href": "04_phytopathometry.html#standard-area-diagrams",
    "title": "Phytopathometry",
    "section": "\n3.4 Standard area diagrams",
    "text": "3.4 Standard area diagrams\nStandard area diagrams (SAD) have long been used as a tool to aid the estimation of plant disease severity, serving as a standard reference template before or during the assessments.\nGiven an object computed with measure_disease() a Standard Area Diagram (SAD) with n images containing the respective severity values are obtained with sad().\nLeaves with the smallest and highest severity will always be in the SAD. If n = 1, the leaf with the smallest severity will be returned. The others are sampled sequentially to achieve the n images after severity has been ordered in ascending order. For example, if there are 30 leaves and n is set to 3, the leaves sampled will be the 1st, 15th, and 30th with the smallest severity values.\nThe SAD can be only computed if an image pattern name is used in argument pattern of measure_disease(). If the images are saved, the n images will be retrevied from dir_processed directory. Otherwise, the severity will be computed again to generate the images. A SAD with 8 images from the above example can be obtained easely with:\n\nsad(sev_lote, n = 6, ncol = 3)\n\n\n\n\n      img  healthy symptomatic rank\n6  soy_14 99.79172    0.208283    1\n41 soy_46 83.64167   16.358326   10\n44 soy_49 70.22985   29.770153   20\n46 soy_50 53.19483   46.805165   30\n31 soy_37 36.80026   63.199742   40\n18 soy_25 10.42410   89.575897   50"
  },
  {
    "objectID": "04_phytopathometry.html#parallel-processing",
    "href": "04_phytopathometry.html#parallel-processing",
    "title": "Phytopathometry",
    "section": "\n3.5 Parallel processing",
    "text": "3.5 Parallel processing\nTo speed up processing time when multiple images are available, you can use the paralell argument. In parallel programming (parallel = TRUE), the images are processed asynchronously (in parallel) in separate R sessions running in the background on the same machine. The number of sections is set by default to 50% of available cores. This number can be controlled explicitly with the argument workers.\n\nsystem.time(\n  sev_lote <- \n    measure_disease(pattern = \"soy\",\n                    img_healthy = \"soja_h\",\n                    img_symptoms = \"soja_s\",\n                    img_background = \"soja_b\",\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\nImage processing using multiple sessions (6). Please wait.\n\n\n  usuário   sistema decorrido \n     0.69      0.17     25.36"
  },
  {
    "objectID": "04_phytopathometry.html#multiple-images-of-the-same-sample",
    "href": "04_phytopathometry.html#multiple-images-of-the-same-sample",
    "title": "Phytopathometry",
    "section": "\n3.6 Multiple images of the same sample",
    "text": "3.6 Multiple images of the same sample\nIf users need to analyze multiple images from the same sample, the images from the same sample must share the same filename prefix, which is defined as the part of the filename that precedes the first hyphen (-) or underscore (_).\nIn the following example, 16 images will be used as examples. Here, they represent four replicates of four different treatments (TRAT1_1, TRAT1_2, ..., TRAT4_4). Note that to ensure that all images are processed, all images must share a common pattern, in this case (\"TRAT\").\n\nsystem.time(\n  sev_trats <- \n    measure_disease(pattern = \"TRAT\",\n                    img_healthy = \"feijao_h\",\n                    img_symptoms = \"feijao_s\",\n                    img_background = \"feijao_b\",\n                    show_features = TRUE,\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\nImage processing using multiple sessions (6). Please wait.\n\n\n  usuário   sistema decorrido \n     0.50      0.14     17.14 \n\nsev <- \n  sev_trats$severity |> \n  separate_col(img, into = c(\"TRAT\", \"REP\"))\n\nlibrary(ggplot2)\nggplot(sev, aes(TRAT, symptomatic))+\n  geom_boxplot() +\n  geom_jitter(alpha = 0.3) +\n  labs(x = \"Tratamentos\",\n       y = \"Severidade (%)\")"
  },
  {
    "objectID": "04_phytopathometry.html#multiple-leaves-in-one-image",
    "href": "04_phytopathometry.html#multiple-leaves-in-one-image",
    "title": "Phytopathometry",
    "section": "\n3.7 Multiple leaves in one image",
    "text": "3.7 Multiple leaves in one image\nWhen multiple leaves are present in an image, the measure_disease function returns the average severity of the leaves present in the image. To quantify the severity per leaf, the measure_disease_byl() function can be used.\nThis function computes the percentage of symptomatic leaf area using color palettes or RGB indices for each leaf (byl) of an image. This allows, for example, to process replicates of the same treatment and obtain the results of each replication with a single image. To do this, the sample sheets are first split using the object_split() function and then the measure_disease() function is applied to the sheet list.\n\nbyl <- \n  measure_disease_byl(pattern = \"multiplas\",\n                      index = \"B\", # used to segment leaves from background\n                      img_healthy = \"soja_h\",\n                      img_symptoms = \"soja_s\",\n                      show_contour = FALSE,\n                      show_features = TRUE,\n                      col_lesions = \"red\",\n                      parallel = TRUE)\n\nImage processing using multiple sessions (6). Please wait.\n\nresults_byl <- get_measures(byl)\n\nresults_byl$results |> \n  head()\n\n           img leaf id       x       y area area_ch perimeter radius_mean\n1 multiplas_01    1  1 232.000  27.278   36      32    24.142       2.934\n2 multiplas_01    1  2 374.250  31.675   40      34    27.728       3.561\n3 multiplas_01    1  3 168.704  82.423   71      64    32.385       4.347\n4 multiplas_01    1  4 226.286  86.500   14       8     9.828       1.660\n5 multiplas_01    1  5 175.529 104.176   34      26    20.485       2.947\n6 multiplas_01    1  6 127.667 102.667    3       0     2.414       0.654\n  radius_min radius_max radius_sd diam_mean diam_min diam_max major_axis\n1      1.640      3.919     0.717     5.867    3.280    7.837      8.105\n2      1.755      6.046     1.167     7.122    3.509   12.093     11.317\n3      2.756      6.038     0.931     8.693    5.513   12.075     11.936\n4      1.300      1.921     0.230     3.321    2.600    3.842      4.209\n5      1.232      4.448     0.864     5.893    2.464    8.895      9.329\n6      0.471      0.745     0.129     1.308    0.943    1.491      2.309\n  minor_axis length width radius_ratio eccentricity  theta solidity convexity\n1      6.233  7.505 5.559        2.390        0.598 -1.292    1.125     0.718\n2      4.821 10.738 4.484        3.446        0.165  0.436    1.176     0.775\n3      7.998 11.651 8.462        2.191        0.500 -1.089    1.109     0.825\n4      4.121  3.000 3.000        1.478        0.938  1.571    1.750     1.000\n5      4.875  8.546 4.382        3.610        0.297  0.839    1.308     0.914\n6      1.333  1.414 0.707        1.581        0.333 -0.785      Inf     1.000\n  elongation circularity circularity_haralick circularity_norm   asm   con\n1      0.259      16.190                4.093            1.893 0.089 0.883\n2      0.582      19.221                3.052            2.309 0.049 4.439\n3      0.274      14.771                4.667            1.490 0.130 0.762\n4      0.000       6.900                7.224            0.961 0.356 0.361\n5      0.487      12.343                3.409            1.421 0.116 3.360\n6      0.500       1.943                5.064            0.928 1.000 0.000\n    cor   var   idm    sav     sva   sen   ent   dva   den   f12   f13\n1 0.651 2.264 0.675 22.107 454.163 0.894 1.165 0.883 0.408 0.195 0.472\n2 0.425 4.858 0.493 19.912 367.418 1.033 1.495 4.439 0.702 0.125 0.426\n3 0.505 1.769 0.702 22.424 471.542 0.763 1.011 0.762 0.388 0.128 0.359\n4 0.126 1.207 0.819 20.583 407.338 0.412 0.521 0.361 0.284 0.013 0.082\n5 0.045 2.760 0.551 19.040 337.034 0.782 1.168 3.360 0.631 0.034 0.198\n6 0.000 1.000 1.000 18.000 324.000 0.000 0.000 0.000 0.000 0.000 0.000"
  },
  {
    "objectID": "04_phytopathometry.html#a-little-gift",
    "href": "04_phytopathometry.html#a-little-gift",
    "title": "Phytopathometry",
    "section": "\n3.8 A little gift",
    "text": "3.8 A little gift\n\nf0 <- image_import(\"fungo.jpg\", plot = TRUE)\nres <- \n  analyze_objects(f0,\n                  my_index = \"(G+B)^3-R\",\n                  watershed = FALSE,\n                  filter = 30,\n                  contour_size = 3,\n                  contour_col = \"black\")\n\nmeas <- get_measures(res, dpi = 254)\nplot_measures(meas,\n              col = \"white\",\n              measure = \"diam_mean\",\n              size = 2)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe segmentation can also be performed using sample palettes representing the foreground and background. In this example, pick the color samples, then use them in the analyze_objects(). ::: {.cell}\nback <- pick_palette(f0)\nfore <- pick_palette(f0)\n\nres <- \n  analyze_objects(f0,\n                  background = back,\n                  foreground = fore,\n                  watershed = FALSE,\n                  filter = 30)\n\nmeas <- get_measures(res, dpi = 254)\nplot_measures(meas,\n              col = \"black\",\n              measure = \"diam_mean\",\n              size = 2)\n\n\n:::\n\n\n\nSource Code\n---\ntitle: \"Phytopathometry\"\n---\n\n```{r include = FALSE}\nknitr::opts_knit$set(root.dir = \"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n# Directory\n```{r eval=FALSE}\nsetwd(\"E:/Desktop/UFSC/cursos/pliman_tut/imgs\")\n```\n\n\n\n# Disease severity\n# Using image indexes\n```{r}\nlibrary(pliman)\nimg <- image_import(\"disease.jpeg\", plot = TRUE)\nres <- measure_disease(img,\n                       index_lb = \"B\",\n                       index_dh = \"HUE2\",\n                       invert = c(FALSE, TRUE))\nres$severity\n```\n\n\n## Using sample palettes\n\nSample palettes can be made by simply manually sampling small areas of representative images and producing a composite image that will represent each of the desired classes (background, healthy, and symptomatic tissues). \n\n```{r doença1, fig.width = 12, fig.height = 3}\nimg <- image_import(\"exemp_1.jpeg\", plot = TRUE)\nh <- image_import(\"exem_h.png\")\nd <- image_import(\"exem_d.png\")\nb <- image_import(\"exem_b.png\")\nimage_combine(img, h, d, b, ncol = 4)\n```\n\n\n## Producing sample palettes\n\nUsers can produce these palettes with `pick_palette()` function.\n\n```{r eval=FALSE, fig.width=10}\nh2 <- pick_palette(img)\nd2 <- pick_palette(img)\nb2 <- pick_palette(img)\nimage_combine(h2, d2, b2, ncol = 3)\n\n```\n\n\n### Defaults settings\n```{r}\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b)\nsev$severity\n```\n\n\n### Filling lesions\n```{r}\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_contour = FALSE)\n```\n\n\n### Showing a mask\n```{r}\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_original = FALSE,\n                  col_lesions = \"brown\") # padrão é \"black\"\n```\n\n\n### Segmenting and analyzing lesions\n\nWhen using `show_features = TRUE`, the function analyzes the lesions and returns results such as number of lesions, area, perimeter, etc. With `show_segmentation = TRUE`, segmented lesions are shown.\n\n```{r}\nsev <- \n  measure_disease(img = img,\n                  img_healthy = h,\n                  img_symptoms = d,\n                  img_background = b,\n                  show_features = TRUE,\n                  show_segmentation = TRUE)\n\n# correct the measures (dpi = 150)\nsev_corrected <- get_measures(sev, dpi = 150)\n```\n\n\n## Batch processing\nTo analyze several images from a directory, use the `pattern` argument to declare a pattern of filenames. Here, we Will used 50 soybean leaves available in the repository https://osf.io/4hbr6, a database of images of annotation of severity of plant diseases. Thanks to [Emerson M. Del Ponte](https://osf.io/jb6yd/) and his contributors for keeping this project publicly available. Using the `save_image = TRUE` argument we save the processed images in a temporary directory, defined by `tempdir()`.\n\n```{r}\n# criar um diretório temporário\ntemp_dir <- tempdir()\n\nsystem.time(\n  sev_lote <- \n    measure_disease(pattern = \"soy\",\n                    img_healthy = \"soja_h\",\n                    img_symptoms = \"soja_s\",\n                    img_background = \"soja_b\",\n                    show_image = FALSE,\n                    save_image = TRUE,\n                    dir_processed = temp_dir,\n                    show_contour = FALSE,\n                    col_lesions = \"brown\")\n)\nsev_lote$severity\n```\n\n\n\n\n## Standard area diagrams\n\nStandard area diagrams (SAD) have long been used as a tool to aid the estimation of plant disease severity, serving as a standard reference template before or during the assessments.\n\nGiven an object computed with `measure_disease()` a Standard Area Diagram (SAD) with `n` images containing the respective severity values are obtained with `sad()`.\n\nLeaves with the smallest and highest severity will always be in the SAD. If `n = 1`, the leaf with the smallest severity will be returned. The others are sampled sequentially to achieve the n images after severity has been ordered in ascending order. For example, if there are 30 leaves and n is set to 3, the leaves sampled will be the 1st, 15th, and 30th with the smallest severity values.\n\nThe SAD can be only computed if an image pattern name is used in argument `pattern` of `measure_disease()`. If the images are saved, the `n` images will be retrevied from `dir_processed` directory. Otherwise, the severity will be computed again to generate the images. A SAD with 8 images from the above example can be obtained easely with:\n\n```{r}\nsad(sev_lote, n = 6, ncol = 3)\n```\n\n\n## Parallel processing\n\nTo speed up processing time when multiple images are available, you can use the `paralell` argument. In parallel programming (`parallel = TRUE`), the images are processed asynchronously (in parallel) in separate R sessions running in the background on the same machine. The number of sections is set by default to 50% of available cores. This number can be controlled explicitly with the argument workers.\n\n```{r}\nsystem.time(\n  sev_lote <- \n    measure_disease(pattern = \"soy\",\n                    img_healthy = \"soja_h\",\n                    img_symptoms = \"soja_s\",\n                    img_background = \"soja_b\",\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\n\n\n```\n\n\n\n## Multiple images of the same sample\n\nIf users need to analyze multiple images from the same sample, the images from the same sample must share the same filename prefix, which is defined as the part of the filename that precedes the first hyphen (`-`) or underscore (`_`).\n\nIn the following example, 16 images will be used as examples. Here, they represent four replicates of four different treatments (`TRAT1_1, TRAT1_2, ..., TRAT4_4`). Note that to ensure that all images are processed, all images must share a common pattern, in this case (`\"TRAT\"`).\n\n```{r}\nsystem.time(\n  sev_trats <- \n    measure_disease(pattern = \"TRAT\",\n                    img_healthy = \"feijao_h\",\n                    img_symptoms = \"feijao_s\",\n                    img_background = \"feijao_b\",\n                    show_features = TRUE,\n                    show_image = FALSE,\n                    parallel = TRUE)\n)\nsev <- \n  sev_trats$severity |> \n  separate_col(img, into = c(\"TRAT\", \"REP\"))\n\nlibrary(ggplot2)\nggplot(sev, aes(TRAT, symptomatic))+\n  geom_boxplot() +\n  geom_jitter(alpha = 0.3) +\n  labs(x = \"Tratamentos\",\n       y = \"Severidade (%)\")\n```\n\n\n\n## Multiple leaves in one image\n\nWhen multiple leaves are present in an image, the `measure_disease` function returns the average severity of the leaves present in the image. To quantify the severity *per leaf*, the `measure_disease_byl()` function can be used.\n\nThis function computes the percentage of symptomatic leaf area using color palettes or RGB indices for each leaf (`byl`) of an image. This allows, for example, to process replicates of the same treatment and obtain the results of each replication with a single image. To do this, the sample sheets are first split using the `object_split()` function and then the `measure_disease()` function is applied to the sheet list.\n\n```{r}\nbyl <- \n  measure_disease_byl(pattern = \"multiplas\",\n                      index = \"B\", # used to segment leaves from background\n                      img_healthy = \"soja_h\",\n                      img_symptoms = \"soja_s\",\n                      show_contour = FALSE,\n                      show_features = TRUE,\n                      col_lesions = \"red\",\n                      parallel = TRUE)\n\nresults_byl <- get_measures(byl)\n\nresults_byl$results |> \n  head()\n```\n\n\n\n## A little gift\n\n```{r}\nf0 <- image_import(\"fungo.jpg\", plot = TRUE)\nres <- \n  analyze_objects(f0,\n                  my_index = \"(G+B)^3-R\",\n                  watershed = FALSE,\n                  filter = 30,\n                  contour_size = 3,\n                  contour_col = \"black\")\n\nmeas <- get_measures(res, dpi = 254)\nplot_measures(meas,\n              col = \"white\",\n              measure = \"diam_mean\",\n              size = 2)\n```\n\n\n:::{.callout-tip}\nThe segmentation can also be performed using sample palettes representing the foreground and background. In this example, pick the color samples, then use them in the `analyze_objects()`.\n```{r eval=FALSE}\n\n\nback <- pick_palette(f0)\nfore <- pick_palette(f0)\n\nres <- \n  analyze_objects(f0,\n                  background = back,\n                  foreground = fore,\n                  watershed = FALSE,\n                  filter = 30)\n\nmeas <- get_measures(res, dpi = 254)\nplot_measures(meas,\n              col = \"black\",\n              measure = \"diam_mean\",\n              size = 2)\n```\n:::"
  }
]